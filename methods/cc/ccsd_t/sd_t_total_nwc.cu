#include "ccsd_t_common.hpp"

__device__ double* t3_s_d;
__device__ double* t3_d;

void dev_mem_d(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d,size_t p6d)
{
  // size_t size_t3;
  size_t size_t3 = h1d*h2d*h3d*p4d*p5d*p6d;
  t3_d = (double *) getGpuMem(size_t3*sizeof(double));
  cudaMemset(t3_d,0,size_t3*sizeof(double));
}
//            void
// dev_mem_d(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d)
// {
//     set_dev_mem_d((int) *h1d, (int) *h2d, (int) *h3d, (int) *p4d, (int) *p5d, (int) *p6d);
// }
void dev_release()
{
  freeGpuMem(t3_d);
  freeGpuMem(t3_s_d);
}
//   void
// dev_release_()
// {
//     dev_release();
// }


/*----------------------------------------------------------------------*
 *triplesx[h3,h1,p6,p5,p4] -= t2sub[h7,p4,p5,h1] * v2sub[h3,p6,h7]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d1_1_kernel(size_t h1d,size_t h3d,size_t h7d,size_t p4d,size_t p5d,size_t p6d,size_t h7ld_t2sub,size_t p4ld_t2sub,size_t p5ld_t2sub,size_t h1ld_t2sub,size_t h3ld_v2sub,size_t p6ld_v2sub,size_t h7ld_v2sub,size_t h3ld_triplesx,size_t h1ld_triplesx,size_t p6ld_triplesx,size_t p5ld_triplesx,size_t p4ld_triplesx,double *triplesx_d, double *t2sub_d, double *v2sub_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h3_0,h3_1,h3_2,h3_3,h7,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,h7l,h7T;
  __shared__ double t2sub_shm[4*T1][Tcomm];
  __shared__ double v2sub_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_0=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_0=rest_y;
  p6_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_1=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_1=rest_y;
  p6_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_2=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_2=rest_y;
  p6_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_3=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_3=rest_y;
  p6_3=rest_x;
  size_t t2sub_d_off, v2sub_d_off;for(h7T=0;h7T<h7d;h7T+=Tcomm){size_t h7l_hi;
    h7l_hi = TG_MIN(Tcomm+h7T,h7d)-h7T;
    t2sub_d_off=p4_0*p4ld_t2sub+p5_0*p5ld_t2sub+h1_0*h1ld_t2sub;
    v2sub_d_off=h3_0*h3ld_v2sub+p6_0*p6ld_v2sub;
    if(thread_y+T1*0<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*0][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*0<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*0] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_1*p4ld_t2sub+p5_1*p5ld_t2sub+h1_1*h1ld_t2sub;
    v2sub_d_off=h3_1*h3ld_v2sub+p6_1*p6ld_v2sub;
    if(thread_y+T1*1<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*1][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*1<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*1] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_2*p4ld_t2sub+p5_2*p5ld_t2sub+h1_2*h1ld_t2sub;
    v2sub_d_off=h3_2*h3ld_v2sub+p6_2*p6ld_v2sub;
    if(thread_y+T1*2<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*2][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*2<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*2] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_3*p4ld_t2sub+p5_3*p5ld_t2sub+h1_3*h1ld_t2sub;
    v2sub_d_off=h3_3*h3ld_v2sub+p6_3*p6ld_v2sub;
    if(thread_y+T1*3<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*3][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*3<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*3] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    __syncthreads();
    for(h7l=0;h7l<h7l_hi;++h7l){
      a1=t2sub_shm[in1_idxl+T1*0][h7l];
      a2=t2sub_shm[in1_idxl+T1*1][h7l];
      a3=t2sub_shm[in1_idxl+T1*2][h7l];
      a4=t2sub_shm[in1_idxl+T1*3][h7l];
      b1=v2sub_shm[h7l][in2_idxl+T2*0];
      b2=v2sub_shm[h7l][in2_idxl+T2*1];
      b3=v2sub_shm[h7l][in2_idxl+T2*2];
      b4=v2sub_shm[h7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p6_0*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+p6_0*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+p6_0*p6ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal3;
      triplesx_d[h3_0*h3ld_triplesx+h1_3*h1ld_triplesx+p6_0*p6ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]-=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p6_0*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+p6_0*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+p6_0*p6ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p6_0*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+p6_0*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p6_0*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p6_1*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+p6_1*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+p6_1*p6ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal7;
      triplesx_d[h3_1*h3ld_triplesx+h1_3*h1ld_triplesx+p6_1*p6ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]-=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p6_1*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+p6_1*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+p6_1*p6ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p6_1*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+p6_1*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p6_1*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p6_2*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+p6_2*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+p6_2*p6ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal11;
      triplesx_d[h3_2*h3ld_triplesx+h1_3*h1ld_triplesx+p6_2*p6ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]-=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p6_2*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+p6_2*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+p6_2*p6ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p6_2*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+p6_2*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p6_2*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p6_3*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+p6_3*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+p6_3*p6ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal15;
      triplesx_d[h3_3*h3ld_triplesx+h1_3*h1ld_triplesx+p6_3*p6ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]-=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p6_3*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+p6_3*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+p6_3*p6ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p6_3*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+p6_3*p6ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p6_3*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
    }
  }
  __syncthreads();

  // // 
  // if (blockIdx.x == 0 && threadIdx.y == 0 && threadIdx.x == 0)
  // {
  //   // triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p6_0*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
  //   printf (">> t3_d[%d]: %.15f\n", h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p6_0*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx, 
  //   triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p6_0*p6ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]);
  // }
}
  void sd_t_d1_1_cuda(size_t h1d, size_t h2d, size_t h3d, size_t h7d, size_t p4d, size_t p5d, size_t p6d, double *triplesx, double *t2sub, double *v2sub) {
  h3d=h3d*h2d;
  size_t h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,p6ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,p6ld_triplesx,p5ld_triplesx,p4ld_triplesx;
  size_t /*size_triplesx,size_block_triplesx,size_el_block_triplesx,*/size_t2sub,size_v2sub;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2sub_d,*v2sub_d;
  //size_triplesx=h3d*h1d*p6d*p5d*p4d*sizeof(double);
  size_t2sub=h7d*p4d*p5d*h1d*sizeof(double);
  size_v2sub=h3d*p6d*h7d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d1_1_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_triplesx=size_triplesx/nstreams;
  //size_el_block_triplesx=size_block_triplesx/sizeof(double);
  t2sub_d=(double*)getGpuMem(size_t2sub);
  v2sub_d=(double*)getGpuMem(size_v2sub);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2sub_d,t2sub,size_t2sub,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2sub_d,v2sub,size_v2sub,cudaMemcpyHostToDevice));
  h7ld_t2sub=1;
  p4ld_t2sub=h7d;
  p5ld_t2sub=p4d*h7d;
  h1ld_t2sub=p5d*p4d*h7d;
  h3ld_v2sub=1;
  p6ld_v2sub=h3d;
  h7ld_v2sub=p6d*h3d;
  h3ld_triplesx=1;
  h1ld_triplesx=h3d;
  p6ld_triplesx=h1d*h3d;
  p5ld_triplesx=p6d*h1d*h3d;
  p4ld_triplesx=p5d*p6d*h1d*h3d;
  size_t total_x = h3d*p6d*1;
  size_t total_y = p4d*p5d*h1d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d1_1_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h3d,h7d,p4d,p5d,p6d,h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,p6ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,p6ld_triplesx,p5ld_triplesx,p4ld_triplesx,t3_d,t2sub_d,v2sub_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  freeGpuMem(t2sub_d);
  freeGpuMem(v2sub_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d1_1_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* h7d, Integer* p4d, Integer* p5d, Integer* p6d, double *triplesx, double *t2sub, double *v2sub) {
  sd_t_d1_1_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*h7d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,triplesx,t2sub,v2sub);
}
/*----------------------------------------------------------------------*
 *triplesx[h3,h1,h2,p5,p4] += t2sub[h7,p4,p5,h1] * v2sub[h3,h2,h7]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d1_2_kernel(size_t h1d,size_t h2d,size_t h3d,size_t h7d,size_t p4d,size_t p5d,size_t h7ld_t2sub,size_t p4ld_t2sub,size_t p5ld_t2sub,size_t h1ld_t2sub,size_t h3ld_v2sub,size_t h2ld_v2sub,size_t h7ld_v2sub,size_t h3ld_triplesx,size_t h1ld_triplesx,size_t h2ld_triplesx,size_t p5ld_triplesx,size_t p4ld_triplesx,double *triplesx_d, double *t2sub_d, double *v2sub_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,h7,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,h7l,h7T;
  __shared__ double t2sub_shm[4*T1][Tcomm];
  __shared__ double v2sub_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_0=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_0=rest_y;
  h2_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_1=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_1=rest_y;
  h2_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_2=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_2=rest_y;
  h2_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_3=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_3=rest_y;
  h2_3=rest_x;
  size_t t2sub_d_off, v2sub_d_off;for(h7T=0;h7T<h7d;h7T+=Tcomm){size_t h7l_hi;
    h7l_hi = TG_MIN(Tcomm+h7T,h7d)-h7T;
    t2sub_d_off=p4_0*p4ld_t2sub+p5_0*p5ld_t2sub+h1_0*h1ld_t2sub;
    v2sub_d_off=h3_0*h3ld_v2sub+h2_0*h2ld_v2sub;
    if(thread_y+T1*0<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*0][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*0<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*0] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_1*p4ld_t2sub+p5_1*p5ld_t2sub+h1_1*h1ld_t2sub;
    v2sub_d_off=h3_1*h3ld_v2sub+h2_1*h2ld_v2sub;
    if(thread_y+T1*1<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*1][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*1<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*1] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_2*p4ld_t2sub+p5_2*p5ld_t2sub+h1_2*h1ld_t2sub;
    v2sub_d_off=h3_2*h3ld_v2sub+h2_2*h2ld_v2sub;
    if(thread_y+T1*2<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*2][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*2<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*2] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_3*p4ld_t2sub+p5_3*p5ld_t2sub+h1_3*h1ld_t2sub;
    v2sub_d_off=h3_3*h3ld_v2sub+h2_3*h2ld_v2sub;
    if(thread_y+T1*3<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*3][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*3<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*3] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    __syncthreads();
    for(h7l=0;h7l<h7l_hi;++h7l){
      a1=t2sub_shm[in1_idxl+T1*0][h7l];
      a2=t2sub_shm[in1_idxl+T1*1][h7l];
      a3=t2sub_shm[in1_idxl+T1*2][h7l];
      a4=t2sub_shm[in1_idxl+T1*3][h7l];
      b1=v2sub_shm[h7l][in2_idxl+T2*0];
      b2=v2sub_shm[h7l][in2_idxl+T2*1];
      b3=v2sub_shm[h7l][in2_idxl+T2*2];
      b4=v2sub_shm[h7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+h2_0*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+h2_0*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]+=tlocal3;
      triplesx_d[h3_0*h3ld_triplesx+h1_3*h1ld_triplesx+h2_0*h2ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]+=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+h2_0*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+h2_0*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]+=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+h2_0*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+h2_1*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+h2_1*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]+=tlocal7;
      triplesx_d[h3_1*h3ld_triplesx+h1_3*h1ld_triplesx+h2_1*h2ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]+=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+h2_1*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+h2_1*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]+=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+h2_1*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+h2_2*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+h2_2*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]+=tlocal11;
      triplesx_d[h3_2*h3ld_triplesx+h1_3*h1ld_triplesx+h2_2*h2ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]+=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+h2_2*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+h2_2*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]+=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+h2_2*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+h2_3*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+h2_3*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]+=tlocal15;
      triplesx_d[h3_3*h3ld_triplesx+h1_3*h1ld_triplesx+h2_3*h2ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]+=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+h2_3*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+h2_3*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]+=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+h2_3*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]+=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d1_2_cuda(size_t h1d, size_t h2d, size_t h3d, size_t h7d, size_t p4d, size_t p5d, size_t p6d, double *triplesx, double *t2sub, double *v2sub) {
  h2d=h2d*p6d;
  size_t h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,h2ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,h2ld_triplesx,p5ld_triplesx,p4ld_triplesx;
  size_t /*size_triplesx,size_block_triplesx,size_el_block_triplesx,*/size_t2sub,size_v2sub;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2sub_d,*v2sub_d;
  //size_triplesx=h3d*h1d*h2d*p5d*p4d*sizeof(double);
  size_t2sub=h7d*p4d*p5d*h1d*sizeof(double);
  size_v2sub=h3d*h2d*h7d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d1_2_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_triplesx=size_triplesx/nstreams;
  //size_el_block_triplesx=size_block_triplesx/sizeof(double);
  t2sub_d=(double*)getGpuMem(size_t2sub);
  v2sub_d=(double*)getGpuMem(size_v2sub);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  //CUDA_SAFE(
    cudaMemcpy(t2sub_d,t2sub,size_t2sub,cudaMemcpyHostToDevice); //);
  //CUDA_SAFE(  
    cudaMemcpy(v2sub_d,v2sub,size_v2sub,cudaMemcpyHostToDevice); //);
  h7ld_t2sub=1;
  p4ld_t2sub=h7d;
  p5ld_t2sub=p4d*h7d;
  h1ld_t2sub=p5d*p4d*h7d;
  h3ld_v2sub=1;
  h2ld_v2sub=h3d;
  h7ld_v2sub=h2d*h3d;
  h3ld_triplesx=1;
  h1ld_triplesx=h3d;
  h2ld_triplesx=h1d*h3d;
  p5ld_triplesx=h2d*h1d*h3d;
  p4ld_triplesx=p5d*h2d*h1d*h3d;
  size_t total_x = h3d*h2d*1;
  size_t total_y = p4d*p5d*h1d;
//printf("Blocks %d %d\n", total_x, total_y); 
//fflush(stdout);    
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d1_2_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,h7d,p4d,p5d,h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,h2ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,h2ld_triplesx,p5ld_triplesx,p4ld_triplesx,t3_d,t2sub_d,v2sub_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  freeGpuMem(t2sub_d);
  freeGpuMem(v2sub_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d1_2_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* h7d, Integer* p4d, Integer* p5d, Integer* p6d, double *triplesx, double *t2sub, double *v2sub) {
  sd_t_d1_2_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*h7d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,triplesx,t2sub,v2sub);
}
/*----------------------------------------------------------------------*
 *triplesx[h1,h3,p5,p4] -= t2sub[h7,p4,p5,h1] * v2sub[h3,h7]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d1_3_kernel(size_t h1d,size_t h3d,size_t h7d,size_t p4d,size_t p5d,size_t h7ld_t2sub,size_t p4ld_t2sub,size_t p5ld_t2sub,size_t h1ld_t2sub,size_t h3ld_v2sub,size_t h7ld_v2sub,size_t h1ld_triplesx,size_t h3ld_triplesx,size_t p5ld_triplesx,size_t p4ld_triplesx,double *triplesx_d, double *t2sub_d, double *v2sub_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h3_0,h3_1,h3_2,h3_3,h7,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,h7l,h7T;
  __shared__ double t2sub_shm[4*T1][Tcomm];
  __shared__ double v2sub_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_0=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_0=rest_y;
  h3_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_1=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_1=rest_y;
  h3_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_2=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_2=rest_y;
  h3_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_3=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_3=rest_y;
  h3_3=rest_x;
  size_t t2sub_d_off, v2sub_d_off;for(h7T=0;h7T<h7d;h7T+=Tcomm){size_t h7l_hi;
    h7l_hi = TG_MIN(Tcomm+h7T,h7d)-h7T;
    t2sub_d_off=p4_0*p4ld_t2sub+p5_0*p5ld_t2sub+h1_0*h1ld_t2sub;
    v2sub_d_off=h3_0*h3ld_v2sub;
    if(thread_y+T1*0<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*0][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*0<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*0] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_1*p4ld_t2sub+p5_1*p5ld_t2sub+h1_1*h1ld_t2sub;
    v2sub_d_off=h3_1*h3ld_v2sub;
    if(thread_y+T1*1<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*1][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*1<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*1] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_2*p4ld_t2sub+p5_2*p5ld_t2sub+h1_2*h1ld_t2sub;
    v2sub_d_off=h3_2*h3ld_v2sub;
    if(thread_y+T1*2<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*2][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*2<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*2] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_3*p4ld_t2sub+p5_3*p5ld_t2sub+h1_3*h1ld_t2sub;
    v2sub_d_off=h3_3*h3ld_v2sub;
    if(thread_y+T1*3<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*3][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*3<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*3] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    __syncthreads();
    for(h7l=0;h7l<h7l_hi;++h7l){
      a1=t2sub_shm[in1_idxl+T1*0][h7l];
      a2=t2sub_shm[in1_idxl+T1*1][h7l];
      a3=t2sub_shm[in1_idxl+T1*2][h7l];
      a4=t2sub_shm[in1_idxl+T1*3][h7l];
      b1=v2sub_shm[h7l][in2_idxl+T2*0];
      b2=v2sub_shm[h7l][in2_idxl+T2*1];
      b3=v2sub_shm[h7l][in2_idxl+T2*2];
      b4=v2sub_shm[h7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
      triplesx_d[h1_1*h1ld_triplesx+h3_0*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal2;
      triplesx_d[h1_2*h1ld_triplesx+h3_0*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal3;
      triplesx_d[h1_3*h1ld_triplesx+h3_0*h3ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]-=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
      triplesx_d[h1_1*h1ld_triplesx+h3_0*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal2;
      triplesx_d[h1_2*h1ld_triplesx+h3_0*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
      triplesx_d[h1_1*h1ld_triplesx+h3_0*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
      triplesx_d[h1_1*h1ld_triplesx+h3_1*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal6;
      triplesx_d[h1_2*h1ld_triplesx+h3_1*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal7;
      triplesx_d[h1_3*h1ld_triplesx+h3_1*h3ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]-=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
      triplesx_d[h1_1*h1ld_triplesx+h3_1*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal6;
      triplesx_d[h1_2*h1ld_triplesx+h3_1*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
      triplesx_d[h1_1*h1ld_triplesx+h3_1*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
      triplesx_d[h1_1*h1ld_triplesx+h3_2*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal10;
      triplesx_d[h1_2*h1ld_triplesx+h3_2*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal11;
      triplesx_d[h1_3*h1ld_triplesx+h3_2*h3ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]-=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
      triplesx_d[h1_1*h1ld_triplesx+h3_2*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal10;
      triplesx_d[h1_2*h1ld_triplesx+h3_2*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
      triplesx_d[h1_1*h1ld_triplesx+h3_2*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
      triplesx_d[h1_1*h1ld_triplesx+h3_3*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal14;
      triplesx_d[h1_2*h1ld_triplesx+h3_3*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal15;
      triplesx_d[h1_3*h1ld_triplesx+h3_3*h3ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx]-=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
      triplesx_d[h1_1*h1ld_triplesx+h3_3*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal14;
      triplesx_d[h1_2*h1ld_triplesx+h3_3*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx]-=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
      triplesx_d[h1_1*h1ld_triplesx+h3_3*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx]-=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d1_3_cuda(size_t h1d, size_t h2d, size_t h3d, size_t h7d, size_t p4d, size_t p5d, size_t p6d, double *triplesx, double *t2sub, double *v2sub) {
  h3d=h3d*h2d;
  h3d=h3d*p6d;
  size_t h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,h7ld_v2sub,h1ld_triplesx,h3ld_triplesx,p5ld_triplesx,p4ld_triplesx;
  size_t /*size_triplesx,size_block_triplesx,size_el_block_triplesx,*/size_t2sub,size_v2sub;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2sub_d,*v2sub_d;
  //size_triplesx=h1d*h3d*p5d*p4d*sizeof(double);
  size_t2sub=h7d*p4d*p5d*h1d*sizeof(double);
  size_v2sub=h3d*h7d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d1_3_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_triplesx=size_triplesx/nstreams;
  //size_el_block_triplesx=size_block_triplesx/sizeof(double);
  t2sub_d=(double*)getGpuMem(size_t2sub);
  v2sub_d=(double*)getGpuMem(size_v2sub);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2sub_d,t2sub,size_t2sub,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2sub_d,v2sub,size_v2sub,cudaMemcpyHostToDevice));
  h7ld_t2sub=1;
  p4ld_t2sub=h7d;
  p5ld_t2sub=p4d*h7d;
  h1ld_t2sub=p5d*p4d*h7d;
  h3ld_v2sub=1;
  h7ld_v2sub=h3d;
  h1ld_triplesx=1;
  h3ld_triplesx=h1d;
  p5ld_triplesx=h3d*h1d;
  p4ld_triplesx=p5d*h3d*h1d;
  size_t total_x = h3d*1;
  size_t total_y = p4d*p5d*h1d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d1_3_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h3d,h7d,p4d,p5d,h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,h7ld_v2sub,h1ld_triplesx,h3ld_triplesx,p5ld_triplesx,p4ld_triplesx,t3_d,t2sub_d,v2sub_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  freeGpuMem(t2sub_d);
  freeGpuMem(v2sub_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d1_3_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* h7d, Integer* p4d, Integer* p5d, Integer* p6d, double *triplesx, double *t2sub, double *v2sub) {
  sd_t_d1_3_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*h7d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,triplesx,t2sub,v2sub);
}
/*----------------------------------------------------------------------*
 *triplesx[h3,h1,p5,p4,p6] -= t2sub[h7,p4,p5,h1] * v2sub[h3,p6,h7]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d1_4_kernel(size_t h1d,size_t h3d,size_t h7d,size_t p4d,size_t p5d,size_t p6d,size_t h7ld_t2sub,size_t p4ld_t2sub,size_t p5ld_t2sub,size_t h1ld_t2sub,size_t h3ld_v2sub,size_t p6ld_v2sub,size_t h7ld_v2sub,size_t h3ld_triplesx,size_t h1ld_triplesx,size_t p5ld_triplesx,size_t p4ld_triplesx,size_t p6ld_triplesx,double *triplesx_d, double *t2sub_d, double *v2sub_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h3_0,h3_1,h3_2,h3_3,h7,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,h7l,h7T;
  __shared__ double t2sub_shm[4*T1][Tcomm];
  __shared__ double v2sub_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_0=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_0=rest_y;
  p6_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_1=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_1=rest_y;
  p6_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_2=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_2=rest_y;
  p6_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_3=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_3=rest_y;
  p6_3=rest_x;
  size_t t2sub_d_off, v2sub_d_off;for(h7T=0;h7T<h7d;h7T+=Tcomm){size_t h7l_hi;
    h7l_hi = TG_MIN(Tcomm+h7T,h7d)-h7T;
    t2sub_d_off=p4_0*p4ld_t2sub+p5_0*p5ld_t2sub+h1_0*h1ld_t2sub;
    v2sub_d_off=h3_0*h3ld_v2sub+p6_0*p6ld_v2sub;
    if(thread_y+T1*0<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*0][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*0<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*0] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_1*p4ld_t2sub+p5_1*p5ld_t2sub+h1_1*h1ld_t2sub;
    v2sub_d_off=h3_1*h3ld_v2sub+p6_1*p6ld_v2sub;
    if(thread_y+T1*1<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*1][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*1<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*1] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_2*p4ld_t2sub+p5_2*p5ld_t2sub+h1_2*h1ld_t2sub;
    v2sub_d_off=h3_2*h3ld_v2sub+p6_2*p6ld_v2sub;
    if(thread_y+T1*2<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*2][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*2<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*2] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_3*p4ld_t2sub+p5_3*p5ld_t2sub+h1_3*h1ld_t2sub;
    v2sub_d_off=h3_3*h3ld_v2sub+p6_3*p6ld_v2sub;
    if(thread_y+T1*3<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*3][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*3<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*3] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    __syncthreads();
    for(h7l=0;h7l<h7l_hi;++h7l){
      a1=t2sub_shm[in1_idxl+T1*0][h7l];
      a2=t2sub_shm[in1_idxl+T1*1][h7l];
      a3=t2sub_shm[in1_idxl+T1*2][h7l];
      a4=t2sub_shm[in1_idxl+T1*3][h7l];
      b1=v2sub_shm[h7l][in2_idxl+T2*0];
      b2=v2sub_shm[h7l][in2_idxl+T2*1];
      b3=v2sub_shm[h7l][in2_idxl+T2*2];
      b4=v2sub_shm[h7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal3;
      triplesx_d[h3_0*h3ld_triplesx+h1_3*h1ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal7;
      triplesx_d[h3_1*h3ld_triplesx+h1_3*h1ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal11;
      triplesx_d[h3_2*h3ld_triplesx+h1_3*h1ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal15;
      triplesx_d[h3_3*h3ld_triplesx+h1_3*h1ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d1_4_cuda(size_t h1d, size_t h2d, size_t h3d, size_t h7d, size_t p4d, size_t p5d, size_t p6d, double *triplesx, double *t2sub, double *v2sub) {
  h3d=h3d*h2d;
  size_t h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,p6ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,p5ld_triplesx,p4ld_triplesx,p6ld_triplesx;
  size_t /*size_triplesx,size_block_triplesx,size_el_block_triplesx,*/size_t2sub,size_v2sub;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2sub_d,*v2sub_d;
  //size_triplesx=h3d*h1d*p5d*p4d*p6d*sizeof(double);
  size_t2sub=h7d*p4d*p5d*h1d*sizeof(double);
  size_v2sub=h3d*p6d*h7d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d1_4_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_triplesx=size_triplesx/nstreams;
  //size_el_block_triplesx=size_block_triplesx/sizeof(double);
  t2sub_d=(double*)getGpuMem(size_t2sub);
  v2sub_d=(double*)getGpuMem(size_v2sub);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2sub_d,t2sub,size_t2sub,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2sub_d,v2sub,size_v2sub,cudaMemcpyHostToDevice));
  h7ld_t2sub=1;
  p4ld_t2sub=h7d;
  p5ld_t2sub=p4d*h7d;
  h1ld_t2sub=p5d*p4d*h7d;
  h3ld_v2sub=1;
  p6ld_v2sub=h3d;
  h7ld_v2sub=p6d*h3d;
  h3ld_triplesx=1;
  h1ld_triplesx=h3d;
  p5ld_triplesx=h1d*h3d;
  p4ld_triplesx=p5d*h1d*h3d;
  p6ld_triplesx=p4d*p5d*h1d*h3d;
  size_t total_x = h3d*p6d*1;
  size_t total_y = p4d*p5d*h1d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d1_4_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h3d,h7d,p4d,p5d,p6d,h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,p6ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,p5ld_triplesx,p4ld_triplesx,p6ld_triplesx,t3_d,t2sub_d,v2sub_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  freeGpuMem(t2sub_d);
  freeGpuMem(v2sub_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d1_4_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* h7d, Integer* p4d, Integer* p5d, Integer* p6d, double *triplesx, double *t2sub, double *v2sub) {
  sd_t_d1_4_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*h7d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,triplesx,t2sub,v2sub);
}
/*----------------------------------------------------------------------*
 *triplesx[h3,h1,h2,p5,p4,p6] += t2sub[h7,p4,p5,h1] * v2sub[h3,h2,p6,h7]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d1_5_kernel(size_t h1d,size_t h2d,size_t h3d,size_t h7d,size_t p4d,size_t p5d,size_t p6d,size_t h7ld_t2sub,size_t p4ld_t2sub,size_t p5ld_t2sub,size_t h1ld_t2sub,size_t h3ld_v2sub,size_t h2ld_v2sub,size_t p6ld_v2sub,size_t h7ld_v2sub,size_t h3ld_triplesx,size_t h1ld_triplesx,size_t h2ld_triplesx,size_t p5ld_triplesx,size_t p4ld_triplesx,size_t p6ld_triplesx,double *triplesx_d, double *t2sub_d, double *v2sub_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,h7,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,h7l,h7T;
  __shared__ double t2sub_shm[4*T1][Tcomm];
  __shared__ double v2sub_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  h2_0=rest_x%h2d;
  rest_x=rest_x/h2d;
  p5_0=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_0=rest_y;
  p6_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  h2_1=rest_x%h2d;
  rest_x=rest_x/h2d;
  p5_1=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_1=rest_y;
  p6_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  h2_2=rest_x%h2d;
  rest_x=rest_x/h2d;
  p5_2=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_2=rest_y;
  p6_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  h2_3=rest_x%h2d;
  rest_x=rest_x/h2d;
  p5_3=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_3=rest_y;
  p6_3=rest_x;
  size_t t2sub_d_off, v2sub_d_off;for(h7T=0;h7T<h7d;h7T+=Tcomm){size_t h7l_hi;
    h7l_hi = TG_MIN(Tcomm+h7T,h7d)-h7T;
    t2sub_d_off=p4_0*p4ld_t2sub+p5_0*p5ld_t2sub+h1_0*h1ld_t2sub;
    v2sub_d_off=h3_0*h3ld_v2sub+h2_0*h2ld_v2sub+p6_0*p6ld_v2sub;
    if(thread_y+T1*0<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*0][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*0<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*0] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_1*p4ld_t2sub+p5_1*p5ld_t2sub+h1_1*h1ld_t2sub;
    v2sub_d_off=h3_1*h3ld_v2sub+h2_1*h2ld_v2sub+p6_1*p6ld_v2sub;
    if(thread_y+T1*1<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*1][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*1<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*1] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_2*p4ld_t2sub+p5_2*p5ld_t2sub+h1_2*h1ld_t2sub;
    v2sub_d_off=h3_2*h3ld_v2sub+h2_2*h2ld_v2sub+p6_2*p6ld_v2sub;
    if(thread_y+T1*2<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*2][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*2<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*2] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_3*p4ld_t2sub+p5_3*p5ld_t2sub+h1_3*h1ld_t2sub;
    v2sub_d_off=h3_3*h3ld_v2sub+h2_3*h2ld_v2sub+p6_3*p6ld_v2sub;
    if(thread_y+T1*3<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*3][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*3<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*3] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    __syncthreads();
    for(h7l=0;h7l<h7l_hi;++h7l){
      a1=t2sub_shm[in1_idxl+T1*0][h7l];
      a2=t2sub_shm[in1_idxl+T1*1][h7l];
      a3=t2sub_shm[in1_idxl+T1*2][h7l];
      a4=t2sub_shm[in1_idxl+T1*3][h7l];
      b1=v2sub_shm[h7l][in2_idxl+T2*0];
      b2=v2sub_shm[h7l][in2_idxl+T2*1];
      b3=v2sub_shm[h7l][in2_idxl+T2*2];
      b4=v2sub_shm[h7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]+=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+h2_0*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_0*p6ld_triplesx]+=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+h2_0*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_0*p6ld_triplesx]+=tlocal3;
      triplesx_d[h3_0*h3ld_triplesx+h1_3*h1ld_triplesx+h2_0*h2ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_0*p6ld_triplesx]+=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]+=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+h2_0*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_0*p6ld_triplesx]+=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+h2_0*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_0*p6ld_triplesx]+=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]+=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+h2_0*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_0*p6ld_triplesx]+=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]+=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]+=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+h2_1*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_1*p6ld_triplesx]+=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+h2_1*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_1*p6ld_triplesx]+=tlocal7;
      triplesx_d[h3_1*h3ld_triplesx+h1_3*h1ld_triplesx+h2_1*h2ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_1*p6ld_triplesx]+=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]+=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+h2_1*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_1*p6ld_triplesx]+=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+h2_1*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_1*p6ld_triplesx]+=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]+=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+h2_1*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_1*p6ld_triplesx]+=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]+=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]+=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+h2_2*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_2*p6ld_triplesx]+=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+h2_2*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_2*p6ld_triplesx]+=tlocal11;
      triplesx_d[h3_2*h3ld_triplesx+h1_3*h1ld_triplesx+h2_2*h2ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_2*p6ld_triplesx]+=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]+=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+h2_2*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_2*p6ld_triplesx]+=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+h2_2*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_2*p6ld_triplesx]+=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]+=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+h2_2*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_2*p6ld_triplesx]+=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]+=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]+=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+h2_3*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_3*p6ld_triplesx]+=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+h2_3*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_3*p6ld_triplesx]+=tlocal15;
      triplesx_d[h3_3*h3ld_triplesx+h1_3*h1ld_triplesx+h2_3*h2ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_3*p6ld_triplesx]+=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]+=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+h2_3*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_3*p6ld_triplesx]+=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+h2_3*h2ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_3*p6ld_triplesx]+=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]+=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+h2_3*h2ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_3*p6ld_triplesx]+=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]+=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d1_5_cuda(size_t h1d, size_t h2d, size_t h3d, size_t h7d, size_t p4d, size_t p5d, size_t p6d, double *triplesx, double *t2sub, double *v2sub) {
  size_t h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,h2ld_v2sub,p6ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,h2ld_triplesx,p5ld_triplesx,p4ld_triplesx,p6ld_triplesx;
  size_t /*size_triplesx,size_block_triplesx,size_el_block_triplesx,*/size_t2sub,size_v2sub;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2sub_d,*v2sub_d;
  //size_triplesx=h3d*h1d*h2d*p5d*p4d*p6d*sizeof(double);
  size_t2sub=h7d*p4d*p5d*h1d*sizeof(double);
  size_v2sub=h3d*h2d*p6d*h7d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d1_5_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_triplesx=size_triplesx/nstreams;
  //size_el_block_triplesx=size_block_triplesx/sizeof(double);
  t2sub_d=(double*)getGpuMem(size_t2sub);
  v2sub_d=(double*)getGpuMem(size_v2sub);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2sub_d,t2sub,size_t2sub,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2sub_d,v2sub,size_v2sub,cudaMemcpyHostToDevice));
  h7ld_t2sub=1;
  p4ld_t2sub=h7d;
  p5ld_t2sub=p4d*h7d;
  h1ld_t2sub=p5d*p4d*h7d;
  h3ld_v2sub=1;
  h2ld_v2sub=h3d;
  p6ld_v2sub=h2d*h3d;
  h7ld_v2sub=p6d*h2d*h3d;
  h3ld_triplesx=1;
  h1ld_triplesx=h3d;
  h2ld_triplesx=h1d*h3d;
  p5ld_triplesx=h2d*h1d*h3d;
  p4ld_triplesx=p5d*h2d*h1d*h3d;
  p6ld_triplesx=p4d*p5d*h2d*h1d*h3d;
  size_t total_x = h3d*h2d*p6d*1;
  size_t total_y = p4d*p5d*h1d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d1_5_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,h7d,p4d,p5d,p6d,h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,h2ld_v2sub,p6ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,h2ld_triplesx,p5ld_triplesx,p4ld_triplesx,p6ld_triplesx,t3_d,t2sub_d,v2sub_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  freeGpuMem(t2sub_d);
  freeGpuMem(v2sub_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d1_5_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* h7d, Integer* p4d, Integer* p5d, Integer* p6d, double *triplesx, double *t2sub, double *v2sub) {
  sd_t_d1_5_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*h7d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,triplesx,t2sub,v2sub);
}
/*----------------------------------------------------------------------*
 *triplesx[h1,h3,p5,p4,p6] -= t2sub[h7,p4,p5,h1] * v2sub[h3,p6,h7]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d1_6_kernel(size_t h1d,size_t h3d,size_t h7d,size_t p4d,size_t p5d,size_t p6d,size_t h7ld_t2sub,size_t p4ld_t2sub,size_t p5ld_t2sub,size_t h1ld_t2sub,size_t h3ld_v2sub,size_t p6ld_v2sub,size_t h7ld_v2sub,size_t h1ld_triplesx,size_t h3ld_triplesx,size_t p5ld_triplesx,size_t p4ld_triplesx,size_t p6ld_triplesx,double *triplesx_d, double *t2sub_d, double *v2sub_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h3_0,h3_1,h3_2,h3_3,h7,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,h7l,h7T;
  __shared__ double t2sub_shm[4*T1][Tcomm];
  __shared__ double v2sub_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  p5_0=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_0=rest_y;
  p6_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  p5_1=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_1=rest_y;
  p6_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  p5_2=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_2=rest_y;
  p6_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  p5_3=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_3=rest_y;
  p6_3=rest_x;
  size_t t2sub_d_off, v2sub_d_off;for(h7T=0;h7T<h7d;h7T+=Tcomm){size_t h7l_hi;
    h7l_hi = TG_MIN(Tcomm+h7T,h7d)-h7T;
    t2sub_d_off=p4_0*p4ld_t2sub+p5_0*p5ld_t2sub+h1_0*h1ld_t2sub;
    v2sub_d_off=h3_0*h3ld_v2sub+p6_0*p6ld_v2sub;
    if(thread_y+T1*0<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*0][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*0<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*0] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_1*p4ld_t2sub+p5_1*p5ld_t2sub+h1_1*h1ld_t2sub;
    v2sub_d_off=h3_1*h3ld_v2sub+p6_1*p6ld_v2sub;
    if(thread_y+T1*1<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*1][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*1<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*1] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_2*p4ld_t2sub+p5_2*p5ld_t2sub+h1_2*h1ld_t2sub;
    v2sub_d_off=h3_2*h3ld_v2sub+p6_2*p6ld_v2sub;
    if(thread_y+T1*2<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*2][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*2<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*2] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_3*p4ld_t2sub+p5_3*p5ld_t2sub+h1_3*h1ld_t2sub;
    v2sub_d_off=h3_3*h3ld_v2sub+p6_3*p6ld_v2sub;
    if(thread_y+T1*3<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*3][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*3<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*3] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    __syncthreads();
    for(h7l=0;h7l<h7l_hi;++h7l){
      a1=t2sub_shm[in1_idxl+T1*0][h7l];
      a2=t2sub_shm[in1_idxl+T1*1][h7l];
      a3=t2sub_shm[in1_idxl+T1*2][h7l];
      a4=t2sub_shm[in1_idxl+T1*3][h7l];
      b1=v2sub_shm[h7l][in2_idxl+T2*0];
      b2=v2sub_shm[h7l][in2_idxl+T2*1];
      b3=v2sub_shm[h7l][in2_idxl+T2*2];
      b4=v2sub_shm[h7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal1;
      triplesx_d[h1_1*h1ld_triplesx+h3_0*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal2;
      triplesx_d[h1_2*h1ld_triplesx+h3_0*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal3;
      triplesx_d[h1_3*h1ld_triplesx+h3_0*h3ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal1;
      triplesx_d[h1_1*h1ld_triplesx+h3_0*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal2;
      triplesx_d[h1_2*h1ld_triplesx+h3_0*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal1;
      triplesx_d[h1_1*h1ld_triplesx+h3_0*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_0*p6ld_triplesx]-=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal5;
      triplesx_d[h1_1*h1ld_triplesx+h3_1*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal6;
      triplesx_d[h1_2*h1ld_triplesx+h3_1*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal7;
      triplesx_d[h1_3*h1ld_triplesx+h3_1*h3ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal5;
      triplesx_d[h1_1*h1ld_triplesx+h3_1*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal6;
      triplesx_d[h1_2*h1ld_triplesx+h3_1*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal5;
      triplesx_d[h1_1*h1ld_triplesx+h3_1*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_1*p6ld_triplesx]-=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal9;
      triplesx_d[h1_1*h1ld_triplesx+h3_2*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal10;
      triplesx_d[h1_2*h1ld_triplesx+h3_2*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal11;
      triplesx_d[h1_3*h1ld_triplesx+h3_2*h3ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal9;
      triplesx_d[h1_1*h1ld_triplesx+h3_2*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal10;
      triplesx_d[h1_2*h1ld_triplesx+h3_2*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal9;
      triplesx_d[h1_1*h1ld_triplesx+h3_2*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_2*p6ld_triplesx]-=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal13;
      triplesx_d[h1_1*h1ld_triplesx+h3_3*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal14;
      triplesx_d[h1_2*h1ld_triplesx+h3_3*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal15;
      triplesx_d[h1_3*h1ld_triplesx+h3_3*h3ld_triplesx+p5_3*p5ld_triplesx+p4_3*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal13;
      triplesx_d[h1_1*h1ld_triplesx+h3_3*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal14;
      triplesx_d[h1_2*h1ld_triplesx+h3_3*h3ld_triplesx+p5_2*p5ld_triplesx+p4_2*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal13;
      triplesx_d[h1_1*h1ld_triplesx+h3_3*h3ld_triplesx+p5_1*p5ld_triplesx+p4_1*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p4_0*p4ld_triplesx+p6_3*p6ld_triplesx]-=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d1_6_cuda(size_t h1d, size_t h2d, size_t h3d, size_t h7d, size_t p4d, size_t p5d, size_t p6d, double *triplesx, double *t2sub, double *v2sub) {
  h3d=h3d*h2d;
  size_t h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,p6ld_v2sub,h7ld_v2sub,h1ld_triplesx,h3ld_triplesx,p5ld_triplesx,p4ld_triplesx,p6ld_triplesx;
  size_t /*size_triplesx,size_block_triplesx,size_el_block_triplesx,*/size_t2sub,size_v2sub;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2sub_d,*v2sub_d;
  //size_triplesx=h1d*h3d*p5d*p4d*p6d*sizeof(double);
  size_t2sub=h7d*p4d*p5d*h1d*sizeof(double);
  size_v2sub=h3d*p6d*h7d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d1_6_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_triplesx=size_triplesx/nstreams;
  //size_el_block_triplesx=size_block_triplesx/sizeof(double);
  t2sub_d=(double*)getGpuMem(size_t2sub);
  v2sub_d=(double*)getGpuMem(size_v2sub);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2sub_d,t2sub,size_t2sub,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2sub_d,v2sub,size_v2sub,cudaMemcpyHostToDevice));
  h7ld_t2sub=1;
  p4ld_t2sub=h7d;
  p5ld_t2sub=p4d*h7d;
  h1ld_t2sub=p5d*p4d*h7d;
  h3ld_v2sub=1;
  p6ld_v2sub=h3d;
  h7ld_v2sub=p6d*h3d;
  h1ld_triplesx=1;
  h3ld_triplesx=h1d;
  p5ld_triplesx=h3d*h1d;
  p4ld_triplesx=p5d*h3d*h1d;
  p6ld_triplesx=p4d*p5d*h3d*h1d;
  size_t total_x = h3d*p6d*1;
  size_t total_y = p4d*p5d*h1d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d1_6_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h3d,h7d,p4d,p5d,p6d,h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,p6ld_v2sub,h7ld_v2sub,h1ld_triplesx,h3ld_triplesx,p5ld_triplesx,p4ld_triplesx,p6ld_triplesx,t3_d,t2sub_d,v2sub_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  freeGpuMem(t2sub_d);
  freeGpuMem(v2sub_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d1_6_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* h7d, Integer* p4d, Integer* p5d, Integer* p6d, double *triplesx, double *t2sub, double *v2sub) {
  sd_t_d1_6_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*h7d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,triplesx,t2sub,v2sub);
}
/*----------------------------------------------------------------------*
 *triplesx[h3,h1,p5,p6,p4] += t2sub[h7,p4,p5,h1] * v2sub[h3,p6,h7]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d1_7_kernel(size_t h1d,size_t h3d,size_t h7d,size_t p4d,size_t p5d,size_t p6d,size_t h7ld_t2sub,size_t p4ld_t2sub,size_t p5ld_t2sub,size_t h1ld_t2sub,size_t h3ld_v2sub,size_t p6ld_v2sub,size_t h7ld_v2sub,size_t h3ld_triplesx,size_t h1ld_triplesx,size_t p5ld_triplesx,size_t p6ld_triplesx,size_t p4ld_triplesx,double *triplesx_d, double *t2sub_d, double *v2sub_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h3_0,h3_1,h3_2,h3_3,h7,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,h7l,h7T;
  __shared__ double t2sub_shm[4*T1][Tcomm];
  __shared__ double v2sub_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_0=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_0=rest_y;
  p6_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_1=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_1=rest_y;
  p6_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_2=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_2=rest_y;
  p6_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p5_3=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_3=rest_y;
  p6_3=rest_x;
  size_t t2sub_d_off, v2sub_d_off;for(h7T=0;h7T<h7d;h7T+=Tcomm){size_t h7l_hi;
    h7l_hi = TG_MIN(Tcomm+h7T,h7d)-h7T;
    t2sub_d_off=p4_0*p4ld_t2sub+p5_0*p5ld_t2sub+h1_0*h1ld_t2sub;
    v2sub_d_off=h3_0*h3ld_v2sub+p6_0*p6ld_v2sub;
    if(thread_y+T1*0<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*0][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*0<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*0] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_1*p4ld_t2sub+p5_1*p5ld_t2sub+h1_1*h1ld_t2sub;
    v2sub_d_off=h3_1*h3ld_v2sub+p6_1*p6ld_v2sub;
    if(thread_y+T1*1<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*1][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*1<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*1] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_2*p4ld_t2sub+p5_2*p5ld_t2sub+h1_2*h1ld_t2sub;
    v2sub_d_off=h3_2*h3ld_v2sub+p6_2*p6ld_v2sub;
    if(thread_y+T1*2<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*2][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*2<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*2] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_3*p4ld_t2sub+p5_3*p5ld_t2sub+h1_3*h1ld_t2sub;
    v2sub_d_off=h3_3*h3ld_v2sub+p6_3*p6ld_v2sub;
    if(thread_y+T1*3<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*3][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*3<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*3] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    __syncthreads();
    for(h7l=0;h7l<h7l_hi;++h7l){
      a1=t2sub_shm[in1_idxl+T1*0][h7l];
      a2=t2sub_shm[in1_idxl+T1*1][h7l];
      a3=t2sub_shm[in1_idxl+T1*2][h7l];
      a4=t2sub_shm[in1_idxl+T1*3][h7l];
      b1=v2sub_shm[h7l][in2_idxl+T2*0];
      b2=v2sub_shm[h7l][in2_idxl+T2*1];
      b3=v2sub_shm[h7l][in2_idxl+T2*2];
      b4=v2sub_shm[h7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_0*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p6_0*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal3;
      triplesx_d[h3_0*h3ld_triplesx+h1_3*h1ld_triplesx+p5_3*p5ld_triplesx+p6_0*p6ld_triplesx+p4_3*p4ld_triplesx]+=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_0*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p6_0*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_0*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_1*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p6_1*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal7;
      triplesx_d[h3_1*h3ld_triplesx+h1_3*h1ld_triplesx+p5_3*p5ld_triplesx+p6_1*p6ld_triplesx+p4_3*p4ld_triplesx]+=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_1*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p6_1*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_1*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_2*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p6_2*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal11;
      triplesx_d[h3_2*h3ld_triplesx+h1_3*h1ld_triplesx+p5_3*p5ld_triplesx+p6_2*p6ld_triplesx+p4_3*p4ld_triplesx]+=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_2*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p6_2*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_2*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_3*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p6_3*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal15;
      triplesx_d[h3_3*h3ld_triplesx+h1_3*h1ld_triplesx+p5_3*p5ld_triplesx+p6_3*p6ld_triplesx+p4_3*p4ld_triplesx]+=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_3*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+p5_2*p5ld_triplesx+p6_3*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+p5_1*p5ld_triplesx+p6_3*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d1_7_cuda(size_t h1d, size_t h2d, size_t h3d, size_t h7d, size_t p4d, size_t p5d, size_t p6d, double *triplesx, double *t2sub, double *v2sub) {
  h3d=h3d*h2d;
  size_t h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,p6ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,p5ld_triplesx,p6ld_triplesx,p4ld_triplesx;
  size_t /*size_triplesx,size_block_triplesx,size_el_block_triplesx,*/size_t2sub,size_v2sub;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2sub_d,*v2sub_d;
  //size_triplesx=h3d*h1d*p5d*p6d*p4d*sizeof(double);
  size_t2sub=h7d*p4d*p5d*h1d*sizeof(double);
  size_v2sub=h3d*p6d*h7d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d1_7_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_triplesx=size_triplesx/nstreams;
  //size_el_block_triplesx=size_block_triplesx/sizeof(double);
  t2sub_d=(double*)getGpuMem(size_t2sub);
  v2sub_d=(double*)getGpuMem(size_v2sub);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2sub_d,t2sub,size_t2sub,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2sub_d,v2sub,size_v2sub,cudaMemcpyHostToDevice));
  h7ld_t2sub=1;
  p4ld_t2sub=h7d;
  p5ld_t2sub=p4d*h7d;
  h1ld_t2sub=p5d*p4d*h7d;
  h3ld_v2sub=1;
  p6ld_v2sub=h3d;
  h7ld_v2sub=p6d*h3d;
  h3ld_triplesx=1;
  h1ld_triplesx=h3d;
  p5ld_triplesx=h1d*h3d;
  p6ld_triplesx=p5d*h1d*h3d;
  p4ld_triplesx=p6d*p5d*h1d*h3d;
  size_t total_x = h3d*p6d*1;
  size_t total_y = p4d*p5d*h1d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d1_7_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h3d,h7d,p4d,p5d,p6d,h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,p6ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,p5ld_triplesx,p6ld_triplesx,p4ld_triplesx,t3_d,t2sub_d,v2sub_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  freeGpuMem(t2sub_d);
  freeGpuMem(v2sub_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d1_7_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* h7d, Integer* p4d, Integer* p5d, Integer* p6d, double *triplesx, double *t2sub, double *v2sub) {
  sd_t_d1_7_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*h7d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,triplesx,t2sub,v2sub);
}
/*----------------------------------------------------------------------*
 *triplesx[h3,h1,h2,p5,p6,p4] -= t2sub[h7,p4,p5,h1] * v2sub[h3,h2,p6,h7]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d1_8_kernel(size_t h1d,size_t h2d,size_t h3d,size_t h7d,size_t p4d,size_t p5d,size_t p6d,size_t h7ld_t2sub,size_t p4ld_t2sub,size_t p5ld_t2sub,size_t h1ld_t2sub,size_t h3ld_v2sub,size_t h2ld_v2sub,size_t p6ld_v2sub,size_t h7ld_v2sub,size_t h3ld_triplesx,size_t h1ld_triplesx,size_t h2ld_triplesx,size_t p5ld_triplesx,size_t p6ld_triplesx,size_t p4ld_triplesx,double *triplesx_d, double *t2sub_d, double *v2sub_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,h7,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,h7l,h7T;
  __shared__ double t2sub_shm[4*T1][Tcomm];
  __shared__ double v2sub_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  h2_0=rest_x%h2d;
  rest_x=rest_x/h2d;
  p5_0=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_0=rest_y;
  p6_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  h2_1=rest_x%h2d;
  rest_x=rest_x/h2d;
  p5_1=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_1=rest_y;
  p6_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  h2_2=rest_x%h2d;
  rest_x=rest_x/h2d;
  p5_2=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_2=rest_y;
  p6_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  h2_3=rest_x%h2d;
  rest_x=rest_x/h2d;
  p5_3=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_3=rest_y;
  p6_3=rest_x;
  size_t t2sub_d_off, v2sub_d_off;for(h7T=0;h7T<h7d;h7T+=Tcomm){size_t h7l_hi;
    h7l_hi = TG_MIN(Tcomm+h7T,h7d)-h7T;
    t2sub_d_off=p4_0*p4ld_t2sub+p5_0*p5ld_t2sub+h1_0*h1ld_t2sub;
    v2sub_d_off=h3_0*h3ld_v2sub+h2_0*h2ld_v2sub+p6_0*p6ld_v2sub;
    if(thread_y+T1*0<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*0][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*0<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*0] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_1*p4ld_t2sub+p5_1*p5ld_t2sub+h1_1*h1ld_t2sub;
    v2sub_d_off=h3_1*h3ld_v2sub+h2_1*h2ld_v2sub+p6_1*p6ld_v2sub;
    if(thread_y+T1*1<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*1][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*1<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*1] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_2*p4ld_t2sub+p5_2*p5ld_t2sub+h1_2*h1ld_t2sub;
    v2sub_d_off=h3_2*h3ld_v2sub+h2_2*h2ld_v2sub+p6_2*p6ld_v2sub;
    if(thread_y+T1*2<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*2][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*2<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*2] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_3*p4ld_t2sub+p5_3*p5ld_t2sub+h1_3*h1ld_t2sub;
    v2sub_d_off=h3_3*h3ld_v2sub+h2_3*h2ld_v2sub+p6_3*p6ld_v2sub;
    if(thread_y+T1*3<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*3][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*3<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*3] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    __syncthreads();
    for(h7l=0;h7l<h7l_hi;++h7l){
      a1=t2sub_shm[in1_idxl+T1*0][h7l];
      a2=t2sub_shm[in1_idxl+T1*1][h7l];
      a3=t2sub_shm[in1_idxl+T1*2][h7l];
      a4=t2sub_shm[in1_idxl+T1*3][h7l];
      b1=v2sub_shm[h7l][in2_idxl+T2*0];
      b2=v2sub_shm[h7l][in2_idxl+T2*1];
      b3=v2sub_shm[h7l][in2_idxl+T2*2];
      b4=v2sub_shm[h7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+h2_0*h2ld_triplesx+p5_1*p5ld_triplesx+p6_0*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+h2_0*h2ld_triplesx+p5_2*p5ld_triplesx+p6_0*p6ld_triplesx+p4_2*p4ld_triplesx]-=tlocal3;
      triplesx_d[h3_0*h3ld_triplesx+h1_3*h1ld_triplesx+h2_0*h2ld_triplesx+p5_3*p5ld_triplesx+p6_0*p6ld_triplesx+p4_3*p4ld_triplesx]-=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+h2_0*h2ld_triplesx+p5_1*p5ld_triplesx+p6_0*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal2;
      triplesx_d[h3_0*h3ld_triplesx+h1_2*h1ld_triplesx+h2_0*h2ld_triplesx+p5_2*p5ld_triplesx+p6_0*p6ld_triplesx+p4_2*p4ld_triplesx]-=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
      triplesx_d[h3_0*h3ld_triplesx+h1_1*h1ld_triplesx+h2_0*h2ld_triplesx+p5_1*p5ld_triplesx+p6_0*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_0*h3ld_triplesx+h1_0*h1ld_triplesx+h2_0*h2ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+h2_1*h2ld_triplesx+p5_1*p5ld_triplesx+p6_1*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+h2_1*h2ld_triplesx+p5_2*p5ld_triplesx+p6_1*p6ld_triplesx+p4_2*p4ld_triplesx]-=tlocal7;
      triplesx_d[h3_1*h3ld_triplesx+h1_3*h1ld_triplesx+h2_1*h2ld_triplesx+p5_3*p5ld_triplesx+p6_1*p6ld_triplesx+p4_3*p4ld_triplesx]-=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+h2_1*h2ld_triplesx+p5_1*p5ld_triplesx+p6_1*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal6;
      triplesx_d[h3_1*h3ld_triplesx+h1_2*h1ld_triplesx+h2_1*h2ld_triplesx+p5_2*p5ld_triplesx+p6_1*p6ld_triplesx+p4_2*p4ld_triplesx]-=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
      triplesx_d[h3_1*h3ld_triplesx+h1_1*h1ld_triplesx+h2_1*h2ld_triplesx+p5_1*p5ld_triplesx+p6_1*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_1*h3ld_triplesx+h1_0*h1ld_triplesx+h2_1*h2ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+h2_2*h2ld_triplesx+p5_1*p5ld_triplesx+p6_2*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+h2_2*h2ld_triplesx+p5_2*p5ld_triplesx+p6_2*p6ld_triplesx+p4_2*p4ld_triplesx]-=tlocal11;
      triplesx_d[h3_2*h3ld_triplesx+h1_3*h1ld_triplesx+h2_2*h2ld_triplesx+p5_3*p5ld_triplesx+p6_2*p6ld_triplesx+p4_3*p4ld_triplesx]-=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+h2_2*h2ld_triplesx+p5_1*p5ld_triplesx+p6_2*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal10;
      triplesx_d[h3_2*h3ld_triplesx+h1_2*h1ld_triplesx+h2_2*h2ld_triplesx+p5_2*p5ld_triplesx+p6_2*p6ld_triplesx+p4_2*p4ld_triplesx]-=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
      triplesx_d[h3_2*h3ld_triplesx+h1_1*h1ld_triplesx+h2_2*h2ld_triplesx+p5_1*p5ld_triplesx+p6_2*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_2*h3ld_triplesx+h1_0*h1ld_triplesx+h2_2*h2ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+h2_3*h2ld_triplesx+p5_1*p5ld_triplesx+p6_3*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+h2_3*h2ld_triplesx+p5_2*p5ld_triplesx+p6_3*p6ld_triplesx+p4_2*p4ld_triplesx]-=tlocal15;
      triplesx_d[h3_3*h3ld_triplesx+h1_3*h1ld_triplesx+h2_3*h2ld_triplesx+p5_3*p5ld_triplesx+p6_3*p6ld_triplesx+p4_3*p4ld_triplesx]-=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+h2_3*h2ld_triplesx+p5_1*p5ld_triplesx+p6_3*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal14;
      triplesx_d[h3_3*h3ld_triplesx+h1_2*h1ld_triplesx+h2_3*h2ld_triplesx+p5_2*p5ld_triplesx+p6_3*p6ld_triplesx+p4_2*p4ld_triplesx]-=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
      triplesx_d[h3_3*h3ld_triplesx+h1_1*h1ld_triplesx+h2_3*h2ld_triplesx+p5_1*p5ld_triplesx+p6_3*p6ld_triplesx+p4_1*p4ld_triplesx]-=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h3_3*h3ld_triplesx+h1_0*h1ld_triplesx+h2_3*h2ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]-=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d1_8_cuda(size_t h1d, size_t h2d, size_t h3d, size_t h7d, size_t p4d, size_t p5d, size_t p6d, double *triplesx, double *t2sub, double *v2sub) {
  size_t h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,h2ld_v2sub,p6ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,h2ld_triplesx,p5ld_triplesx,p6ld_triplesx,p4ld_triplesx;
  size_t /*size_triplesx,size_block_triplesx,size_el_block_triplesx,*/size_t2sub,size_v2sub;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2sub_d,*v2sub_d;
  //size_triplesx=h3d*h1d*h2d*p5d*p6d*p4d*sizeof(double);
  size_t2sub=h7d*p4d*p5d*h1d*sizeof(double);
  size_v2sub=h3d*h2d*p6d*h7d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d1_8_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_triplesx=size_triplesx/nstreams;
  //size_el_block_triplesx=size_block_triplesx/sizeof(double);
  t2sub_d=(double*)getGpuMem(size_t2sub);
  v2sub_d=(double*)getGpuMem(size_v2sub);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2sub_d,t2sub,size_t2sub,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2sub_d,v2sub,size_v2sub,cudaMemcpyHostToDevice));
  h7ld_t2sub=1;
  p4ld_t2sub=h7d;
  p5ld_t2sub=p4d*h7d;
  h1ld_t2sub=p5d*p4d*h7d;
  h3ld_v2sub=1;
  h2ld_v2sub=h3d;
  p6ld_v2sub=h2d*h3d;
  h7ld_v2sub=p6d*h2d*h3d;
  h3ld_triplesx=1;
  h1ld_triplesx=h3d;
  h2ld_triplesx=h1d*h3d;
  p5ld_triplesx=h2d*h1d*h3d;
  p6ld_triplesx=p5d*h2d*h1d*h3d;
  p4ld_triplesx=p6d*p5d*h2d*h1d*h3d;
  size_t total_x = h3d*h2d*p6d*1;
  size_t total_y = p4d*p5d*h1d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d1_8_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,h7d,p4d,p5d,p6d,h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,h2ld_v2sub,p6ld_v2sub,h7ld_v2sub,h3ld_triplesx,h1ld_triplesx,h2ld_triplesx,p5ld_triplesx,p6ld_triplesx,p4ld_triplesx,t3_d,t2sub_d,v2sub_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  freeGpuMem(t2sub_d);
  freeGpuMem(v2sub_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d1_8_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* h7d, Integer* p4d, Integer* p5d, Integer* p6d, double *triplesx, double *t2sub, double *v2sub) {
  sd_t_d1_8_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*h7d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,triplesx,t2sub,v2sub);
}
/*----------------------------------------------------------------------*
 *triplesx[h1,h3,p5,p6,p4] += t2sub[h7,p4,p5,h1] * v2sub[h3,p6,h7]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d1_9_kernel(size_t h1d,size_t h3d,size_t h7d,size_t p4d,size_t p5d,size_t p6d,size_t h7ld_t2sub,size_t p4ld_t2sub,size_t p5ld_t2sub,size_t h1ld_t2sub,size_t h3ld_v2sub,size_t p6ld_v2sub,size_t h7ld_v2sub,size_t h1ld_triplesx,size_t h3ld_triplesx,size_t p5ld_triplesx,size_t p6ld_triplesx,size_t p4ld_triplesx,double *triplesx_d, double *t2sub_d, double *v2sub_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h3_0,h3_1,h3_2,h3_3,h7,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,h7l,h7T;
  __shared__ double t2sub_shm[4*T1][Tcomm];
  __shared__ double v2sub_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  p5_0=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_0=rest_y;
  p6_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  p5_1=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_1=rest_y;
  p6_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  p5_2=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_2=rest_y;
  p6_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  p5_3=rest_y%p5d;
  rest_y=rest_y/p5d;
  p4_3=rest_y;
  p6_3=rest_x;
  size_t t2sub_d_off, v2sub_d_off;for(h7T=0;h7T<h7d;h7T+=Tcomm){size_t h7l_hi;
    h7l_hi = TG_MIN(Tcomm+h7T,h7d)-h7T;
    t2sub_d_off=p4_0*p4ld_t2sub+p5_0*p5ld_t2sub+h1_0*h1ld_t2sub;
    v2sub_d_off=h3_0*h3ld_v2sub+p6_0*p6ld_v2sub;
    if(thread_y+T1*0<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*0][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*0<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*0] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_1*p4ld_t2sub+p5_1*p5ld_t2sub+h1_1*h1ld_t2sub;
    v2sub_d_off=h3_1*h3ld_v2sub+p6_1*p6ld_v2sub;
    if(thread_y+T1*1<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*1][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*1<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*1] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_2*p4ld_t2sub+p5_2*p5ld_t2sub+h1_2*h1ld_t2sub;
    v2sub_d_off=h3_2*h3ld_v2sub+p6_2*p6ld_v2sub;
    if(thread_y+T1*2<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*2][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*2<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*2] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    t2sub_d_off=p4_3*p4ld_t2sub+p5_3*p5ld_t2sub+h1_3*h1ld_t2sub;
    v2sub_d_off=h3_3*h3ld_v2sub+p6_3*p6ld_v2sub;
    if(thread_y+T1*3<total_y)for(h7l=threadIdx.x;h7l<h7l_hi;h7l+=blockDim.x){
	h7=h7l+h7T;
	t2sub_shm[in1_idxl+T1*3][h7l] = t2sub_d[t2sub_d_off+h7*h7ld_t2sub];
      }
    if(thread_x+T1*3<total_x)for(h7l=threadIdx.y;h7l<h7l_hi;h7l+=blockDim.y){
	h7=h7l+h7T;
	v2sub_shm[h7l][in2_idxl+T1*3] = v2sub_d[v2sub_d_off+h7*h7ld_v2sub];
      }
    __syncthreads();
    for(h7l=0;h7l<h7l_hi;++h7l){
      a1=t2sub_shm[in1_idxl+T1*0][h7l];
      a2=t2sub_shm[in1_idxl+T1*1][h7l];
      a3=t2sub_shm[in1_idxl+T1*2][h7l];
      a4=t2sub_shm[in1_idxl+T1*3][h7l];
      b1=v2sub_shm[h7l][in2_idxl+T2*0];
      b2=v2sub_shm[h7l][in2_idxl+T2*1];
      b3=v2sub_shm[h7l][in2_idxl+T2*2];
      b4=v2sub_shm[h7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
      triplesx_d[h1_1*h1ld_triplesx+h3_0*h3ld_triplesx+p5_1*p5ld_triplesx+p6_0*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal2;
      triplesx_d[h1_2*h1ld_triplesx+h3_0*h3ld_triplesx+p5_2*p5ld_triplesx+p6_0*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal3;
      triplesx_d[h1_3*h1ld_triplesx+h3_0*h3ld_triplesx+p5_3*p5ld_triplesx+p6_0*p6ld_triplesx+p4_3*p4ld_triplesx]+=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
      triplesx_d[h1_1*h1ld_triplesx+h3_0*h3ld_triplesx+p5_1*p5ld_triplesx+p6_0*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal2;
      triplesx_d[h1_2*h1ld_triplesx+h3_0*h3ld_triplesx+p5_2*p5ld_triplesx+p6_0*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
      triplesx_d[h1_1*h1ld_triplesx+h3_0*h3ld_triplesx+p5_1*p5ld_triplesx+p6_0*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_0*h3ld_triplesx+p5_0*p5ld_triplesx+p6_0*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
      triplesx_d[h1_1*h1ld_triplesx+h3_1*h3ld_triplesx+p5_1*p5ld_triplesx+p6_1*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal6;
      triplesx_d[h1_2*h1ld_triplesx+h3_1*h3ld_triplesx+p5_2*p5ld_triplesx+p6_1*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal7;
      triplesx_d[h1_3*h1ld_triplesx+h3_1*h3ld_triplesx+p5_3*p5ld_triplesx+p6_1*p6ld_triplesx+p4_3*p4ld_triplesx]+=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
      triplesx_d[h1_1*h1ld_triplesx+h3_1*h3ld_triplesx+p5_1*p5ld_triplesx+p6_1*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal6;
      triplesx_d[h1_2*h1ld_triplesx+h3_1*h3ld_triplesx+p5_2*p5ld_triplesx+p6_1*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
      triplesx_d[h1_1*h1ld_triplesx+h3_1*h3ld_triplesx+p5_1*p5ld_triplesx+p6_1*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_1*h3ld_triplesx+p5_0*p5ld_triplesx+p6_1*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
      triplesx_d[h1_1*h1ld_triplesx+h3_2*h3ld_triplesx+p5_1*p5ld_triplesx+p6_2*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal10;
      triplesx_d[h1_2*h1ld_triplesx+h3_2*h3ld_triplesx+p5_2*p5ld_triplesx+p6_2*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal11;
      triplesx_d[h1_3*h1ld_triplesx+h3_2*h3ld_triplesx+p5_3*p5ld_triplesx+p6_2*p6ld_triplesx+p4_3*p4ld_triplesx]+=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
      triplesx_d[h1_1*h1ld_triplesx+h3_2*h3ld_triplesx+p5_1*p5ld_triplesx+p6_2*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal10;
      triplesx_d[h1_2*h1ld_triplesx+h3_2*h3ld_triplesx+p5_2*p5ld_triplesx+p6_2*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
      triplesx_d[h1_1*h1ld_triplesx+h3_2*h3ld_triplesx+p5_1*p5ld_triplesx+p6_2*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_2*h3ld_triplesx+p5_0*p5ld_triplesx+p6_2*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
      triplesx_d[h1_1*h1ld_triplesx+h3_3*h3ld_triplesx+p5_1*p5ld_triplesx+p6_3*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal14;
      triplesx_d[h1_2*h1ld_triplesx+h3_3*h3ld_triplesx+p5_2*p5ld_triplesx+p6_3*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal15;
      triplesx_d[h1_3*h1ld_triplesx+h3_3*h3ld_triplesx+p5_3*p5ld_triplesx+p6_3*p6ld_triplesx+p4_3*p4ld_triplesx]+=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
      triplesx_d[h1_1*h1ld_triplesx+h3_3*h3ld_triplesx+p5_1*p5ld_triplesx+p6_3*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal14;
      triplesx_d[h1_2*h1ld_triplesx+h3_3*h3ld_triplesx+p5_2*p5ld_triplesx+p6_3*p6ld_triplesx+p4_2*p4ld_triplesx]+=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
      triplesx_d[h1_1*h1ld_triplesx+h3_3*h3ld_triplesx+p5_1*p5ld_triplesx+p6_3*p6ld_triplesx+p4_1*p4ld_triplesx]+=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      triplesx_d[h1_0*h1ld_triplesx+h3_3*h3ld_triplesx+p5_0*p5ld_triplesx+p6_3*p6ld_triplesx+p4_0*p4ld_triplesx]+=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d1_9_cuda(size_t h1d, size_t h2d, size_t h3d, size_t h7d, size_t p4d, size_t p5d, size_t p6d, double *triplesx, double *t2sub, double *v2sub) {
  h3d=h3d*h2d;
  size_t h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,p6ld_v2sub,h7ld_v2sub,h1ld_triplesx,h3ld_triplesx,p5ld_triplesx,p6ld_triplesx,p4ld_triplesx;
  size_t /*size_triplesx,size_block_triplesx,size_el_block_triplesx,*/size_t2sub,size_v2sub;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2sub_d,*v2sub_d;
  //size_triplesx=h1d*h3d*p5d*p6d*p4d*sizeof(double);
  size_t2sub=h7d*p4d*p5d*h1d*sizeof(double);
  size_v2sub=h3d*p6d*h7d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d1_9_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_triplesx=size_triplesx/nstreams;
  //size_el_block_triplesx=size_block_triplesx/sizeof(double);
  t2sub_d=(double*)getGpuMem(size_t2sub);
  v2sub_d=(double*)getGpuMem(size_v2sub);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2sub_d,t2sub,size_t2sub,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2sub_d,v2sub,size_v2sub,cudaMemcpyHostToDevice));
  h7ld_t2sub=1;
  p4ld_t2sub=h7d;
  p5ld_t2sub=p4d*h7d;
  h1ld_t2sub=p5d*p4d*h7d;
  h3ld_v2sub=1;
  p6ld_v2sub=h3d;
  h7ld_v2sub=p6d*h3d;
  h1ld_triplesx=1;
  h3ld_triplesx=h1d;
  p5ld_triplesx=h3d*h1d;
  p6ld_triplesx=p5d*h3d*h1d;
  p4ld_triplesx=p6d*p5d*h3d*h1d;
  size_t total_x = h3d*p6d*1;
  size_t total_y = p4d*p5d*h1d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d1_9_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h3d,h7d,p4d,p5d,p6d,h7ld_t2sub,p4ld_t2sub,p5ld_t2sub,h1ld_t2sub,h3ld_v2sub,p6ld_v2sub,h7ld_v2sub,h1ld_triplesx,h3ld_triplesx,p5ld_triplesx,p6ld_triplesx,p4ld_triplesx,t3_d,t2sub_d,v2sub_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  freeGpuMem(t2sub_d);
  freeGpuMem(v2sub_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d1_9_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* h7d, Integer* p4d, Integer* p5d, Integer* p6d, double *triplesx, double *t2sub, double *v2sub) {
  sd_t_d1_9_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*h7d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,triplesx,t2sub,v2sub);
}

/*----------------------------------------------------------------------*
 *t3[h3,h2,h1,p6,p4] -= t2[p7,p4,h1,h2] * v2[p7,h3,p6]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d2_1_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p6d,size_t p7d,size_t p7ld_t2,size_t p4ld_t2,size_t h1ld_t2,size_t h2ld_t2,size_t p7ld_v2,size_t h3ld_v2,size_t p6ld_v2,size_t h3ld_t3,size_t h2ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p4ld_t3,double *t3d, double *t2_d, double *v2_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,p4_0,p4_1,p4_2,p4_3,p6_0,p6_1,p6_2,p6_3,p7;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,p7l,p7T;
  __shared__ double t2_shm[4*T1][Tcomm];
  __shared__ double v2_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_0=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_0=rest_y;
  p6_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_1=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_1=rest_y;
  p6_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_2=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_2=rest_y;
  p6_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_3=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_3=rest_y;
  p6_3=rest_x;
  size_t t2_d_off, v2_d_off;for(p7T=0;p7T<p7d;p7T+=Tcomm){size_t p7l_hi;
    p7l_hi = TG_MIN(Tcomm+p7T,p7d)-p7T;
    t2_d_off=p4_0*p4ld_t2+h1_0*h1ld_t2+h2_0*h2ld_t2;
    v2_d_off=h3_0*h3ld_v2+p6_0*p6ld_v2;
    if(thread_y+T1*0<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*0][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*0<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*0] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_1*p4ld_t2+h1_1*h1ld_t2+h2_1*h2ld_t2;
    v2_d_off=h3_1*h3ld_v2+p6_1*p6ld_v2;
    if(thread_y+T1*1<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*1][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*1<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*1] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_2*p4ld_t2+h1_2*h1ld_t2+h2_2*h2ld_t2;
    v2_d_off=h3_2*h3ld_v2+p6_2*p6ld_v2;
    if(thread_y+T1*2<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*2][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*2<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*2] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_3*p4ld_t2+h1_3*h1ld_t2+h2_3*h2ld_t2;
    v2_d_off=h3_3*h3ld_v2+p6_3*p6ld_v2;
    if(thread_y+T1*3<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*3][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*3<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*3] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    __syncthreads();
    for(p7l=0;p7l<p7l_hi;++p7l){
      a1=t2_shm[in1_idxl+T1*0][p7l];
      a2=t2_shm[in1_idxl+T1*1][p7l];
      a3=t2_shm[in1_idxl+T1*2][p7l];
      a4=t2_shm[in1_idxl+T1*3][p7l];
      b1=v2_shm[p7l][in2_idxl+T2*0];
      b2=v2_shm[p7l][in2_idxl+T2*1];
      b3=v2_shm[p7l][in2_idxl+T2*2];
      b4=v2_shm[p7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3]-=tlocal1;
      t3d[h3_0*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3]-=tlocal2;
      t3d[h3_0*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_0*p6ld_t3+p4_2*p4ld_t3]-=tlocal3;
      t3d[h3_0*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p6_0*p6ld_t3+p4_3*p4ld_t3]-=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3]-=tlocal1;
      t3d[h3_0*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3]-=tlocal2;
      t3d[h3_0*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_0*p6ld_t3+p4_2*p4ld_t3]-=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3]-=tlocal1;
      t3d[h3_0*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3]-=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3]-=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3]-=tlocal5;
      t3d[h3_1*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3]-=tlocal6;
      t3d[h3_1*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_1*p6ld_t3+p4_2*p4ld_t3]-=tlocal7;
      t3d[h3_1*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p6_1*p6ld_t3+p4_3*p4ld_t3]-=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3]-=tlocal5;
      t3d[h3_1*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3]-=tlocal6;
      t3d[h3_1*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_1*p6ld_t3+p4_2*p4ld_t3]-=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3]-=tlocal5;
      t3d[h3_1*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3]-=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3]-=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3]-=tlocal9;
      t3d[h3_2*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3]-=tlocal10;
      t3d[h3_2*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_2*p6ld_t3+p4_2*p4ld_t3]-=tlocal11;
      t3d[h3_2*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p6_2*p6ld_t3+p4_3*p4ld_t3]-=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3]-=tlocal9;
      t3d[h3_2*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3]-=tlocal10;
      t3d[h3_2*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_2*p6ld_t3+p4_2*p4ld_t3]-=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3]-=tlocal9;
      t3d[h3_2*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3]-=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3]-=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3]-=tlocal13;
      t3d[h3_3*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3]-=tlocal14;
      t3d[h3_3*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_3*p6ld_t3+p4_2*p4ld_t3]-=tlocal15;
      t3d[h3_3*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p6_3*p6ld_t3+p4_3*p4ld_t3]-=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3]-=tlocal13;
      t3d[h3_3*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3]-=tlocal14;
      t3d[h3_3*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_3*p6ld_t3+p4_2*p4ld_t3]-=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3]-=tlocal13;
      t3d[h3_3*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3]-=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3]-=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d2_1_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, size_t p7d, double *t3, double *t2, double *v2) {
  p6d=p6d*p5d;
  size_t p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p4ld_t3;
  size_t /*size_t3,size_block_t3,size_el_block_t3,*/size_t2,size_v2;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2_d,*v2_d;
  //size_t3=h3d*h2d*h1d*p6d*p4d*sizeof(double);
  size_t2=p7d*p4d*h1d*h2d*sizeof(double);
  size_v2=p7d*h3d*p6d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d2_1_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_t3=size_t3/nstreams;
  //size_el_block_t3=size_block_t3/sizeof(double);
  //t3d=(double*)getGpuMem(size_t3);
  t2_d=(double*)getGpuMem(size_t2);
  v2_d=(double*)getGpuMem(size_v2);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2_d,t2,size_t2,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2_d,v2,size_v2,cudaMemcpyHostToDevice));
  p7ld_t2=1;
  p4ld_t2=p7d;
  h1ld_t2=p4d*p7d;
  h2ld_t2=h1d*p4d*p7d;
  p7ld_v2=1;
  h3ld_v2=p7d;
  p6ld_v2=h3d*p7d;
  h3ld_t3=1;
  h2ld_t3=h3d;
  h1ld_t3=h2d*h3d;
  p6ld_t3=h1d*h2d*h3d;
  p4ld_t3=p6d*h1d*h2d*h3d;
  size_t total_x = h3d*p6d;
  size_t total_y = p4d*h1d*h2d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d2_1_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p6d,p7d,p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,t3_d,t2_d,v2_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  //freeGpuMem(t3d);
  freeGpuMem(t2_d);
  freeGpuMem(v2_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d2_1_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* p4d, Integer* p5d, Integer* p6d, Integer* p7d, double *t3, double *t2, double *v2) {
  sd_t_d2_1_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,(size_t)*p7d,t3,t2,v2);
}
/*----------------------------------------------------------------------*
 *t3[h2,h1,h3,p4] -= t2[p7,p4,h1,h2] * v2[p7,h3]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d2_2_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p7d,size_t p7ld_t2,size_t p4ld_t2,size_t h1ld_t2,size_t h2ld_t2,size_t p7ld_v2,size_t h3ld_v2,size_t h2ld_t3,size_t h1ld_t3,size_t h3ld_t3,size_t p4ld_t3,double *t3d, double *t2_d, double *v2_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,p4_0,p4_1,p4_2,p4_3,p7;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,p7l,p7T;
  __shared__ double t2_shm[4*T1][Tcomm];
  __shared__ double v2_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h2_0=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_0=rest_y;
  h3_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h2_1=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_1=rest_y;
  h3_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h2_2=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_2=rest_y;
  h3_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h2_3=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_3=rest_y;
  h3_3=rest_x;
  size_t t2_d_off, v2_d_off;for(p7T=0;p7T<p7d;p7T+=Tcomm){size_t p7l_hi;
    p7l_hi = TG_MIN(Tcomm+p7T,p7d)-p7T;
    t2_d_off=p4_0*p4ld_t2+h1_0*h1ld_t2+h2_0*h2ld_t2;
    v2_d_off=h3_0*h3ld_v2;
    if(thread_y+T1*0<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*0][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*0<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*0] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_1*p4ld_t2+h1_1*h1ld_t2+h2_1*h2ld_t2;
    v2_d_off=h3_1*h3ld_v2;
    if(thread_y+T1*1<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*1][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*1<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*1] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_2*p4ld_t2+h1_2*h1ld_t2+h2_2*h2ld_t2;
    v2_d_off=h3_2*h3ld_v2;
    if(thread_y+T1*2<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*2][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*2<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*2] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_3*p4ld_t2+h1_3*h1ld_t2+h2_3*h2ld_t2;
    v2_d_off=h3_3*h3ld_v2;
    if(thread_y+T1*3<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*3][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*3<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*3] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    __syncthreads();
    for(p7l=0;p7l<p7l_hi;++p7l){
      a1=t2_shm[in1_idxl+T1*0][p7l];
      a2=t2_shm[in1_idxl+T1*1][p7l];
      a3=t2_shm[in1_idxl+T1*2][p7l];
      a4=t2_shm[in1_idxl+T1*3][p7l];
      b1=v2_shm[p7l][in2_idxl+T2*0];
      b2=v2_shm[p7l][in2_idxl+T2*1];
      b3=v2_shm[p7l][in2_idxl+T2*2];
      b4=v2_shm[p7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3]-=tlocal1;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_0*h3ld_t3+p4_1*p4ld_t3]-=tlocal2;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_0*h3ld_t3+p4_2*p4ld_t3]-=tlocal3;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_0*h3ld_t3+p4_3*p4ld_t3]-=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3]-=tlocal1;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_0*h3ld_t3+p4_1*p4ld_t3]-=tlocal2;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_0*h3ld_t3+p4_2*p4ld_t3]-=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3]-=tlocal1;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_0*h3ld_t3+p4_1*p4ld_t3]-=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3]-=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3]-=tlocal5;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_1*h3ld_t3+p4_1*p4ld_t3]-=tlocal6;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_1*h3ld_t3+p4_2*p4ld_t3]-=tlocal7;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_1*h3ld_t3+p4_3*p4ld_t3]-=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3]-=tlocal5;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_1*h3ld_t3+p4_1*p4ld_t3]-=tlocal6;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_1*h3ld_t3+p4_2*p4ld_t3]-=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3]-=tlocal5;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_1*h3ld_t3+p4_1*p4ld_t3]-=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3]-=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3]-=tlocal9;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_2*h3ld_t3+p4_1*p4ld_t3]-=tlocal10;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_2*h3ld_t3+p4_2*p4ld_t3]-=tlocal11;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_2*h3ld_t3+p4_3*p4ld_t3]-=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3]-=tlocal9;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_2*h3ld_t3+p4_1*p4ld_t3]-=tlocal10;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_2*h3ld_t3+p4_2*p4ld_t3]-=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3]-=tlocal9;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_2*h3ld_t3+p4_1*p4ld_t3]-=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3]-=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3]-=tlocal13;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_3*h3ld_t3+p4_1*p4ld_t3]-=tlocal14;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_3*h3ld_t3+p4_2*p4ld_t3]-=tlocal15;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_3*h3ld_t3+p4_3*p4ld_t3]-=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3]-=tlocal13;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_3*h3ld_t3+p4_1*p4ld_t3]-=tlocal14;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_3*h3ld_t3+p4_2*p4ld_t3]-=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3]-=tlocal13;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_3*h3ld_t3+p4_1*p4ld_t3]-=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3]-=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d2_2_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, size_t p7d, double *t3, double *t2, double *v2) {
  h3d=h3d*p6d;
  h3d=h3d*p5d;
  size_t p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,h2ld_t3,h1ld_t3,h3ld_t3,p4ld_t3;
  size_t /*size_t3,size_block_t3,size_el_block_t3,*/size_t2,size_v2;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2_d,*v2_d;
  //size_t3=h2d*h1d*h3d*p4d*sizeof(double);
  size_t2=p7d*p4d*h1d*h2d*sizeof(double);
  size_v2=p7d*h3d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d2_2_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_t3=size_t3/nstreams;
  //size_el_block_t3=size_block_t3/sizeof(double);
  //t3d=(double*)getGpuMem(size_t3);
  t2_d=(double*)getGpuMem(size_t2);
  v2_d=(double*)getGpuMem(size_v2);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2_d,t2,size_t2,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2_d,v2,size_v2,cudaMemcpyHostToDevice));
  p7ld_t2=1;
  p4ld_t2=p7d;
  h1ld_t2=p4d*p7d;
  h2ld_t2=h1d*p4d*p7d;
  p7ld_v2=1;
  h3ld_v2=p7d;
  h2ld_t3=1;
  h1ld_t3=h2d;
  h3ld_t3=h1d*h2d;
  p4ld_t3=h3d*h1d*h2d;
  size_t total_x = h3d;
  size_t total_y = p4d*h1d*h2d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d2_2_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p7d,p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,h2ld_t3,h1ld_t3,h3ld_t3,p4ld_t3,t3_d,t2_d,v2_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  //freeGpuMem(t3d);
  freeGpuMem(t2_d);
  freeGpuMem(v2_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d2_2_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* p4d, Integer* p5d, Integer* p6d, Integer* p7d, double *t3, double *t2, double *v2) {
  sd_t_d2_2_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,(size_t)*p7d,t3,t2,v2);
}
/*----------------------------------------------------------------------*
 *t3[h2,h3,h1,p6,p4] += t2[p7,p4,h1,h2] * v2[p7,h3,p6]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d2_3_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p6d,size_t p7d,size_t p7ld_t2,size_t p4ld_t2,size_t h1ld_t2,size_t h2ld_t2,size_t p7ld_v2,size_t h3ld_v2,size_t p6ld_v2,size_t h2ld_t3,size_t h3ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p4ld_t3,double *t3d, double *t2_d, double *v2_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,p4_0,p4_1,p4_2,p4_3,p6_0,p6_1,p6_2,p6_3,p7;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,p7l,p7T;
  __shared__ double t2_shm[4*T1][Tcomm];
  __shared__ double v2_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h2_0=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_0=rest_y;
  p6_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h2_1=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_1=rest_y;
  p6_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h2_2=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_2=rest_y;
  p6_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h2_3=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p4_3=rest_y;
  p6_3=rest_x;
  size_t t2_d_off, v2_d_off;for(p7T=0;p7T<p7d;p7T+=Tcomm){size_t p7l_hi;
    p7l_hi = TG_MIN(Tcomm+p7T,p7d)-p7T;
    t2_d_off=p4_0*p4ld_t2+h1_0*h1ld_t2+h2_0*h2ld_t2;
    v2_d_off=h3_0*h3ld_v2+p6_0*p6ld_v2;
    if(thread_y+T1*0<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*0][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*0<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*0] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_1*p4ld_t2+h1_1*h1ld_t2+h2_1*h2ld_t2;
    v2_d_off=h3_1*h3ld_v2+p6_1*p6ld_v2;
    if(thread_y+T1*1<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*1][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*1<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*1] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_2*p4ld_t2+h1_2*h1ld_t2+h2_2*h2ld_t2;
    v2_d_off=h3_2*h3ld_v2+p6_2*p6ld_v2;
    if(thread_y+T1*2<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*2][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*2<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*2] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_3*p4ld_t2+h1_3*h1ld_t2+h2_3*h2ld_t2;
    v2_d_off=h3_3*h3ld_v2+p6_3*p6ld_v2;
    if(thread_y+T1*3<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*3][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*3<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*3] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    __syncthreads();
    for(p7l=0;p7l<p7l_hi;++p7l){
      a1=t2_shm[in1_idxl+T1*0][p7l];
      a2=t2_shm[in1_idxl+T1*1][p7l];
      a3=t2_shm[in1_idxl+T1*2][p7l];
      a4=t2_shm[in1_idxl+T1*3][p7l];
      b1=v2_shm[p7l][in2_idxl+T2*0];
      b2=v2_shm[p7l][in2_idxl+T2*1];
      b3=v2_shm[p7l][in2_idxl+T2*2];
      b4=v2_shm[p7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3]+=tlocal1;
      t3d[h2_1*h2ld_t3+h3_0*h3ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3]+=tlocal2;
      t3d[h2_2*h2ld_t3+h3_0*h3ld_t3+h1_2*h1ld_t3+p6_0*p6ld_t3+p4_2*p4ld_t3]+=tlocal3;
      t3d[h2_3*h2ld_t3+h3_0*h3ld_t3+h1_3*h1ld_t3+p6_0*p6ld_t3+p4_3*p4ld_t3]+=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3]+=tlocal1;
      t3d[h2_1*h2ld_t3+h3_0*h3ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3]+=tlocal2;
      t3d[h2_2*h2ld_t3+h3_0*h3ld_t3+h1_2*h1ld_t3+p6_0*p6ld_t3+p4_2*p4ld_t3]+=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3]+=tlocal1;
      t3d[h2_1*h2ld_t3+h3_0*h3ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3]+=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3]+=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3]+=tlocal5;
      t3d[h2_1*h2ld_t3+h3_1*h3ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3]+=tlocal6;
      t3d[h2_2*h2ld_t3+h3_1*h3ld_t3+h1_2*h1ld_t3+p6_1*p6ld_t3+p4_2*p4ld_t3]+=tlocal7;
      t3d[h2_3*h2ld_t3+h3_1*h3ld_t3+h1_3*h1ld_t3+p6_1*p6ld_t3+p4_3*p4ld_t3]+=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3]+=tlocal5;
      t3d[h2_1*h2ld_t3+h3_1*h3ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3]+=tlocal6;
      t3d[h2_2*h2ld_t3+h3_1*h3ld_t3+h1_2*h1ld_t3+p6_1*p6ld_t3+p4_2*p4ld_t3]+=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3]+=tlocal5;
      t3d[h2_1*h2ld_t3+h3_1*h3ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3]+=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3]+=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3]+=tlocal9;
      t3d[h2_1*h2ld_t3+h3_2*h3ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3]+=tlocal10;
      t3d[h2_2*h2ld_t3+h3_2*h3ld_t3+h1_2*h1ld_t3+p6_2*p6ld_t3+p4_2*p4ld_t3]+=tlocal11;
      t3d[h2_3*h2ld_t3+h3_2*h3ld_t3+h1_3*h1ld_t3+p6_2*p6ld_t3+p4_3*p4ld_t3]+=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3]+=tlocal9;
      t3d[h2_1*h2ld_t3+h3_2*h3ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3]+=tlocal10;
      t3d[h2_2*h2ld_t3+h3_2*h3ld_t3+h1_2*h1ld_t3+p6_2*p6ld_t3+p4_2*p4ld_t3]+=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3]+=tlocal9;
      t3d[h2_1*h2ld_t3+h3_2*h3ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3]+=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3]+=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3]+=tlocal13;
      t3d[h2_1*h2ld_t3+h3_3*h3ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3]+=tlocal14;
      t3d[h2_2*h2ld_t3+h3_3*h3ld_t3+h1_2*h1ld_t3+p6_3*p6ld_t3+p4_2*p4ld_t3]+=tlocal15;
      t3d[h2_3*h2ld_t3+h3_3*h3ld_t3+h1_3*h1ld_t3+p6_3*p6ld_t3+p4_3*p4ld_t3]+=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3]+=tlocal13;
      t3d[h2_1*h2ld_t3+h3_3*h3ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3]+=tlocal14;
      t3d[h2_2*h2ld_t3+h3_3*h3ld_t3+h1_2*h1ld_t3+p6_3*p6ld_t3+p4_2*p4ld_t3]+=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3]+=tlocal13;
      t3d[h2_1*h2ld_t3+h3_3*h3ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3]+=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3]+=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d2_3_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, size_t p7d, double *t3, double *t2, double *v2) {
  p6d=p6d*p5d;
  size_t p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,h2ld_t3,h3ld_t3,h1ld_t3,p6ld_t3,p4ld_t3;
  size_t /*size_t3,size_block_t3,size_el_block_t3,*/size_t2,size_v2;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2_d,*v2_d;
  //size_t3=h2d*h3d*h1d*p6d*p4d*sizeof(double);
  size_t2=p7d*p4d*h1d*h2d*sizeof(double);
  size_v2=p7d*h3d*p6d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d2_3_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_t3=size_t3/nstreams;
  //size_el_block_t3=size_block_t3/sizeof(double);
  //t3d=(double*)getGpuMem(size_t3);
  t2_d=(double*)getGpuMem(size_t2);
  v2_d=(double*)getGpuMem(size_v2);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2_d,t2,size_t2,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2_d,v2,size_v2,cudaMemcpyHostToDevice));
  p7ld_t2=1;
  p4ld_t2=p7d;
  h1ld_t2=p4d*p7d;
  h2ld_t2=h1d*p4d*p7d;
  p7ld_v2=1;
  h3ld_v2=p7d;
  p6ld_v2=h3d*p7d;
  h2ld_t3=1;
  h3ld_t3=h2d;
  h1ld_t3=h3d*h2d;
  p6ld_t3=h1d*h3d*h2d;
  p4ld_t3=p6d*h1d*h3d*h2d;
  size_t total_x = h3d*p6d;
  size_t total_y = p4d*h1d*h2d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d2_3_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p6d,p7d,p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,h2ld_t3,h3ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,t3_d,t2_d,v2_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
//  freeGpuMem(t3_d);
  freeGpuMem(t2_d);
  freeGpuMem(v2_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d2_3_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* p4d, Integer* p5d, Integer* p6d, Integer* p7d, double *t3, double *t2, double *v2) {
  sd_t_d2_3_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,(size_t)*p7d,t3,t2,v2);
}
/*----------------------------------------------------------------------*
 *t3[h3,h2,h1,p6,p4,p5] += t2[p7,p4,h1,h2] * v2[p7,h3,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d2_4_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p5d,size_t p6d,size_t p7d,size_t p7ld_t2,size_t p4ld_t2,size_t h1ld_t2,size_t h2ld_t2,size_t p7ld_v2,size_t h3ld_v2,size_t p6ld_v2,size_t p5ld_v2,size_t h3ld_t3,size_t h2ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p4ld_t3,size_t p5ld_t3,double *t3d, double *t2_d, double *v2_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3,p7;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,p7l,p7T;
  __shared__ double t2_shm[4*T1][Tcomm];
  __shared__ double v2_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_0=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_0=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_0=rest_y;
  p5_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_1=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_1=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_1=rest_y;
  p5_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_2=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_2=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_2=rest_y;
  p5_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_3=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_3=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_3=rest_y;
  p5_3=rest_x;
  size_t t2_d_off, v2_d_off;for(p7T=0;p7T<p7d;p7T+=Tcomm){size_t p7l_hi;
    p7l_hi = TG_MIN(Tcomm+p7T,p7d)-p7T;
    t2_d_off=p4_0*p4ld_t2+h1_0*h1ld_t2+h2_0*h2ld_t2;
    v2_d_off=h3_0*h3ld_v2+p6_0*p6ld_v2+p5_0*p5ld_v2;
    if(thread_y+T1*0<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*0][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*0<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*0] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_1*p4ld_t2+h1_1*h1ld_t2+h2_1*h2ld_t2;
    v2_d_off=h3_1*h3ld_v2+p6_1*p6ld_v2+p5_1*p5ld_v2;
    if(thread_y+T1*1<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*1][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*1<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*1] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_2*p4ld_t2+h1_2*h1ld_t2+h2_2*h2ld_t2;
    v2_d_off=h3_2*h3ld_v2+p6_2*p6ld_v2+p5_2*p5ld_v2;
    if(thread_y+T1*2<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*2][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*2<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*2] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_3*p4ld_t2+h1_3*h1ld_t2+h2_3*h2ld_t2;
    v2_d_off=h3_3*h3ld_v2+p6_3*p6ld_v2+p5_3*p5ld_v2;
    if(thread_y+T1*3<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*3][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*3<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*3] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    __syncthreads();
    for(p7l=0;p7l<p7l_hi;++p7l){
      a1=t2_shm[in1_idxl+T1*0][p7l];
      a2=t2_shm[in1_idxl+T1*1][p7l];
      a3=t2_shm[in1_idxl+T1*2][p7l];
      a4=t2_shm[in1_idxl+T1*3][p7l];
      b1=v2_shm[p7l][in2_idxl+T2*0];
      b2=v2_shm[p7l][in2_idxl+T2*1];
      b3=v2_shm[p7l][in2_idxl+T2*2];
      b4=v2_shm[p7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]+=tlocal1;
      t3d[h3_0*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3+p5_0*p5ld_t3]+=tlocal2;
      t3d[h3_0*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_0*p6ld_t3+p4_2*p4ld_t3+p5_0*p5ld_t3]+=tlocal3;
      t3d[h3_0*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p6_0*p6ld_t3+p4_3*p4ld_t3+p5_0*p5ld_t3]+=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]+=tlocal1;
      t3d[h3_0*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3+p5_0*p5ld_t3]+=tlocal2;
      t3d[h3_0*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_0*p6ld_t3+p4_2*p4ld_t3+p5_0*p5ld_t3]+=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]+=tlocal1;
      t3d[h3_0*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3+p5_0*p5ld_t3]+=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]+=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]+=tlocal5;
      t3d[h3_1*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3+p5_1*p5ld_t3]+=tlocal6;
      t3d[h3_1*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_1*p6ld_t3+p4_2*p4ld_t3+p5_1*p5ld_t3]+=tlocal7;
      t3d[h3_1*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p6_1*p6ld_t3+p4_3*p4ld_t3+p5_1*p5ld_t3]+=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]+=tlocal5;
      t3d[h3_1*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3+p5_1*p5ld_t3]+=tlocal6;
      t3d[h3_1*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_1*p6ld_t3+p4_2*p4ld_t3+p5_1*p5ld_t3]+=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]+=tlocal5;
      t3d[h3_1*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3+p5_1*p5ld_t3]+=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]+=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]+=tlocal9;
      t3d[h3_2*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3+p5_2*p5ld_t3]+=tlocal10;
      t3d[h3_2*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_2*p6ld_t3+p4_2*p4ld_t3+p5_2*p5ld_t3]+=tlocal11;
      t3d[h3_2*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p6_2*p6ld_t3+p4_3*p4ld_t3+p5_2*p5ld_t3]+=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]+=tlocal9;
      t3d[h3_2*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3+p5_2*p5ld_t3]+=tlocal10;
      t3d[h3_2*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_2*p6ld_t3+p4_2*p4ld_t3+p5_2*p5ld_t3]+=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]+=tlocal9;
      t3d[h3_2*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3+p5_2*p5ld_t3]+=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]+=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]+=tlocal13;
      t3d[h3_3*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3+p5_3*p5ld_t3]+=tlocal14;
      t3d[h3_3*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_3*p6ld_t3+p4_2*p4ld_t3+p5_3*p5ld_t3]+=tlocal15;
      t3d[h3_3*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p6_3*p6ld_t3+p4_3*p4ld_t3+p5_3*p5ld_t3]+=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]+=tlocal13;
      t3d[h3_3*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3+p5_3*p5ld_t3]+=tlocal14;
      t3d[h3_3*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p6_3*p6ld_t3+p4_2*p4ld_t3+p5_3*p5ld_t3]+=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]+=tlocal13;
      t3d[h3_3*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3+p5_3*p5ld_t3]+=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]+=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d2_4_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, size_t p7d, double *t3, double *t2, double *v2) {
  size_t p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,p5ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,p5ld_t3;
  size_t /*size_t3,size_block_t3,size_el_block_t3,*/size_t2,size_v2;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2_d,*v2_d;
  //size_t3=h3d*h2d*h1d*p6d*p4d*p5d*sizeof(double);
  size_t2=p7d*p4d*h1d*h2d*sizeof(double);
  size_v2=p7d*h3d*p6d*p5d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d2_4_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_t3=size_t3/nstreams;
  //size_el_block_t3=size_block_t3/sizeof(double);
  //t3d=(double*)getGpuMem(size_t3);
  t2_d=(double*)getGpuMem(size_t2);
  v2_d=(double*)getGpuMem(size_v2);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2_d,t2,size_t2,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2_d,v2,size_v2,cudaMemcpyHostToDevice));
  p7ld_t2=1;
  p4ld_t2=p7d;
  h1ld_t2=p4d*p7d;
  h2ld_t2=h1d*p4d*p7d;
  p7ld_v2=1;
  h3ld_v2=p7d;
  p6ld_v2=h3d*p7d;
  p5ld_v2=p6d*h3d*p7d;
  h3ld_t3=1;
  h2ld_t3=h3d;
  h1ld_t3=h2d*h3d;
  p6ld_t3=h1d*h2d*h3d;
  p4ld_t3=p6d*h1d*h2d*h3d;
  p5ld_t3=p4d*p6d*h1d*h2d*h3d;
  size_t total_x = h3d*p6d*p5d;
  size_t total_y = p4d*h1d*h2d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d2_4_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d,p6d,p7d,p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,p5ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,p5ld_t3,t3_d,t2_d,v2_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  //freeGpuMem(t3d);
  freeGpuMem(t2_d);
  freeGpuMem(v2_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d2_4_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* p4d, Integer* p5d, Integer* p6d, Integer* p7d, double *t3, double *t2, double *v2) {
  sd_t_d2_4_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,(size_t)*p7d,t3,t2,v2);
}
/*----------------------------------------------------------------------*
 *t3[h2,h1,h3,p4,p5] += t2[p7,p4,h1,h2] * v2[p7,h3,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d2_5_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p5d,size_t p7d,size_t p7ld_t2,size_t p4ld_t2,size_t h1ld_t2,size_t h2ld_t2,size_t p7ld_v2,size_t h3ld_v2,size_t p5ld_v2,size_t h2ld_t3,size_t h1ld_t3,size_t h3ld_t3,size_t p4ld_t3,size_t p5ld_t3,double *t3d, double *t2_d, double *v2_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p7;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,p7l,p7T;
  __shared__ double t2_shm[4*T1][Tcomm];
  __shared__ double v2_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h2_0=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  p4_0=rest_y;
  p5_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h2_1=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  p4_1=rest_y;
  p5_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h2_2=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  p4_2=rest_y;
  p5_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h2_3=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  p4_3=rest_y;
  p5_3=rest_x;
  size_t t2_d_off, v2_d_off;for(p7T=0;p7T<p7d;p7T+=Tcomm){size_t p7l_hi;
    p7l_hi = TG_MIN(Tcomm+p7T,p7d)-p7T;
    t2_d_off=p4_0*p4ld_t2+h1_0*h1ld_t2+h2_0*h2ld_t2;
    v2_d_off=h3_0*h3ld_v2+p5_0*p5ld_v2;
    if(thread_y+T1*0<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*0][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*0<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*0] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_1*p4ld_t2+h1_1*h1ld_t2+h2_1*h2ld_t2;
    v2_d_off=h3_1*h3ld_v2+p5_1*p5ld_v2;
    if(thread_y+T1*1<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*1][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*1<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*1] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_2*p4ld_t2+h1_2*h1ld_t2+h2_2*h2ld_t2;
    v2_d_off=h3_2*h3ld_v2+p5_2*p5ld_v2;
    if(thread_y+T1*2<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*2][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*2<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*2] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_3*p4ld_t2+h1_3*h1ld_t2+h2_3*h2ld_t2;
    v2_d_off=h3_3*h3ld_v2+p5_3*p5ld_v2;
    if(thread_y+T1*3<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*3][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*3<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*3] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    __syncthreads();
    for(p7l=0;p7l<p7l_hi;++p7l){
      a1=t2_shm[in1_idxl+T1*0][p7l];
      a2=t2_shm[in1_idxl+T1*1][p7l];
      a3=t2_shm[in1_idxl+T1*2][p7l];
      a4=t2_shm[in1_idxl+T1*3][p7l];
      b1=v2_shm[p7l][in2_idxl+T2*0];
      b2=v2_shm[p7l][in2_idxl+T2*1];
      b3=v2_shm[p7l][in2_idxl+T2*2];
      b4=v2_shm[p7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]+=tlocal1;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_0*h3ld_t3+p4_1*p4ld_t3+p5_0*p5ld_t3]+=tlocal2;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_0*h3ld_t3+p4_2*p4ld_t3+p5_0*p5ld_t3]+=tlocal3;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_0*h3ld_t3+p4_3*p4ld_t3+p5_0*p5ld_t3]+=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]+=tlocal1;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_0*h3ld_t3+p4_1*p4ld_t3+p5_0*p5ld_t3]+=tlocal2;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_0*h3ld_t3+p4_2*p4ld_t3+p5_0*p5ld_t3]+=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]+=tlocal1;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_0*h3ld_t3+p4_1*p4ld_t3+p5_0*p5ld_t3]+=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]+=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]+=tlocal5;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_1*h3ld_t3+p4_1*p4ld_t3+p5_1*p5ld_t3]+=tlocal6;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_1*h3ld_t3+p4_2*p4ld_t3+p5_1*p5ld_t3]+=tlocal7;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_1*h3ld_t3+p4_3*p4ld_t3+p5_1*p5ld_t3]+=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]+=tlocal5;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_1*h3ld_t3+p4_1*p4ld_t3+p5_1*p5ld_t3]+=tlocal6;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_1*h3ld_t3+p4_2*p4ld_t3+p5_1*p5ld_t3]+=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]+=tlocal5;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_1*h3ld_t3+p4_1*p4ld_t3+p5_1*p5ld_t3]+=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]+=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]+=tlocal9;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_2*h3ld_t3+p4_1*p4ld_t3+p5_2*p5ld_t3]+=tlocal10;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_2*h3ld_t3+p4_2*p4ld_t3+p5_2*p5ld_t3]+=tlocal11;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_2*h3ld_t3+p4_3*p4ld_t3+p5_2*p5ld_t3]+=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]+=tlocal9;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_2*h3ld_t3+p4_1*p4ld_t3+p5_2*p5ld_t3]+=tlocal10;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_2*h3ld_t3+p4_2*p4ld_t3+p5_2*p5ld_t3]+=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]+=tlocal9;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_2*h3ld_t3+p4_1*p4ld_t3+p5_2*p5ld_t3]+=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]+=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]+=tlocal13;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_3*h3ld_t3+p4_1*p4ld_t3+p5_3*p5ld_t3]+=tlocal14;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_3*h3ld_t3+p4_2*p4ld_t3+p5_3*p5ld_t3]+=tlocal15;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_3*h3ld_t3+p4_3*p4ld_t3+p5_3*p5ld_t3]+=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]+=tlocal13;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_3*h3ld_t3+p4_1*p4ld_t3+p5_3*p5ld_t3]+=tlocal14;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_3*h3ld_t3+p4_2*p4ld_t3+p5_3*p5ld_t3]+=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]+=tlocal13;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_3*h3ld_t3+p4_1*p4ld_t3+p5_3*p5ld_t3]+=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]+=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d2_5_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, size_t p7d, double *t3, double *t2, double *v2) {
  h3d=h3d*p6d;
  size_t p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p5ld_v2,h2ld_t3,h1ld_t3,h3ld_t3,p4ld_t3,p5ld_t3;
  size_t /*size_t3,size_block_t3,size_el_block_t3,*/size_t2,size_v2;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2_d,*v2_d;
  //size_t3=h2d*h1d*h3d*p4d*p5d*sizeof(double);
  size_t2=p7d*p4d*h1d*h2d*sizeof(double);
  size_v2=p7d*h3d*p5d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d2_5_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_t3=size_t3/nstreams;
  //size_el_block_t3=size_block_t3/sizeof(double);
  //t3d=(double*)getGpuMem(size_t3);
  t2_d=(double*)getGpuMem(size_t2);
  v2_d=(double*)getGpuMem(size_v2);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2_d,t2,size_t2,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2_d,v2,size_v2,cudaMemcpyHostToDevice));
  p7ld_t2=1;
  p4ld_t2=p7d;
  h1ld_t2=p4d*p7d;
  h2ld_t2=h1d*p4d*p7d;
  p7ld_v2=1;
  h3ld_v2=p7d;
  p5ld_v2=h3d*p7d;
  h2ld_t3=1;
  h1ld_t3=h2d;
  h3ld_t3=h1d*h2d;
  p4ld_t3=h3d*h1d*h2d;
  p5ld_t3=p4d*h3d*h1d*h2d;
  size_t total_x = h3d*p5d;
  size_t total_y = p4d*h1d*h2d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d2_5_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d,p7d,p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p5ld_v2,h2ld_t3,h1ld_t3,h3ld_t3,p4ld_t3,p5ld_t3,t3_d,t2_d,v2_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  //freeGpuMem(t3d);
  freeGpuMem(t2_d);
  freeGpuMem(v2_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d2_5_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* p4d, Integer* p5d, Integer* p6d, Integer* p7d, double *t3, double *t2, double *v2) {
  sd_t_d2_5_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,(size_t)*p7d,t3,t2,v2);
}
/*----------------------------------------------------------------------*
 *t3[h2,h3,h1,p6,p4,p5] -= t2[p7,p4,h1,h2] * v2[p7,h3,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d2_6_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p5d,size_t p6d,size_t p7d,size_t p7ld_t2,size_t p4ld_t2,size_t h1ld_t2,size_t h2ld_t2,size_t p7ld_v2,size_t h3ld_v2,size_t p6ld_v2,size_t p5ld_v2,size_t h2ld_t3,size_t h3ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p4ld_t3,size_t p5ld_t3,double *t3d, double *t2_d, double *v2_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3,p7;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,p7l,p7T;
  __shared__ double t2_shm[4*T1][Tcomm];
  __shared__ double v2_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h2_0=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_0=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_0=rest_y;
  p5_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h2_1=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_1=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_1=rest_y;
  p5_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h2_2=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_2=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_2=rest_y;
  p5_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h2_3=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_3=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_3=rest_y;
  p5_3=rest_x;
  size_t t2_d_off, v2_d_off;for(p7T=0;p7T<p7d;p7T+=Tcomm){size_t p7l_hi;
    p7l_hi = TG_MIN(Tcomm+p7T,p7d)-p7T;
    t2_d_off=p4_0*p4ld_t2+h1_0*h1ld_t2+h2_0*h2ld_t2;
    v2_d_off=h3_0*h3ld_v2+p6_0*p6ld_v2+p5_0*p5ld_v2;
    if(thread_y+T1*0<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*0][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*0<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*0] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_1*p4ld_t2+h1_1*h1ld_t2+h2_1*h2ld_t2;
    v2_d_off=h3_1*h3ld_v2+p6_1*p6ld_v2+p5_1*p5ld_v2;
    if(thread_y+T1*1<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*1][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*1<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*1] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_2*p4ld_t2+h1_2*h1ld_t2+h2_2*h2ld_t2;
    v2_d_off=h3_2*h3ld_v2+p6_2*p6ld_v2+p5_2*p5ld_v2;
    if(thread_y+T1*2<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*2][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*2<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*2] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_3*p4ld_t2+h1_3*h1ld_t2+h2_3*h2ld_t2;
    v2_d_off=h3_3*h3ld_v2+p6_3*p6ld_v2+p5_3*p5ld_v2;
    if(thread_y+T1*3<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*3][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*3<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*3] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    __syncthreads();
    for(p7l=0;p7l<p7l_hi;++p7l){
      a1=t2_shm[in1_idxl+T1*0][p7l];
      a2=t2_shm[in1_idxl+T1*1][p7l];
      a3=t2_shm[in1_idxl+T1*2][p7l];
      a4=t2_shm[in1_idxl+T1*3][p7l];
      b1=v2_shm[p7l][in2_idxl+T2*0];
      b2=v2_shm[p7l][in2_idxl+T2*1];
      b3=v2_shm[p7l][in2_idxl+T2*2];
      b4=v2_shm[p7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]-=tlocal1;
      t3d[h2_1*h2ld_t3+h3_0*h3ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3+p5_0*p5ld_t3]-=tlocal2;
      t3d[h2_2*h2ld_t3+h3_0*h3ld_t3+h1_2*h1ld_t3+p6_0*p6ld_t3+p4_2*p4ld_t3+p5_0*p5ld_t3]-=tlocal3;
      t3d[h2_3*h2ld_t3+h3_0*h3ld_t3+h1_3*h1ld_t3+p6_0*p6ld_t3+p4_3*p4ld_t3+p5_0*p5ld_t3]-=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]-=tlocal1;
      t3d[h2_1*h2ld_t3+h3_0*h3ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3+p5_0*p5ld_t3]-=tlocal2;
      t3d[h2_2*h2ld_t3+h3_0*h3ld_t3+h1_2*h1ld_t3+p6_0*p6ld_t3+p4_2*p4ld_t3+p5_0*p5ld_t3]-=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]-=tlocal1;
      t3d[h2_1*h2ld_t3+h3_0*h3ld_t3+h1_1*h1ld_t3+p6_0*p6ld_t3+p4_1*p4ld_t3+p5_0*p5ld_t3]-=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p6_0*p6ld_t3+p4_0*p4ld_t3+p5_0*p5ld_t3]-=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]-=tlocal5;
      t3d[h2_1*h2ld_t3+h3_1*h3ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3+p5_1*p5ld_t3]-=tlocal6;
      t3d[h2_2*h2ld_t3+h3_1*h3ld_t3+h1_2*h1ld_t3+p6_1*p6ld_t3+p4_2*p4ld_t3+p5_1*p5ld_t3]-=tlocal7;
      t3d[h2_3*h2ld_t3+h3_1*h3ld_t3+h1_3*h1ld_t3+p6_1*p6ld_t3+p4_3*p4ld_t3+p5_1*p5ld_t3]-=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]-=tlocal5;
      t3d[h2_1*h2ld_t3+h3_1*h3ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3+p5_1*p5ld_t3]-=tlocal6;
      t3d[h2_2*h2ld_t3+h3_1*h3ld_t3+h1_2*h1ld_t3+p6_1*p6ld_t3+p4_2*p4ld_t3+p5_1*p5ld_t3]-=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]-=tlocal5;
      t3d[h2_1*h2ld_t3+h3_1*h3ld_t3+h1_1*h1ld_t3+p6_1*p6ld_t3+p4_1*p4ld_t3+p5_1*p5ld_t3]-=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p6_1*p6ld_t3+p4_0*p4ld_t3+p5_1*p5ld_t3]-=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]-=tlocal9;
      t3d[h2_1*h2ld_t3+h3_2*h3ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3+p5_2*p5ld_t3]-=tlocal10;
      t3d[h2_2*h2ld_t3+h3_2*h3ld_t3+h1_2*h1ld_t3+p6_2*p6ld_t3+p4_2*p4ld_t3+p5_2*p5ld_t3]-=tlocal11;
      t3d[h2_3*h2ld_t3+h3_2*h3ld_t3+h1_3*h1ld_t3+p6_2*p6ld_t3+p4_3*p4ld_t3+p5_2*p5ld_t3]-=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]-=tlocal9;
      t3d[h2_1*h2ld_t3+h3_2*h3ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3+p5_2*p5ld_t3]-=tlocal10;
      t3d[h2_2*h2ld_t3+h3_2*h3ld_t3+h1_2*h1ld_t3+p6_2*p6ld_t3+p4_2*p4ld_t3+p5_2*p5ld_t3]-=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]-=tlocal9;
      t3d[h2_1*h2ld_t3+h3_2*h3ld_t3+h1_1*h1ld_t3+p6_2*p6ld_t3+p4_1*p4ld_t3+p5_2*p5ld_t3]-=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p6_2*p6ld_t3+p4_0*p4ld_t3+p5_2*p5ld_t3]-=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]-=tlocal13;
      t3d[h2_1*h2ld_t3+h3_3*h3ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3+p5_3*p5ld_t3]-=tlocal14;
      t3d[h2_2*h2ld_t3+h3_3*h3ld_t3+h1_2*h1ld_t3+p6_3*p6ld_t3+p4_2*p4ld_t3+p5_3*p5ld_t3]-=tlocal15;
      t3d[h2_3*h2ld_t3+h3_3*h3ld_t3+h1_3*h1ld_t3+p6_3*p6ld_t3+p4_3*p4ld_t3+p5_3*p5ld_t3]-=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]-=tlocal13;
      t3d[h2_1*h2ld_t3+h3_3*h3ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3+p5_3*p5ld_t3]-=tlocal14;
      t3d[h2_2*h2ld_t3+h3_3*h3ld_t3+h1_2*h1ld_t3+p6_3*p6ld_t3+p4_2*p4ld_t3+p5_3*p5ld_t3]-=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]-=tlocal13;
      t3d[h2_1*h2ld_t3+h3_3*h3ld_t3+h1_1*h1ld_t3+p6_3*p6ld_t3+p4_1*p4ld_t3+p5_3*p5ld_t3]-=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p6_3*p6ld_t3+p4_0*p4ld_t3+p5_3*p5ld_t3]-=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d2_6_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, size_t p7d, double *t3, double *t2, double *v2) {
  size_t p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,p5ld_v2,h2ld_t3,h3ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,p5ld_t3;
  size_t /*size_t3,size_block_t3,size_el_block_t3,*/size_t2,size_v2;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2_d,*v2_d;
  //size_t3=h2d*h3d*h1d*p6d*p4d*p5d*sizeof(double);
  size_t2=p7d*p4d*h1d*h2d*sizeof(double);
  size_v2=p7d*h3d*p6d*p5d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d2_6_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_t3=size_t3/nstreams;
  //size_el_block_t3=size_block_t3/sizeof(double);
  //t3d=(double*)getGpuMem(size_t3);
  t2_d=(double*)getGpuMem(size_t2);
  v2_d=(double*)getGpuMem(size_v2);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2_d,t2,size_t2,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2_d,v2,size_v2,cudaMemcpyHostToDevice));
  p7ld_t2=1;
  p4ld_t2=p7d;
  h1ld_t2=p4d*p7d;
  h2ld_t2=h1d*p4d*p7d;
  p7ld_v2=1;
  h3ld_v2=p7d;
  p6ld_v2=h3d*p7d;
  p5ld_v2=p6d*h3d*p7d;
  h2ld_t3=1;
  h3ld_t3=h2d;
  h1ld_t3=h3d*h2d;
  p6ld_t3=h1d*h3d*h2d;
  p4ld_t3=p6d*h1d*h3d*h2d;
  p5ld_t3=p4d*p6d*h1d*h3d*h2d;
  size_t total_x = h3d*p6d*p5d;
  size_t total_y = p4d*h1d*h2d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d2_6_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d,p6d,p7d,p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,p5ld_v2,h2ld_t3,h3ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,p5ld_t3,t3_d,t2_d,v2_d,i,total_x,total_y);
    CHECK_ERR();
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  //freeGpuMem(t3d);
  freeGpuMem(t2_d);
  freeGpuMem(v2_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d2_6_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* p4d, Integer* p5d, Integer* p6d, Integer* p7d, double *t3, double *t2, double *v2) {
  sd_t_d2_6_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,(size_t)*p7d,t3,t2,v2);
}
/*----------------------------------------------------------------------*
 *t3[h3,h2,h1,p4,p6,p5] -= t2[p7,p4,h1,h2] * v2[p7,h3,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d2_7_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p5d,size_t p6d,size_t p7d,size_t p7ld_t2,size_t p4ld_t2,size_t h1ld_t2,size_t h2ld_t2,size_t p7ld_v2,size_t h3ld_v2,size_t p6ld_v2,size_t p5ld_v2,size_t h3ld_t3,size_t h2ld_t3,size_t h1ld_t3,size_t p4ld_t3,size_t p6ld_t3,size_t p5ld_t3,double *t3d, double *t2_d, double *v2_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3,p7;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,p7l,p7T;
  __shared__ double t2_shm[4*T1][Tcomm];
  __shared__ double v2_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_0=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_0=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_0=rest_y;
  p5_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_1=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_1=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_1=rest_y;
  p5_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_2=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_2=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_2=rest_y;
  p5_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h2_3=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_3=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_3=rest_y;
  p5_3=rest_x;
  size_t t2_d_off, v2_d_off;for(p7T=0;p7T<p7d;p7T+=Tcomm){size_t p7l_hi;
    p7l_hi = TG_MIN(Tcomm+p7T,p7d)-p7T;
    t2_d_off=p4_0*p4ld_t2+h1_0*h1ld_t2+h2_0*h2ld_t2;
    v2_d_off=h3_0*h3ld_v2+p6_0*p6ld_v2+p5_0*p5ld_v2;
    if(thread_y+T1*0<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*0][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*0<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*0] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_1*p4ld_t2+h1_1*h1ld_t2+h2_1*h2ld_t2;
    v2_d_off=h3_1*h3ld_v2+p6_1*p6ld_v2+p5_1*p5ld_v2;
    if(thread_y+T1*1<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*1][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*1<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*1] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_2*p4ld_t2+h1_2*h1ld_t2+h2_2*h2ld_t2;
    v2_d_off=h3_2*h3ld_v2+p6_2*p6ld_v2+p5_2*p5ld_v2;
    if(thread_y+T1*2<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*2][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*2<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*2] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_3*p4ld_t2+h1_3*h1ld_t2+h2_3*h2ld_t2;
    v2_d_off=h3_3*h3ld_v2+p6_3*p6ld_v2+p5_3*p5ld_v2;
    if(thread_y+T1*3<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*3][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*3<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*3] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    __syncthreads();
    for(p7l=0;p7l<p7l_hi;++p7l){
      a1=t2_shm[in1_idxl+T1*0][p7l];
      a2=t2_shm[in1_idxl+T1*1][p7l];
      a3=t2_shm[in1_idxl+T1*2][p7l];
      a4=t2_shm[in1_idxl+T1*3][p7l];
      b1=v2_shm[p7l][in2_idxl+T2*0];
      b2=v2_shm[p7l][in2_idxl+T2*1];
      b3=v2_shm[p7l][in2_idxl+T2*2];
      b4=v2_shm[p7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal1;
      t3d[h3_0*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal2;
      t3d[h3_0*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal3;
      t3d[h3_0*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p4_3*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal1;
      t3d[h3_0*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal2;
      t3d[h3_0*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal1;
      t3d[h3_0*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_0*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal5;
      t3d[h3_1*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal6;
      t3d[h3_1*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal7;
      t3d[h3_1*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p4_3*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal5;
      t3d[h3_1*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal6;
      t3d[h3_1*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal5;
      t3d[h3_1*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_1*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal9;
      t3d[h3_2*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal10;
      t3d[h3_2*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal11;
      t3d[h3_2*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p4_3*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal9;
      t3d[h3_2*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal10;
      t3d[h3_2*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal9;
      t3d[h3_2*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_2*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal13;
      t3d[h3_3*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal14;
      t3d[h3_3*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal15;
      t3d[h3_3*h3ld_t3+h2_3*h2ld_t3+h1_3*h1ld_t3+p4_3*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal13;
      t3d[h3_3*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal14;
      t3d[h3_3*h3ld_t3+h2_2*h2ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal13;
      t3d[h3_3*h3ld_t3+h2_1*h2ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h3_3*h3ld_t3+h2_0*h2ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d2_7_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, size_t p7d, double *t3, double *t2, double *v2) {
  size_t p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,p5ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p4ld_t3,p6ld_t3,p5ld_t3;
  size_t /*size_t3,size_block_t3,size_el_block_t3,*/size_t2,size_v2;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2_d,*v2_d;
  //size_t3=h3d*h2d*h1d*p4d*p6d*p5d*sizeof(double);
  size_t2=p7d*p4d*h1d*h2d*sizeof(double);
  size_v2=p7d*h3d*p6d*p5d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d2_7_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_t3=size_t3/nstreams;
  //size_el_block_t3=size_block_t3/sizeof(double);
  //t3d=(double*)getGpuMem(size_t3);
  t2_d=(double*)getGpuMem(size_t2);
  v2_d=(double*)getGpuMem(size_v2);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2_d,t2,size_t2,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2_d,v2,size_v2,cudaMemcpyHostToDevice));
  p7ld_t2=1;
  p4ld_t2=p7d;
  h1ld_t2=p4d*p7d;
  h2ld_t2=h1d*p4d*p7d;
  p7ld_v2=1;
  h3ld_v2=p7d;
  p6ld_v2=h3d*p7d;
  p5ld_v2=p6d*h3d*p7d;
  h3ld_t3=1;
  h2ld_t3=h3d;
  h1ld_t3=h2d*h3d;
  p4ld_t3=h1d*h2d*h3d;
  p6ld_t3=p4d*h1d*h2d*h3d;
  p5ld_t3=p6d*p4d*h1d*h2d*h3d;
  size_t total_x = h3d*p6d*p5d;
  size_t total_y = p4d*h1d*h2d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d2_7_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d,p6d,p7d,p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,p5ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p4ld_t3,p6ld_t3,p5ld_t3,t3_d,t2_d,v2_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  //freeGpuMem(t3d);
  freeGpuMem(t2_d);
  freeGpuMem(v2_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d2_7_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* p4d, Integer* p5d, Integer* p6d, Integer* p7d, double *t3, double *t2, double *v2) {
  sd_t_d2_7_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,(size_t)*p7d,t3,t2,v2);
}
/*----------------------------------------------------------------------*
 *t3[h2,h1,h3,p4,p6,p5] -= t2[p7,p4,h1,h2] * v2[p7,h3,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d2_8_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p5d,size_t p6d,size_t p7d,size_t p7ld_t2,size_t p4ld_t2,size_t h1ld_t2,size_t h2ld_t2,size_t p7ld_v2,size_t h3ld_v2,size_t p6ld_v2,size_t p5ld_v2,size_t h2ld_t3,size_t h1ld_t3,size_t h3ld_t3,size_t p4ld_t3,size_t p6ld_t3,size_t p5ld_t3,double *t3d, double *t2_d, double *v2_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3,p7;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,p7l,p7T;
  __shared__ double t2_shm[4*T1][Tcomm];
  __shared__ double v2_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h2_0=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  p6_0=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_0=rest_y;
  p5_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h2_1=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  p6_1=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_1=rest_y;
  p5_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h2_2=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  p6_2=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_2=rest_y;
  p5_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h2_3=rest_y%h2d;
  rest_y=rest_y/h2d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  p6_3=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_3=rest_y;
  p5_3=rest_x;
  size_t t2_d_off, v2_d_off;for(p7T=0;p7T<p7d;p7T+=Tcomm){size_t p7l_hi;
    p7l_hi = TG_MIN(Tcomm+p7T,p7d)-p7T;
    t2_d_off=p4_0*p4ld_t2+h1_0*h1ld_t2+h2_0*h2ld_t2;
    v2_d_off=h3_0*h3ld_v2+p6_0*p6ld_v2+p5_0*p5ld_v2;
    if(thread_y+T1*0<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*0][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*0<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*0] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_1*p4ld_t2+h1_1*h1ld_t2+h2_1*h2ld_t2;
    v2_d_off=h3_1*h3ld_v2+p6_1*p6ld_v2+p5_1*p5ld_v2;
    if(thread_y+T1*1<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*1][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*1<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*1] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_2*p4ld_t2+h1_2*h1ld_t2+h2_2*h2ld_t2;
    v2_d_off=h3_2*h3ld_v2+p6_2*p6ld_v2+p5_2*p5ld_v2;
    if(thread_y+T1*2<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*2][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*2<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*2] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_3*p4ld_t2+h1_3*h1ld_t2+h2_3*h2ld_t2;
    v2_d_off=h3_3*h3ld_v2+p6_3*p6ld_v2+p5_3*p5ld_v2;
    if(thread_y+T1*3<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*3][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*3<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*3] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    __syncthreads();
    for(p7l=0;p7l<p7l_hi;++p7l){
      a1=t2_shm[in1_idxl+T1*0][p7l];
      a2=t2_shm[in1_idxl+T1*1][p7l];
      a3=t2_shm[in1_idxl+T1*2][p7l];
      a4=t2_shm[in1_idxl+T1*3][p7l];
      b1=v2_shm[p7l][in2_idxl+T2*0];
      b2=v2_shm[p7l][in2_idxl+T2*1];
      b3=v2_shm[p7l][in2_idxl+T2*2];
      b4=v2_shm[p7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal1;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_0*h3ld_t3+p4_1*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal2;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_0*h3ld_t3+p4_2*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal3;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_0*h3ld_t3+p4_3*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal1;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_0*h3ld_t3+p4_1*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal2;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_0*h3ld_t3+p4_2*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal1;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_0*h3ld_t3+p4_1*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_0*h3ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]-=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal5;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_1*h3ld_t3+p4_1*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal6;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_1*h3ld_t3+p4_2*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal7;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_1*h3ld_t3+p4_3*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal5;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_1*h3ld_t3+p4_1*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal6;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_1*h3ld_t3+p4_2*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal5;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_1*h3ld_t3+p4_1*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_1*h3ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]-=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal9;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_2*h3ld_t3+p4_1*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal10;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_2*h3ld_t3+p4_2*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal11;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_2*h3ld_t3+p4_3*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal9;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_2*h3ld_t3+p4_1*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal10;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_2*h3ld_t3+p4_2*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal9;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_2*h3ld_t3+p4_1*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_2*h3ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]-=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal13;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_3*h3ld_t3+p4_1*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal14;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_3*h3ld_t3+p4_2*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal15;
      t3d[h2_3*h2ld_t3+h1_3*h1ld_t3+h3_3*h3ld_t3+p4_3*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal13;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_3*h3ld_t3+p4_1*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal14;
      t3d[h2_2*h2ld_t3+h1_2*h1ld_t3+h3_3*h3ld_t3+p4_2*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal13;
      t3d[h2_1*h2ld_t3+h1_1*h1ld_t3+h3_3*h3ld_t3+p4_1*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h1_0*h1ld_t3+h3_3*h3ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]-=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d2_8_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, size_t p7d, double *t3, double *t2, double *v2) {
  size_t p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,p5ld_v2,h2ld_t3,h1ld_t3,h3ld_t3,p4ld_t3,p6ld_t3,p5ld_t3;
  size_t /*size_t3,size_block_t3,size_el_block_t3,*/size_t2,size_v2;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2_d,*v2_d;
  //size_t3=h2d*h1d*h3d*p4d*p6d*p5d*sizeof(double);
  size_t2=p7d*p4d*h1d*h2d*sizeof(double);
  size_v2=p7d*h3d*p6d*p5d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d2_8_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_t3=size_t3/nstreams;
  //size_el_block_t3=size_block_t3/sizeof(double);
  //t3d=(double*)getGpuMem(size_t3);
  t2_d=(double*)getGpuMem(size_t2);
  v2_d=(double*)getGpuMem(size_v2);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2_d,t2,size_t2,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2_d,v2,size_v2,cudaMemcpyHostToDevice));
  p7ld_t2=1;
  p4ld_t2=p7d;
  h1ld_t2=p4d*p7d;
  h2ld_t2=h1d*p4d*p7d;
  p7ld_v2=1;
  h3ld_v2=p7d;
  p6ld_v2=h3d*p7d;
  p5ld_v2=p6d*h3d*p7d;
  h2ld_t3=1;
  h1ld_t3=h2d;
  h3ld_t3=h1d*h2d;
  p4ld_t3=h3d*h1d*h2d;
  p6ld_t3=p4d*h3d*h1d*h2d;
  p5ld_t3=p6d*p4d*h3d*h1d*h2d;
  size_t total_x = h3d*p6d*p5d;
  size_t total_y = p4d*h1d*h2d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d2_8_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d,p6d,p7d,p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,p5ld_v2,h2ld_t3,h1ld_t3,h3ld_t3,p4ld_t3,p6ld_t3,p5ld_t3,t3_d,t2_d,v2_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  //freeGpuMem(t3d);
  freeGpuMem(t2_d);
  freeGpuMem(v2_d);
  free(streams);
}
#undef T1
#undef T2
#undef Tcomm
  void sd_t_d2_8_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* p4d, Integer* p5d, Integer* p6d, Integer* p7d, double *t3, double *t2, double *v2) {
  sd_t_d2_8_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,(size_t)*p7d,t3,t2,v2);
}
/*----------------------------------------------------------------------*
 *t3[h2,h3,h1,p4,p6,p5] += t2[p7,p4,h1,h2] * v2[p7,h3,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_d2_9_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p5d,size_t p6d,size_t p7d,size_t p7ld_t2,size_t p4ld_t2,size_t h1ld_t2,size_t h2ld_t2,size_t p7ld_v2,size_t h3ld_v2,size_t p6ld_v2,size_t p5ld_v2,size_t h2ld_t3,size_t h3ld_t3,size_t h1ld_t3,size_t p4ld_t3,size_t p6ld_t3,size_t p5ld_t3,double *t3d, double *t2_d, double *v2_d,size_t unused_idx, size_t total_x, size_t total_y) {
  size_t h1_0,h1_1,h1_2,h1_3,h2_0,h2_1,h2_2,h2_3,h3_0,h3_1,h3_2,h3_3,p4_0,p4_1,p4_2,p4_3,p5_0,p5_1,p5_2,p5_3,p6_0,p6_1,p6_2,p6_3,p7;
  double a1,b1;
  double a2,b2;
  double a3,b3;
  double a4,b4;
  size_t in1_idxl,in2_idxl,p7l,p7T;
  __shared__ double t2_shm[4*T1][Tcomm];
  __shared__ double v2_shm[Tcomm][4*T2];
  size_t rest_x=blockIdx.x;
  size_t rest_y=blockIdx.y;
  size_t thread_x = T2*4 * rest_x + threadIdx.x;
  size_t thread_y = T1*4 * rest_y + threadIdx.y;
  in1_idxl=threadIdx.y;
  in2_idxl=threadIdx.x ;
  double tlocal1=0;
  double tlocal2=0;
  double tlocal3=0;
  double tlocal4=0;
  double tlocal5=0;
  double tlocal6=0;
  double tlocal7=0;
  double tlocal8=0;
  double tlocal9=0;
  double tlocal10=0;
  double tlocal11=0;
  double tlocal12=0;
  double tlocal13=0;
  double tlocal14=0;
  double tlocal15=0;
  double tlocal16=0;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*0;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*0;
  h2_0=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_0=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_0=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_0=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_0=rest_y;
  p5_0=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*1;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*1;
  h2_1=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_1=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_1=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_1=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_1=rest_y;
  p5_1=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*2;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*2;
  h2_2=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_2=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_2=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_2=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_2=rest_y;
  p5_2=rest_x;
  rest_x = T2 *4* blockIdx.x + threadIdx.x+T1*3;
  rest_y = T1 *4* blockIdx.y + threadIdx.y+T1*3;
  h2_3=rest_y%h2d;
  rest_y=rest_y/h2d;
  h3_3=rest_x%h3d;
  rest_x=rest_x/h3d;
  h1_3=rest_y%h1d;
  rest_y=rest_y/h1d;
  p6_3=rest_x%p6d;
  rest_x=rest_x/p6d;
  p4_3=rest_y;
  p5_3=rest_x;
  size_t t2_d_off, v2_d_off;for(p7T=0;p7T<p7d;p7T+=Tcomm){
    size_t p7l_hi;
    p7l_hi = TG_MIN(Tcomm+p7T,p7d)-p7T;
    t2_d_off=p4_0*p4ld_t2+h1_0*h1ld_t2+h2_0*h2ld_t2;
    v2_d_off=h3_0*h3ld_v2+p6_0*p6ld_v2+p5_0*p5ld_v2;
    if(thread_y+T1*0<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*0][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*0<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*0] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_1*p4ld_t2+h1_1*h1ld_t2+h2_1*h2ld_t2;
    v2_d_off=h3_1*h3ld_v2+p6_1*p6ld_v2+p5_1*p5ld_v2;
    if(thread_y+T1*1<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*1][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*1<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*1] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_2*p4ld_t2+h1_2*h1ld_t2+h2_2*h2ld_t2;
    v2_d_off=h3_2*h3ld_v2+p6_2*p6ld_v2+p5_2*p5ld_v2;
    if(thread_y+T1*2<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*2][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*2<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*2] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    t2_d_off=p4_3*p4ld_t2+h1_3*h1ld_t2+h2_3*h2ld_t2;
    v2_d_off=h3_3*h3ld_v2+p6_3*p6ld_v2+p5_3*p5ld_v2;
    if(thread_y+T1*3<total_y)for(p7l=threadIdx.x;p7l<p7l_hi;p7l+=blockDim.x){
	p7=p7l+p7T;
	t2_shm[in1_idxl+T1*3][p7l] = t2_d[t2_d_off+p7*p7ld_t2];
      }
    if(thread_x+T1*3<total_x)for(p7l=threadIdx.y;p7l<p7l_hi;p7l+=blockDim.y){
	p7=p7l+p7T;
	v2_shm[p7l][in2_idxl+T1*3] = v2_d[v2_d_off+p7*p7ld_v2];
      }
    __syncthreads();
    for(p7l=0;p7l<p7l_hi;++p7l){
      a1=t2_shm[in1_idxl+T1*0][p7l];
      a2=t2_shm[in1_idxl+T1*1][p7l];
      a3=t2_shm[in1_idxl+T1*2][p7l];
      a4=t2_shm[in1_idxl+T1*3][p7l];
      b1=v2_shm[p7l][in2_idxl+T2*0];
      b2=v2_shm[p7l][in2_idxl+T2*1];
      b3=v2_shm[p7l][in2_idxl+T2*2];
      b4=v2_shm[p7l][in2_idxl+T2*3];
      tlocal1+=a1*b1;
      tlocal2+=a2*b1;
      tlocal3+=a3*b1;
      tlocal4+=a4*b1;
      tlocal5+=a1*b2;
      tlocal6+=a2*b2;
      tlocal7+=a3*b2;
      tlocal8+=a4*b2;
      tlocal9+=a1*b3;
      tlocal10+=a2*b3;
      tlocal11+=a3*b3;
      tlocal12+=a4*b3;
      tlocal13+=a1*b4;
      tlocal14+=a2*b4;
      tlocal15+=a3*b4;
      tlocal16+=a4*b4;
    }
    __syncthreads();
  }
  if(thread_x+T1*0<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]+=tlocal1;
      t3d[h2_1*h2ld_t3+h3_0*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]+=tlocal2;
      t3d[h2_2*h2ld_t3+h3_0*h3ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]+=tlocal3;
      t3d[h2_3*h2ld_t3+h3_0*h3ld_t3+h1_3*h1ld_t3+p4_3*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]+=tlocal4;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]+=tlocal1;
      t3d[h2_1*h2ld_t3+h3_0*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]+=tlocal2;
      t3d[h2_2*h2ld_t3+h3_0*h3ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]+=tlocal3;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]+=tlocal1;
      t3d[h2_1*h2ld_t3+h3_0*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]+=tlocal2;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_0*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_0*p6ld_t3+p5_0*p5ld_t3]+=tlocal1;
    }
  }
  if(thread_x+T1*1<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]+=tlocal5;
      t3d[h2_1*h2ld_t3+h3_1*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]+=tlocal6;
      t3d[h2_2*h2ld_t3+h3_1*h3ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]+=tlocal7;
      t3d[h2_3*h2ld_t3+h3_1*h3ld_t3+h1_3*h1ld_t3+p4_3*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]+=tlocal8;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]+=tlocal5;
      t3d[h2_1*h2ld_t3+h3_1*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]+=tlocal6;
      t3d[h2_2*h2ld_t3+h3_1*h3ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]+=tlocal7;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]+=tlocal5;
      t3d[h2_1*h2ld_t3+h3_1*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]+=tlocal6;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_1*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_1*p6ld_t3+p5_1*p5ld_t3]+=tlocal5;
    }
  }
  if(thread_x+T1*2<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]+=tlocal9;
      t3d[h2_1*h2ld_t3+h3_2*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]+=tlocal10;
      t3d[h2_2*h2ld_t3+h3_2*h3ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]+=tlocal11;
      t3d[h2_3*h2ld_t3+h3_2*h3ld_t3+h1_3*h1ld_t3+p4_3*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]+=tlocal12;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]+=tlocal9;
      t3d[h2_1*h2ld_t3+h3_2*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]+=tlocal10;
      t3d[h2_2*h2ld_t3+h3_2*h3ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]+=tlocal11;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]+=tlocal9;
      t3d[h2_1*h2ld_t3+h3_2*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]+=tlocal10;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_2*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_2*p6ld_t3+p5_2*p5ld_t3]+=tlocal9;
    }
  }
  if(thread_x+T1*3<total_x){
    if(thread_y+T2*3<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]+=tlocal13;
      t3d[h2_1*h2ld_t3+h3_3*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]+=tlocal14;
      t3d[h2_2*h2ld_t3+h3_3*h3ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]+=tlocal15;
      t3d[h2_3*h2ld_t3+h3_3*h3ld_t3+h1_3*h1ld_t3+p4_3*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]+=tlocal16;
    }
    else if(thread_y+T2*2<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]+=tlocal13;
      t3d[h2_1*h2ld_t3+h3_3*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]+=tlocal14;
      t3d[h2_2*h2ld_t3+h3_3*h3ld_t3+h1_2*h1ld_t3+p4_2*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]+=tlocal15;
    }
    else if(thread_y+T2*1<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]+=tlocal13;
      t3d[h2_1*h2ld_t3+h3_3*h3ld_t3+h1_1*h1ld_t3+p4_1*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]+=tlocal14;
    }
    else if(thread_y+T2*0<total_y) {
      t3d[h2_0*h2ld_t3+h3_3*h3ld_t3+h1_0*h1ld_t3+p4_0*p4ld_t3+p6_3*p6ld_t3+p5_3*p5ld_t3]+=tlocal13;
    }
  }
  __syncthreads();
}
  void sd_t_d2_9_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, size_t p7d, double *t3, double *t2, double *v2) {
  size_t p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,p5ld_v2,h2ld_t3,h3ld_t3,h1ld_t3,p4ld_t3,p6ld_t3,p5ld_t3;
  size_t /*size_t3,size_block_t3,size_el_block_t3,*/size_t2,size_v2;
  cudaStream_t *streams;
  size_t nstreams,i;
  double *t2_d,*v2_d;
  //size_t3=h2d*h3d*h1d*p4d*p6d*p5d*sizeof(double);
  size_t2=p7d*p4d*h1d*h2d*sizeof(double);
  size_v2=p7d*h3d*p6d*p5d*sizeof(double);
  cudaFuncSetCacheConfig(sd_t_d2_9_kernel, cudaFuncCachePreferShared);
  nstreams=1;
  //size_block_t3=size_t3/nstreams;
  //size_el_block_t3=size_block_t3/sizeof(double);
  //t3d=(double*)getGpuMem(size_t3);
  t2_d=(double*)getGpuMem(size_t2);
  v2_d=(double*)getGpuMem(size_v2);
  streams=(cudaStream_t*) malloc(nstreams*sizeof(cudaStream_t));
  assert(streams!= NULL);
  for(i=0;i<nstreams;++i) {
    CUDA_SAFE(cudaStreamCreate(&streams[i])) ;
  }
  CUDA_SAFE(cudaMemcpy(t2_d,t2,size_t2,cudaMemcpyHostToDevice));
  CUDA_SAFE(cudaMemcpy(v2_d,v2,size_v2,cudaMemcpyHostToDevice));
  p7ld_t2=1;
  p4ld_t2=p7d;
  h1ld_t2=p4d*p7d;
  h2ld_t2=h1d*p4d*p7d;
  p7ld_v2=1;
  h3ld_v2=p7d;
  p6ld_v2=h3d*p7d;
  p5ld_v2=p6d*h3d*p7d;
  h2ld_t3=1;
  h3ld_t3=h2d;
  h1ld_t3=h3d*h2d;
  p4ld_t3=h1d*h3d*h2d;
  p6ld_t3=p4d*h1d*h3d*h2d;
  p5ld_t3=p6d*p4d*h1d*h3d*h2d;
  size_t total_x = h3d*p6d*p5d;
  size_t total_y = p4d*h1d*h2d;
  dim3 dimBlock(T2,T1);dim3 dimGrid(DIV_UB(total_x,(4*T2)), DIV_UB(total_y,(4*T1)));
  for(i=0;i<nstreams;++i){
    sd_t_d2_9_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d,p6d,p7d,p7ld_t2,p4ld_t2,h1ld_t2,h2ld_t2,p7ld_v2,h3ld_v2,p6ld_v2,p5ld_v2,h2ld_t3,h3ld_t3,h1ld_t3,p4ld_t3,p6ld_t3,p5ld_t3,t3_d,t2_d,v2_d,i,total_x,total_y);
    CHECK_ERR("Kernel execution failed");
  }
  cudaDeviceSynchronize();
  for(i=0;i<nstreams;++i){
    cudaStreamDestroy(streams[i]);}
  //freeGpuMem(t3d);
  freeGpuMem(t2_d);
  freeGpuMem(v2_d);
  free(streams);
}

  void sd_t_d2_9_cuda_(Integer *h1d, Integer* h2d, Integer* h3d, Integer* p4d, Integer* p5d, Integer* p6d, Integer* p7d, double *t3, double *t2, double *v2) {
  sd_t_d2_9_cuda((size_t)*h1d,(size_t)*h2d,(size_t)*h3d,(size_t)*p4d,(size_t)*p5d,(size_t)*p6d,(size_t)*p7d,t3,t2,v2);
}


#define MAX_h3 64
#include <iostream>

/* IMPORTANT!!!!
t3_d must be passed as parameter to kernel function. A __global__ function can't access the global variable directly*/

__global__ void compute_energy_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p5d,size_t p6d,double* eval1,double* eval2,double* eval3,double* eval4,double* eval5,double* eval6, double* energy, double factor, size_t total_size, double* t3d, double* t3_sd)
{
  size_t h1,h2,p6,p4,p5; //,h3,i=0;
  double e1,e2,e4,e5,e6;
  //  __shared__ double t2_shm[MAX_h3];
  __shared__ double energy_s[T1];
  __shared__ double energy2_s[T1];
  double inner_fac;
  // size_t limit;
  size_t rest_x=blockIdx.x;
  size_t thread_x = T2*T1 * rest_x + threadIdx.x;
  if(threadIdx.x==0)
  {
        energy[blockIdx.x]=0;
        energy[blockIdx.x+gridDim.x]=0;
        energy_s[threadIdx.x] = 0.0;
        energy2_s[threadIdx.x] = 0.0;
  }

  // printf("rest_x, thread_x = %d %d %d\n",rest_x,thread_x,T2*T1);

  for(size_t j =0; j<T2*T1;j++) {
    thread_x = T2*T1*blockIdx.x + j;  
    rest_x = thread_x;
    __syncthreads();
    h2=rest_x%h2d;
    rest_x=rest_x/h2d;
    h1=rest_x%h1d;
    rest_x=rest_x/h1d;
    p6=rest_x%p6d;
    rest_x=rest_x/p6d;
    p5=rest_x%p5d;
    rest_x=rest_x/p5d;
    p4=rest_x%p4d;
    e1 = eval1[h1];
    e2 = eval2[h2];
    e4 = eval4[p4];
    e5 = eval5[p5];
    e6 = eval6[p6];

    // printf("e123456= %lf %lf %lf %lf %lf \n",e1,e2,e4,e5,e6);
/*
  for(p4=0;p4<p4d;p4++) 
    for(p5 = 0;p5<p5d;p5++)
        for(p6=0;p6<p6d;p6++) 
            for(h1= 0;h1<h1d;h1++) 
                for(h2=0;h2<h2d;h2++) 
                    for(h3=0;h3<h3d;h3++) {
                        inner_fac = -eval4[p4]-eval5[p5]-eval6[p6]+eval1[h1]
                            +eval2[h2]+eval3[h3];
                        energy_s[0]+=factor*t3d[i]*t3d[i]/inner_fac;
                        energy2_s[0]+=factor*t3d[i]*(t3_sd[i]+t3d[i])/inner_fac;
                        i++;
                    }
*/
    if(thread_x<total_size)
    for(size_t i=0;i<h3d;i++)
    {
        inner_fac = -e4-e5-e6+e1+e2+eval3[i]; //t2_shm[i];
//ckbn avoid e1 in case we need just (T)
        energy_s[threadIdx.x] += factor* t3d[thread_x*h3d+i]*t3d[thread_x*h3d+i]/inner_fac;
        energy2_s[threadIdx.x] += factor* t3d[thread_x*h3d+i]*(t3_sd[thread_x*h3d+i]+t3d[thread_x*h3d+i])/inner_fac;

        // printf("inner_fac,e1s,e2s = %lf %lf %lf\n", inner_fac,energy_s[threadIdx.x],energy2_s[threadIdx.x]);
    }
    __syncthreads();
  }
  if(threadIdx.x==0)
  {
/*	  limit = blockDim.x;
      if (blockIdx.x == (gridDim.x-1)) limit = total_size%blockDim.x;
      for(size_t i=0;i<limit;i++)
      {
        energy[blockIdx.x]+=energy_s[i];
        energy[blockIdx.x+gridDim.x]+=energy2_s[i];
      }
*/
    energy[blockIdx.x] = energy_s[0];
    energy[blockIdx.x+gridDim.x] = energy2_s[0];
   }
  __syncthreads();

}

    void compute_energy(double factor, double* energy, double* eval1, double* eval2,double* eval3,double* eval4,double* eval5,double* eval6,size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d,size_t p6d, double* host1, double* host2)
//ckbn en_comment, double* total_d, double* total_s)
{
    double* energy_d, *energy_h;
    double* eval_d1,*eval_d2,*eval_d3,*eval_d4,*eval_d5,*eval_d6;
    size_t size_energy = 2*sizeof(double);
    size_t total_block = DIV_UB((h1d*h2d*p4d*p5d*p6d), (T2*T1));

//    size_t total_block = 1;
    size_t total_elements = h1d*h2d*p4d*p5d*p6d;
    
    energy_d = (double*)getGpuMem(size_energy*total_block*2);
    // size_t i=0,in; 
    double* t3 = (double*)malloc(sizeof(double)*h3d*total_elements);
    double* ts3 = (double*)malloc(sizeof(double)*h3d*total_elements);

    energy_h = (double*)getHostMem(size_energy*2*total_block);
    eval_d1 = (double*)getGpuMem(h1d*sizeof(double));
    eval_d2 = (double*)getGpuMem(h2d*sizeof(double));
    eval_d3 = (double*)getGpuMem(h3d*sizeof(double));
    eval_d4 = (double*)getGpuMem(p4d*sizeof(double));
    eval_d5 = (double*)getGpuMem(p5d*sizeof(double));
    eval_d6 = (double*)getGpuMem(p6d*sizeof(double));

    CUDA_SAFE(cudaMemcpy(eval_d1, eval1, h1d*sizeof(double), cudaMemcpyHostToDevice));
    CUDA_SAFE(cudaMemcpy(eval_d2, eval2, h2d*sizeof(double), cudaMemcpyHostToDevice));
    CUDA_SAFE(cudaMemcpy(eval_d3, eval3, h3d*sizeof(double), cudaMemcpyHostToDevice));
    CUDA_SAFE(cudaMemcpy(eval_d4, eval4, p4d*sizeof(double), cudaMemcpyHostToDevice));
    CUDA_SAFE(cudaMemcpy(eval_d5, eval5, p5d*sizeof(double), cudaMemcpyHostToDevice));
    CUDA_SAFE(cudaMemcpy(eval_d6, eval6, p6d*sizeof(double), cudaMemcpyHostToDevice));
/* for test only */
//printf("host 2 is %f %f\n", host2[0], host2[1]);
//    CUDA_SAFE(cudaMemcpy(t3_s_d, host2, total_elements*h3d*sizeof(double), cudaMemcpyHostToDevice));

    dim3 dimBlock(1); //T2*T1);
    dim3 dimGrid(total_block);
    compute_energy_kernel<<<dimGrid,dimBlock,0>>>(h1d,h2d,h3d,p4d,p5d,p6d, eval_d1,eval_d2,eval_d3,eval_d4,eval_d5,eval_d6,energy_d, factor, h1d*h2d*p4d*p5d*p6d, t3_d, t3_s_d);
	cudaDeviceSynchronize();
    //CHECK_ERR("Kernel execution failed");
    CUDA_SAFE(cudaMemcpy(((char *) energy_h) , ((char *) energy_d) , 
    size_energy*total_block*2, cudaMemcpyDeviceToHost));

    for(size_t i=1;i<dimGrid.x;i++)
      {
        energy_h[0]+=energy_h[i];
        energy_h[dimGrid.x]+=energy_h[i+dimGrid.x];
      }

     
//    printf("CUDA energy_h is %f %f %d %d %d %d %d %d\n", energy_h[0], energy_h[dimGrid.x]); //, total_size, h1d, h2d, p4d, p5d,p6d);
/*
    CUDA_SAFE(cudaMemcpy(((char *) t3) , ((char *) t3_d) , sizeof(double)*h3d*total_elements, cudaMemcpyDeviceToHost));
    CUDA_SAFE(cudaMemcpy(((char *) ts3) , ((char *) t3_s_d) , sizeof(double)*h3d*total_elements, cudaMemcpyDeviceToHost));
    total_s[0]=0.0, total_d[0]=0.0;
    for(size_t i=0;i<h3d*total_elements;i++) {
        total_s[0] += ts3[i];
        total_d[0] += t3[i];
    }
*/
//    printf("Total doubles and singles %f, %f\n", total_d, total_s);
    energy[0] = energy_h[0];
    energy[1] = energy_h[dimGrid.x];
    freeGpuMem(energy_d);
    freeGpuMem(eval_d1);
    freeGpuMem(eval_d2);
    freeGpuMem(eval_d3);
    freeGpuMem(eval_d4);
    freeGpuMem(eval_d5);
    freeGpuMem(eval_d6);
    freeHostMem(energy_h);
}
           void
compute_en_(double * factor, double * energy, double * eval1,double* eval2,double* eval3,double* eval4,double* eval5,double* eval6, Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d, double* host1, double* host2)
//ckbn en_comment,double* total_d, double* total_s)
{
    compute_energy((double) *factor, energy, eval1,eval2, eval3, eval4, eval5, eval6,(int) *h1d, (int) *h2d, (int) *h3d, (int) *p4d, (int) *p5d, (int) *p6d, host1, host2);
//ckbn en_comment    ,total_d, total_s);
}

//__device__ double* t3_d; 
     void dev_mem_s(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d,size_t p6d)
{
    // size_t size_t3;
    size_t size_t3 = h1d*h2d*h3d*p4d*p5d*p6d;
    t3_s_d = (double *) getGpuMem(size_t3*sizeof(double));
    cudaMemset(t3_s_d,0,size_t3*sizeof(double));
}



//            void
// dev_mem_s(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d)
// {
//     set_dev_mem_s((int) *h1d, (int) *h2d, (int) *h3d, (int) *p4d, (int) *p5d, (int) *p6d);
// }

/*----------------------------------------------------------------------*
 *t3[h3,h2,h1,p6,p5,p4] -= t2[p4,h1] * v2[h3,h2,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_s1_1_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p6d,size_t p4ld_t2,size_t h1ld_t2,size_t h3ld_v2,
  size_t h2ld_v2,size_t p6ld_v2,size_t h3ld_t3,size_t h2ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p4ld_t3, double *t2_d, double *v2_d,
  size_t p4, size_t total_x, double* t3d) {
  size_t h1,h2,h3,p6;
  __shared__ double t2_shm[T1*4*Tcomm];
  
  for(size_t i=threadIdx.x;i<h1d*p4d;i+=blockDim.x)
  if(i<h1d*p4d) 
  t2_shm[i] = t2_d[i];
  size_t rest_x=blockIdx.x;
  size_t thread_x = T2*T1 * rest_x + threadIdx.x;
  rest_x = thread_x;
    __syncthreads();
/* the following computation may need to happen inside the loop */
  for(size_t i=0;i<total_x;i+=gridDim.x*blockDim.x)
  {
    rest_x += i;
  	h3=rest_x%h3d;
  	rest_x=rest_x/h3d;
  	h2=rest_x%h2d;
  	rest_x=rest_x/h2d;
  	p6=rest_x%p6d;

    if((thread_x+i)<total_x)
  	for(h1=0;h1<h1d;h1++)
  	for(p4=0;p4<p4d;p4++)
  	{
     	t3d[h3*h3ld_t3+h2*h2ld_t3+h1*h1ld_t3+p6*p6ld_t3+p4*p4ld_t3]+=t2_shm[h1*p4d+p4]*v2_d[h3*h3ld_v2+h2*h2ld_v2+p6*p6ld_v2];
  	}
  }
    __syncthreads();
}

           void 
sd_t_s1_1_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, double *t3, double *t2, double *v2)
{
    // double st, et;
  //ckbn    st = timer(); 
  size_t          p4ld_t2, h1ld_t2, h2ld_v2, h3ld_v2, h1ld_t3,
                  p6ld_v2, p4ld_t3, h3ld_t3, h2ld_t3, p6ld_t3;
                  //p7ld_t2, p7ld_v2, p5ld_v2, p5ld_t3;
	size_t          /*size_t3, size_block_t3, size_el_block_t3,*/ size_t2,
	                size_v2;
	cudaStream_t   *streams;
	size_t          nstreams, i=0;
	double         *t2_d, *v2_d;//, *t3_p;
	//size_t3 = h3d * h2d * h1d * p6d * p5d * p4d * sizeof(double);
	size_t2 = p4d * h1d * sizeof(double);
	size_v2 = h3d * h2d * p6d * p5d * sizeof(double);
	nstreams = 1;
	//size_block_t3=size_t3 / nstreams;
	//size_el_block_t3=size_block_t3 / sizeof(double);
//CUDA_SAFE(cudaMalloc((void**) &t3_d, size_t3));
//CUDA_SAFE(cudaMalloc((void**) &t2_d, size_t2));
//CUDA_SAFE(cudaMalloc((void**) &v2_d, size_v2));
//	t3_d = (double *) getGpuMem(size_t3);
	t2_d = (double *) getGpuMem(size_t2);
	v2_d = (double *) getGpuMem(size_v2);
	//t3_p = (double *) getHostMem(size_t3);
	streams = (cudaStream_t *) malloc(nstreams * sizeof(cudaStream_t));
	assert(streams != NULL);
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaStreamCreate(&streams[i]));
	}
	CUDA_SAFE(cudaMemcpy(t2_d, t2, size_t2, cudaMemcpyHostToDevice));
	CUDA_SAFE(cudaMemcpy(v2_d, v2, size_v2, cudaMemcpyHostToDevice));

	p4ld_t2 = 1;
	h1ld_t2 = p4d;

	h3ld_v2 = 1;
	h2ld_v2 = h3d;
	p6ld_v2 = h3d *  h2d;
//	p5ld_v2 = p6d * h3d * p7d;
	h3ld_t3 = 1;
	h2ld_t3 = h3d;
	h1ld_t3 = h2d * h3d;
	p6ld_t3 = h1d * h2d * h3d;
//	p5ld_t3 = p6d * h1d * h2d * h3d;
	p4ld_t3 = p5d * p6d * h1d * h2d * h3d;
  size_t total_x = h3d*h2d*p6d*p5d;
  dim3 dimBlock(T2*T1);dim3 dimGrid(DIV_UB(total_x,T2*T1), 1);
  for(i=0;i<nstreams;++i){
    sd_t_s1_1_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d*p6d,p4ld_t2,h1ld_t2,h3ld_v2,h2ld_v2,p6ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,t2_d,v2_d,i,total_x, t3_s_d);
		CHECK_ERR("Kernel execution failed");
	}
/*
    st = timer();
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaMemcpyAsync(((char *) t3_p) + i * size_block_t3, ((char *) t3_s_d) + i * size_block_t3, size_block_t3, cudaMemcpyDeviceToHost, streams[i]));
	}

	stream = 0;
	while (stream < nstreams) {
		while (cudaStreamQuery(streams[stream]) != cudaSuccess);
		double         *src = &t3_p[stream * size_el_block_t3];
		double         *dst = &t3[stream * size_el_block_t3];
		for (i = 0; i < size_el_block_t3; ++i) {
			dst[i] = src[i];
		}
		stream++;
	}
*/
	cudaDeviceSynchronize();

//	CUDA_SAFE(cudaMemcpy(((char *) t3) , ((char *) t3_s_d) , size_t3, cudaMemcpyDeviceToHost));
	for (i = 0; i < nstreams; ++i) {
		cudaStreamDestroy(streams[i]);
	}
//	freeGpuMem(t3_d);
	freeGpuMem(t2_d);
	freeGpuMem(v2_d);
   //  cudaFree(t2_d);
   //  cudaFree(v2_d);
	//freeHostMem(t3_p);
	free(streams);
}
#undef T1
#undef T2
#undef Tcomm
           void 
sd_t_s1_1_cuda_(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d, double *t3, double *t2, double *v2)
{
	sd_t_s1_1_cuda((size_t) *h1d, (size_t) *h2d, (size_t) *h3d, (size_t) *p4d, (size_t) *p5d, (size_t) *p6d,  t3, t2, v2);
}
/*----------------------------------------------------------------------*
 *t3[h3,h1,h2,p6,p5,p4] -= t2[p4,h1] * v2[h3,h2,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_s1_2_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p6d,size_t p4ld_t2,size_t h1ld_t2,size_t h3ld_v2,size_t h2ld_v2,size_t p6ld_v2,size_t h3ld_t3,size_t h2ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p4ld_t3,double *t2_d, double *v2_d,size_t p4, size_t total_x, double* t3d) {
  size_t h1,h2,h3,p6;
  __shared__ double t2_shm[T1*4*Tcomm];
  
  for(size_t i=threadIdx.x;i<h1d*p4d;i+=blockDim.x)
  if(i<h1d*p4d)
  t2_shm[i] = t2_d[i];
  size_t rest_x=blockIdx.x;
  size_t thread_x = T2*T1 * rest_x + threadIdx.x;
  rest_x = thread_x;
    __syncthreads();
/* the following computation may need to happen inside the loop */
  for(size_t i=0;i<total_x;i+=gridDim.x*blockDim.x)
  {
    rest_x += i;
  	h3=rest_x%h3d;
  	rest_x=rest_x/h3d;
  	h2=rest_x%h2d;
  	rest_x=rest_x/h2d;
  	p6=rest_x%p6d;

    if((thread_x+i)<total_x)
  	for(h1=0;h1<h1d;h1++)
  	for(p4=0;p4<p4d;p4++)
  	{
     	t3d[h3*h3ld_t3+h2*h2ld_t3+h1*h1ld_t3+p6*p6ld_t3+p4*p4ld_t3]-=t2_shm[h1*p4d+p4]*v2_d[h3*h3ld_v2+h2*h2ld_v2+p6*p6ld_v2];
  	}
  }
    __syncthreads();
}

           void 
sd_t_s1_2_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d, double *t3, double *t2, double *v2)
{
    // double st, et;
  //ckbn    st = timer(); 
	size_t          p4ld_t2, h1ld_t2, h2ld_v2, h3ld_v2, h1ld_t3,
	                p6ld_v2, p4ld_t3, h3ld_t3, h2ld_t3, p6ld_t3;
	                //p7ld_t2, p7ld_v2, p5ld_v2, p5ld_t3;
  size_t          /*size_t3, size_block_t3, size_el_block_t3,*/ 
                  size_t2, size_v2;
	cudaStream_t   *streams;
	size_t          nstreams, i=0;
	double         *t2_d, *v2_d; //, *t3_p;
	//size_t3 = h3d * h2d * h1d * p6d * p5d * p4d * sizeof(double);
	size_t2 = p4d * h1d * sizeof(double);
	size_v2 = h3d * h2d * p6d * p5d * sizeof(double);
	nstreams = 1;
	//size_block_t3=size_t3 / nstreams;
	//size_el_block_t3=size_block_t3 / sizeof(double);
/*    if(first==1)
    {
		t3_d = (double *) getGpuMem(size_t3);
        cudaMemset(t3_d,0,size_t3*sizeof(double));
        first = 0;
	}*/
//CUDA_SAFE(cudaMalloc((void**) &t2_d, size_t2));
//CUDA_SAFE(cudaMalloc((void**) &v2_d, size_v2));
	t2_d = (double *) getGpuMem(size_t2);
	v2_d = (double *) getGpuMem(size_v2);
	//t3_p = (double *) getHostMem(size_t3);
	streams = (cudaStream_t *) malloc(nstreams * sizeof(cudaStream_t));
/*	assert(streams != NULL);
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaStreamCreate(&streams[i]));
	}*/
	CUDA_SAFE(cudaMemcpy(t2_d, t2, size_t2, cudaMemcpyHostToDevice));
	CUDA_SAFE(cudaMemcpy(v2_d, v2, size_v2, cudaMemcpyHostToDevice));

	p4ld_t2 = 1;
	h1ld_t2 = p4d ;

	h3ld_v2 = 1;
	h2ld_v2 = h3d;
	p6ld_v2 = h3d *  h2d;
//	p5ld_v2 = p6d * h3d * p7d;
	h3ld_t3 = 1;
	h1ld_t3 = h3d;
	h2ld_t3 = h1d * h3d;
	p6ld_t3 = h1d * h2d * h3d;
//	p5ld_t3 = p6d * h1d * h2d * h3d;
	p4ld_t3 = p5d * p6d * h1d * h2d * h3d;
  size_t total_x = h3d*h2d*p6d*p5d;
  dim3 dimBlock(T2*T1);dim3 dimGrid(DIV_UB(total_x,T2*T1), 1);
//  for(i=0;i<nstreams;++i){

    sd_t_s1_2_kernel<<<dimGrid,dimBlock,0>>>(h1d,h2d,h3d,p4d,p5d*p6d,p4ld_t2,h1ld_t2,h3ld_v2,h2ld_v2,p6ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,t2_d,v2_d,i,total_x, t3_s_d);
		CHECK_ERR("Kernel execution failed");
//	}
/*
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaMemcpyAsync(((char *) t3_p) + i * size_block_t3, ((char *) t3_s_d) + i * size_block_t3, size_block_t3, cudaMemcpyDeviceToHost, streams[i]));
	}

	stream = 0;
	while (stream < nstreams) {
		while (cudaStreamQuery(streams[stream]) != cudaSuccess);
		double         *src = &t3_p[stream * size_el_block_t3];
		double         *dst = &t3[stream * size_el_block_t3];
		for (i = 0; i < size_el_block_t3; ++i) {
			dst[i] = src[i];
		}
		stream++;
	}*/
	cudaDeviceSynchronize();
//	CUDA_SAFE(cudaMemcpy(((char *) t3) , ((char *) t3_s_d) , size_t3, cudaMemcpyDeviceToHost));
/*
	for (i = 0; i < nstreams; ++i) {
		cudaStreamDestroy(streams[i]);
	}*/
	freeGpuMem(t2_d);
	freeGpuMem(v2_d);
	//freeHostMem(t3_p);
	free(streams);
}
           void 
sd_t_s1_2_cuda_(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d, double *t3, double *t2, double *v2)
{
	sd_t_s1_2_cuda((size_t) *h1d, (size_t) *h2d, (size_t) *h3d, (size_t) *p4d, (size_t) *p5d, (size_t) *p6d,  t3, t2, v2);
}
           void 
sd_t_s1_3_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d,  double *t3, double *t2, double *v2)
{
    // double st, et;
  //ckbn    st = timer();
  size_t          p4ld_t2, h1ld_t2, h2ld_v2, h3ld_v2, h1ld_t3,
                  p6ld_v2, p4ld_t3, h3ld_t3, h2ld_t3, p6ld_t3;
                  //p7ld_t2, p7ld_v2, p5ld_v2, p5ld_t3;
	size_t          /*size_t3, size_block_t3, size_el_block_t3,*/ size_t2,
	                size_v2;
	cudaStream_t   *streams;
	size_t          nstreams, i=0;
	double         *t2_d, *v2_d;// *t3_p;
	//size_t3 = h3d * h2d * h1d * p6d * p5d * p4d * sizeof(double);
	size_t2 = p4d * h1d * sizeof(double);
	size_v2 = h3d * h2d * p6d * p5d * sizeof(double);
	nstreams = 1;
	//size_block_t3=size_t3 / nstreams;
	//size_el_block_t3=size_block_t3 / sizeof(double);
  /*  if(first==1)
    {
        t3_d = (double *) getGpuMem(size_t3);
        cudaMemset(t3_d,0,size_t3*sizeof(double));
        first = 0;
    }
*/
	t2_d = (double *) getGpuMem(size_t2);
	v2_d = (double *) getGpuMem(size_v2);
	//t3_p = (double *) getHostMem(size_t3);
	streams = (cudaStream_t *) malloc(nstreams * sizeof(cudaStream_t));
	assert(streams != NULL);
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaStreamCreate(&streams[i]));
	}
	CUDA_SAFE(cudaMemcpy(t2_d, t2, size_t2, cudaMemcpyHostToDevice));
	CUDA_SAFE(cudaMemcpy(v2_d, v2, size_v2, cudaMemcpyHostToDevice));

	p4ld_t2 = 1;
	h1ld_t2 = p4d ;

	h3ld_v2 = 1;
	h2ld_v2 = h3d;
	p6ld_v2 = h3d *  h2d;
//	p5ld_v2 = p6d * h3d * p7d;
	h1ld_t3 = 1;
	h3ld_t3 = h1d;
	h2ld_t3 = h1d * h3d;
	p6ld_t3 = h1d * h2d * h3d;
//	p5ld_t3 = p6d * h1d * h2d * h3d;
	p4ld_t3 = p5d * p6d * h1d * h2d * h3d;
  size_t total_x = h3d*h2d*p6d*p5d;
  dim3 dimBlock(T2*T1);dim3 dimGrid(DIV_UB(total_x,T2*T1), 1);
  for(i=0;i<nstreams;++i){
    sd_t_s1_1_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d*p6d,p4ld_t2,h1ld_t2,h3ld_v2,h2ld_v2,p6ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,t2_d,v2_d,i,total_x, t3_s_d);
		CHECK_ERR("Kernel execution failed");
	}
/*
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaMemcpyAsync(((char *) t3_p) + i * size_block_t3, ((char *) t3_s_d) + i * size_block_t3, size_block_t3, cudaMemcpyDeviceToHost, streams[i]));
	}

	stream = 0;
	while (stream < nstreams) {
		while (cudaStreamQuery(streams[stream]) != cudaSuccess);
		double         *src = &t3_p[stream * size_el_block_t3];
		double         *dst = &t3[stream * size_el_block_t3];
		for (i = 0; i < size_el_block_t3; ++i) {
			dst[i] = src[i];
		}
		stream++;
	}
*/	cudaDeviceSynchronize();
	//CUDA_SAFE(cudaMemcpy(((char *) t3) , ((char *) t3_s_d) , size_t3, cudaMemcpyDeviceToHost));

	for (i = 0; i < nstreams; ++i) {
		cudaStreamDestroy(streams[i]);
	}
//	freeGpuMem(t3_d);
	freeGpuMem(t2_d);
	freeGpuMem(v2_d);
	//freeHostMem(t3_p);
	free(streams);
}
#undef T1
#undef T2
#undef Tcomm
           void 
sd_t_s1_3_cuda_(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d,  double *t3, double *t2, double *v2)
{
	sd_t_s1_3_cuda((size_t) *h1d, (size_t) *h2d, (size_t) *h3d, (size_t) *p4d, (size_t) *p5d, (size_t) *p6d, t3, t2, v2);
}
/*----------------------------------------------------------------------*
 *t3[h3,h2,h1,p6,p4,p5] -= t2[p4,h1] * v2[h3,h2,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_s1_4_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p5d,size_t p6d,size_t p4ld_t2,size_t h1ld_t2,size_t h3ld_v2,size_t h2ld_v2,size_t p6ld_v2,size_t p5ld_v2,size_t h3ld_t3,size_t h2ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p5ld_t3,size_t p4ld_t3,double *t3d, double *t2_d, double *v2_d,size_t p4, size_t total_x) {
  size_t h1,h2,h3,p6,p5;
  __shared__ double t2_shm[T1*4*Tcomm];
  
  for(size_t i=threadIdx.x;i<h1d*p4d;i+=blockDim.x)
  if(i<h1d*p4d)
  t2_shm[i] = t2_d[i];
  size_t rest_x=blockIdx.x;
  size_t thread_x = T2*T1 * rest_x + threadIdx.x;
  rest_x = thread_x;
    __syncthreads();
/* the following computation may need to happen inside the loop */
  for(size_t i=0;i<total_x;i+=gridDim.x*blockDim.x)
  {
    rest_x += i;
  	h3=rest_x%h3d;
  	rest_x=rest_x/h3d;
  	h2=rest_x%h2d;
  	rest_x=rest_x/h2d;
  	p6=rest_x%p6d;
  	rest_x=rest_x/p6d;
  	p5=rest_x%p5d;

    if((thread_x+i)<total_x)
  	for(h1=0;h1<h1d;h1++)
  	for(p4=0;p4<p4d;p4++)
  	{
     	t3d[h3*h3ld_t3+h2*h2ld_t3+h1*h1ld_t3+p6*p6ld_t3+p5*p5ld_t3+p4*p4ld_t3]-=t2_shm[h1*p4d+p4]*v2_d[h3*h3ld_v2+h2*h2ld_v2+p6*p6ld_v2+p5*p5ld_v2];
  	}
  }
    __syncthreads();
}

           void 
sd_t_s1_4_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d,  double *t3, double *t2, double *v2)
{
    // double st, et;
  //ckbn    st = timer(); 
  size_t          p4ld_t2, h1ld_t2, h2ld_v2, h3ld_v2, h1ld_t3,
                  p6ld_v2, p4ld_t3, h3ld_t3, h2ld_t3, p6ld_t3,
                  /*p7ld_t2, p7ld_v2*/ p5ld_v2, p5ld_t3;
	size_t          /*size_t3, size_block_t3, size_el_block_t3,*/ size_t2,
	                size_v2;
	cudaStream_t   *streams;
	size_t          nstreams, i=0;
	double         *t2_d, *v2_d; // *t3_p;
	//size_t3 = h3d * h2d * h1d * p6d * p5d * p4d * sizeof(double);
	size_t2 = p4d * h1d * sizeof(double);
	size_v2 = h3d * h2d * p6d * p5d * sizeof(double);
	nstreams = 1;
	//size_block_t3=size_t3 / nstreams;
	//size_el_block_t3=size_block_t3 / sizeof(double);
  /*  if(first==1)
    {
        t3_d = (double *) getGpuMem(size_t3);
        cudaMemset(t3_d,0,size_t3*sizeof(double));
        first = 0;
    }
*/
//	t3_d = (double *) getGpuMem(size_t3);
	t2_d = (double *) getGpuMem(size_t2);
	v2_d = (double *) getGpuMem(size_v2);
	//t3_p = (double *) getHostMem(size_t3);
	streams = (cudaStream_t *) malloc(nstreams * sizeof(cudaStream_t));
/*	assert(streams != NULL);
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaStreamCreate(&streams[i]));
	}*/
	CUDA_SAFE(cudaMemcpy(t2_d, t2, size_t2, cudaMemcpyHostToDevice));
	CUDA_SAFE(cudaMemcpy(v2_d, v2, size_v2, cudaMemcpyHostToDevice));

	p4ld_t2 = 1;
	h1ld_t2 = p4d;

	h3ld_v2 = 1;
	h2ld_v2 = h3d;
	p6ld_v2 = h3d * h2d;
	p5ld_v2 = p6d * h3d * h2d;
	h3ld_t3 = 1;
	h2ld_t3 = h3d;
	h1ld_t3 = h2d * h3d;
	p6ld_t3 = h1d * h2d * h3d;
	p4ld_t3 = p6d * h1d * h2d * h3d;
	p5ld_t3 = p4d * p6d * h1d * h2d * h3d;
  size_t total_x = h3d*h2d*p6d*p5d;
  dim3 dimBlock(T2*T1);dim3 dimGrid(DIV_UB(total_x,T2*T1), 1);
   i=0;
 // for(i=0;i<nstreams;++i){
    sd_t_s1_4_kernel<<<dimGrid,dimBlock,0>>>(h1d,h2d,h3d,p4d,p5d,p6d,p4ld_t2,h1ld_t2,h3ld_v2,h2ld_v2,p6ld_v2,p5ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p5ld_t3,p4ld_t3,t3_s_d,t2_d,v2_d,i,total_x);
    //sd_t_s1_4_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d,p6d,p4ld_t2,h1ld_t2,h3ld_v2,h2ld_v2,p6ld_v2,p5ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p5ld_t3,p4ld_t3,t3_d,t2_d,v2_d,i,total_x);
		CHECK_ERR("Kernel execution failed");
//	}


	cudaDeviceSynchronize();
	/*	CUDA_SAFE(cudaMemcpy(((char *) t3_p) , ((char *) t3_d) , size_block_t3, cudaMemcpyDeviceToHost));
	printf("Time for Async DeviceToHost %f\n", et-st);
	stream = 0;
//	while (stream < nstreams) {
//		while (cudaStreamQuery(streams[stream]) != cudaSuccess);
		double         *src = t3_p; //[stream * size_el_block_t3];
		double         *dst = t3;  //[stream * size_el_block_t3];
		for (i = 0; i < size_el_block_t3; ++i) {
			dst[i] -= src[i];
		}
//		stream++;
//	}
*/
//	cudaDeviceSynchronize();
/*
	for (i = 0; i < nstreams; ++i) {
		cudaStreamDestroy(streams[i]);
	}*/
//	freeGpuMem(t3_d);
	freeGpuMem(t2_d);
	freeGpuMem(v2_d);
	//freeHostMem(t3_p);
	free(streams);
}
#undef T1
#undef T2
#undef Tcomm
           void 
sd_t_s1_4_cuda_(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d, double *t3, double *t2, double *v2)
{
	sd_t_s1_4_cuda((size_t) *h1d, (size_t) *h2d, (size_t) *h3d, (size_t) *p4d, (size_t) *p5d, (size_t) *p6d,  t3, t2, v2);
}

/*----------------------------------------------------------------------*
 *t3[h3,h1,h2,p6,p4,p5] -= t2[p4,h1] * v2[h3,h2,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_s1_5_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p5d,size_t p6d,size_t p4ld_t2,size_t h1ld_t2,size_t h3ld_v2,size_t h2ld_v2,size_t p6ld_v2,size_t p5ld_v2,size_t h3ld_t3,size_t h2ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p5ld_t3,size_t p4ld_t3,double *t3d, double *t2_d, double *v2_d,size_t p4, size_t total_x) {
  size_t h1,h2,h3,p6,p5;
  __shared__ double t2_shm[T1*4*Tcomm];
  
  for(size_t i=threadIdx.x;i<h1d*p4d;i+=blockDim.x)
  if(i<h1d*p4d)
  t2_shm[i] = t2_d[i];
  size_t rest_x=blockIdx.x;
  size_t thread_x = T2*T1 * rest_x + threadIdx.x;
  rest_x = thread_x;
    __syncthreads();
/* the following computation may need to happen inside the loop */
  for(size_t i=0;i<total_x;i+=gridDim.x*blockDim.x)
  {
    rest_x += i;
  	h3=rest_x%h3d;
  	rest_x=rest_x/h3d;
  	h2=rest_x%h2d;
  	rest_x=rest_x/h2d;
  	p6=rest_x%p6d;
  	rest_x=rest_x/p6d;
  	p5=rest_x%p5d;

    if((thread_x+i)<total_x)
  	for(h1=0;h1<h1d;h1++)
  	for(p4=0;p4<p4d;p4++)
  	{
     	t3d[h3*h3ld_t3+h2*h2ld_t3+h1*h1ld_t3+p6*p6ld_t3+p5*p5ld_t3+p4*p4ld_t3]+=t2_shm[h1*p4d+p4]*v2_d[h3*h3ld_v2+h2*h2ld_v2+p6*p6ld_v2+p5*p5ld_v2];
  	}
  }
    __syncthreads();
}

           void 
sd_t_s1_5_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d,  double *t3, double *t2, double *v2)
{
    // double st, et;
  //ckbn    st = timer(); 
  size_t          p4ld_t2, h1ld_t2, h2ld_v2, h3ld_v2, h1ld_t3,
                  p6ld_v2, p4ld_t3, h3ld_t3, h2ld_t3, p6ld_t3,
                  /*p7ld_t2, p7ld_v2*/ p5ld_v2, p5ld_t3;

	size_t          /*size_t3, size_block_t3, size_el_block_t3,*/ size_t2,
	                size_v2;
	cudaStream_t   *streams;
	size_t          nstreams, i=0;
	double         *t2_d, *v2_d;// *t3_p;
	//size_t3 = h3d * h2d * h1d * p6d * p5d * p4d * sizeof(double);
	size_t2 = p4d * h1d * sizeof(double);
	size_v2 = h3d * h2d * p6d * p5d * sizeof(double);
	nstreams = 1;
	//size_block_t3=size_t3 / nstreams;
	//size_el_block_t3=size_block_t3 / sizeof(double);
  /*  if(first==1)
    {
        t3_d = (double *) getGpuMem(size_t3);
        cudaMemset(t3_d,0,size_t3*sizeof(double));
        first = 0;
    }
*/
//	t3_d = (double *) getGpuMem(size_t3);
	t2_d = (double *) getGpuMem(size_t2);
	v2_d = (double *) getGpuMem(size_v2);
	//t3_p = (double *) getHostMem(size_t3);
	streams = (cudaStream_t *) malloc(nstreams * sizeof(cudaStream_t));
	assert(streams != NULL);
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaStreamCreate(&streams[i]));
	}
	CUDA_SAFE(cudaMemcpy(t2_d, t2, size_t2, cudaMemcpyHostToDevice));
	CUDA_SAFE(cudaMemcpy(v2_d, v2, size_v2, cudaMemcpyHostToDevice));

	p4ld_t2 = 1;
	h1ld_t2 = p4d ;

	h3ld_v2 = 1;
	h2ld_v2 = h3d;
	p6ld_v2 = h3d * h2d;
	p5ld_v2 = p6d * h3d * h2d;
	h3ld_t3 = 1;
	h1ld_t3 = h3d;
	h2ld_t3 = h1d * h3d;
	p6ld_t3 = h1d * h2d * h3d;
	p4ld_t3 = p6d * h1d * h2d * h3d;
	p5ld_t3 = p4d * p6d * h1d * h2d * h3d;
  size_t total_x = h3d*h2d*p6d*p5d;
  dim3 dimBlock(T2*T1);dim3 dimGrid(DIV_UB(total_x,T2*T1), 1);
  for(i=0;i<nstreams;++i){
    sd_t_s1_5_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d,p6d,p4ld_t2,h1ld_t2,h3ld_v2,h2ld_v2,p6ld_v2,p5ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p5ld_t3,p4ld_t3,t3_s_d,t2_d,v2_d,i,total_x);
		CHECK_ERR("Kernel execution failed");
	}
/*
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaMemcpyAsync(((char *) t3_p) + i * size_block_t3, ((char *) t3_s_d) + i * size_block_t3, size_block_t3, cudaMemcpyDeviceToHost, streams[i]));
	}

	stream = 0;
	while (stream < nstreams) {
		while (cudaStreamQuery(streams[stream]) != cudaSuccess);
		double         *src = &t3_p[stream * size_el_block_t3];
		double         *dst = &t3[stream * size_el_block_t3];
		for (i = 0; i < size_el_block_t3; ++i) {
			dst[i] = src[i];
		}
		stream++;
	}
*/
	cudaDeviceSynchronize();

	//CUDA_SAFE(cudaMemcpy(((char *) t3) , ((char *) t3_s_d) , size_t3, cudaMemcpyDeviceToHost));
	for (i = 0; i < nstreams; ++i) {
		cudaStreamDestroy(streams[i]);
	}
//	freeGpuMem(t3_d);
	freeGpuMem(t2_d);
	freeGpuMem(v2_d);
	//freeHostMem(t3_p);
	free(streams);
}
#undef T1
#undef T2
#undef Tcomm
           void 
sd_t_s1_5_cuda_(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d,  double *t3, double *t2, double *v2)
{
	sd_t_s1_5_cuda((size_t) *h1d, (size_t) *h2d, (size_t) *h3d, (size_t) *p4d, (size_t) *p5d, (size_t) *p6d,  t3, t2, v2);
}

/*----------------------------------------------------------------------*
 *t3[h1,h3,h2,p6,p4,p5] -= t2[p4,h1] * v2[h3,h2,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_s1_6_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p5d,size_t p6d,size_t p4ld_t2,size_t h1ld_t2,size_t h3ld_v2,size_t h2ld_v2,size_t p6ld_v2,size_t p5ld_v2,size_t h3ld_t3,size_t h2ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p5ld_t3,size_t p4ld_t3,double *t3d, double *t2_d, double *v2_d,size_t p4, size_t total_x) {
  size_t h1,h2,h3,p6,p5;
  __shared__ double t2_shm[T1*4*Tcomm];
  
  for(size_t i=threadIdx.x;i<h1d*p4d;i+=blockDim.x)
  if(i<h1d*p4d)
  t2_shm[i] = t2_d[i];
  size_t rest_x=blockIdx.x;
  size_t thread_x = T2*T1 * rest_x + threadIdx.x;
  rest_x = thread_x;
    __syncthreads();
/* the following computation may need to happen inside the loop */
  for(size_t i=0;i<total_x;i+=gridDim.x*blockDim.x)
  {
    rest_x += i;
  	h3=rest_x%h3d;
  	rest_x=rest_x/h3d;
  	h2=rest_x%h2d;
  	rest_x=rest_x/h2d;
  	p6=rest_x%p6d;
  	rest_x=rest_x/p6d;
  	p5=rest_x%p5d;

    if((thread_x+i)<total_x)
  	for(h1=0;h1<h1d;h1++)
  	for(p4=0;p4<p4d;p4++)
  	{
     	t3d[h3*h3ld_t3+h2*h2ld_t3+h1*h1ld_t3+p6*p6ld_t3+p5*p5ld_t3+p4*p4ld_t3]-=t2_shm[h1*p4d+p4]*v2_d[h3*h3ld_v2+h2*h2ld_v2+p6*p6ld_v2+p5*p5ld_v2];
  	}
  }
    __syncthreads();
}

           void 
sd_t_s1_6_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d,  double *t3, double *t2, double *v2)
{
    // double st, et;
  //ckbn    st = timer(); 
  size_t          p4ld_t2, h1ld_t2, h2ld_v2, h3ld_v2, h1ld_t3,
                  p6ld_v2, p4ld_t3, h3ld_t3, h2ld_t3, p6ld_t3,
                  /*p7ld_t2, p7ld_v2*/ p5ld_v2, p5ld_t3;

	size_t          /*size_t3, size_block_t3, size_el_block_t3,*/ size_t2,
	                size_v2;
	cudaStream_t   *streams;
	size_t          nstreams, i=0;
	double          *t2_d, *v2_d;// *t3_p;
	//size_t3 = h3d * h2d * h1d * p6d * p5d * p4d * sizeof(double);
	size_t2 = p4d * h1d * sizeof(double);
	size_v2 = h3d * h2d * p6d * p5d * sizeof(double);
	nstreams = 1;
	//size_block_t3=size_t3 / nstreams;
	//size_el_block_t3=size_block_t3 / sizeof(double);
  /*  if(first==1)
    {
        t3_d = (double *) getGpuMem(size_t3);
        cudaMemset(t3_d,0,size_t3*sizeof(double));
        first = 0;
    }
*/
//	t3_d = (double *) getGpuMem(size_t3);
	t2_d = (double *) getGpuMem(size_t2);
	v2_d = (double *) getGpuMem(size_v2);
	//t3_p = (double *) getHostMem(size_t3);
	streams = (cudaStream_t *) malloc(nstreams * sizeof(cudaStream_t));
	assert(streams != NULL);
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaStreamCreate(&streams[i]));
	}
	CUDA_SAFE(cudaMemcpy(t2_d, t2, size_t2, cudaMemcpyHostToDevice));
	CUDA_SAFE(cudaMemcpy(v2_d, v2, size_v2, cudaMemcpyHostToDevice));

	p4ld_t2 = 1;
	h1ld_t2 = p4d;

	h3ld_v2 = 1;
	h2ld_v2 = h3d;
	p6ld_v2 = h3d * h2d;
	p5ld_v2 = p6d * h3d * h2d;
	h1ld_t3 = 1;
	h3ld_t3 = h1d;
	h2ld_t3 = h1d * h3d;
	p6ld_t3 = h1d * h2d * h3d;
	p4ld_t3 = p6d * h1d * h2d * h3d;
	p5ld_t3 = p4d * p6d * h1d * h2d * h3d;
  size_t total_x = h3d*h2d*p6d*p5d;
  dim3 dimBlock(T2*T1);dim3 dimGrid(DIV_UB(total_x,T2*T1), 1);
  for(i=0;i<nstreams;++i){
    sd_t_s1_6_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d,p6d,p4ld_t2,h1ld_t2,h3ld_v2,h2ld_v2,p6ld_v2,p5ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p5ld_t3,p4ld_t3,t3_s_d,t2_d,v2_d,i,total_x);
		CHECK_ERR("Kernel execution failed");
	}
/*	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaMemcpyAsync(((char *) t3_p) + i * size_block_t3, ((char *) t3_s_d) + i * size_block_t3, size_block_t3, cudaMemcpyDeviceToHost, streams[i]));
	}

	stream = 0;
	while (stream < nstreams) {
		while (cudaStreamQuery(streams[stream]) != cudaSuccess);
		double         *src = &t3_p[stream * size_el_block_t3];
		double         *dst = &t3[stream * size_el_block_t3];
		for (i = 0; i < size_el_block_t3; ++i) {
			dst[i] = src[i];
		}
		stream++;
	}*/
	cudaDeviceSynchronize();
	//CUDA_SAFE(cudaMemcpy(((char *) t3) , ((char *) t3_s_d) , size_t3, cudaMemcpyDeviceToHost));

	for (i = 0; i < nstreams; ++i) {
		cudaStreamDestroy(streams[i]);
	}
//	freeGpuMem(t3_d);
	freeGpuMem(t2_d);
	freeGpuMem(v2_d);
	//freeHostMem(t3_p);
	free(streams);
}
#undef T1
#undef T2
#undef Tcomm
           void 
sd_t_s1_6_cuda_(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d, double *t3, double *t2, double *v2)
{
	sd_t_s1_6_cuda((size_t) *h1d, (size_t) *h2d, (size_t) *h3d, (size_t) *p4d, (size_t) *p5d, (size_t) *p6d, t3, t2, v2);
}









/*----------------------------------------------------------------------*
 *t3[h3,h2,h1,p4,p6,p5] -= t2[p4,h1] * v2[h3,h2,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_s1_7_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p6d,size_t p4ld_t2,size_t h1ld_t2,size_t h3ld_v2,size_t h2ld_v2,size_t p6ld_v2,size_t h3ld_t3,size_t h2ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p4ld_t3,double *t3d, double *t2_d, double *v2_d,size_t p4, size_t total_x) {
  size_t h1,h2,h3,p6;
  __shared__ double t2_shm[T1*4*Tcomm];
  
  for(size_t i=threadIdx.x;i<h1d*p4d;i+=blockDim.x)
  if(i<h1d*p4d)
  t2_shm[i] = t2_d[i];
  size_t rest_x=blockIdx.x;
  size_t thread_x = T2*T1 * rest_x + threadIdx.x;
  rest_x = thread_x;
    __syncthreads();
/* the following computation may need to happen inside the loop */
  for(size_t i=0;i<total_x;i+=gridDim.x*blockDim.x)
  {
    rest_x += i;
  	h3=rest_x%h3d;
  	rest_x=rest_x/h3d;
  	h2=rest_x%h2d;
  	rest_x=rest_x/h2d;
  	p6=rest_x%p6d;

    if((thread_x+i)<total_x)
  	for(h1=0;h1<h1d;h1++)
  	for(p4=0;p4<p4d;p4++)
  	{
     	t3d[h3*h3ld_t3+h2*h2ld_t3+h1*h1ld_t3+p6*p6ld_t3+p4*p4ld_t3]+=t2_shm[h1*p4d+p4]*v2_d[h3*h3ld_v2+h2*h2ld_v2+p6*p6ld_v2];
  	}
  }
    __syncthreads();
}
           void 
sd_t_s1_7_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d,  double *t3, double *t2, double *v2)
{
    // double st, et;
  //ckbn    st = timer(); 
  size_t          p4ld_t2, h1ld_t2, h2ld_v2, h3ld_v2, h1ld_t3,
                  p6ld_v2, p4ld_t3, h3ld_t3, h2ld_t3, p6ld_t3;
                  //p7ld_t2, p7ld_v2, p5ld_v2, p5ld_t3;

	size_t          /*size_t3, size_block_t3, size_el_block_t3,*/ size_t2,
	                size_v2;
	cudaStream_t   *streams;
	size_t          nstreams, i=0;
	double         *t2_d, *v2_d;// *t3_p;
	//size_t3 = h3d * h2d * h1d * p6d * p5d * p4d * sizeof(double);
	size_t2 = p4d * h1d * sizeof(double);
	size_v2 = h3d * h2d * p6d * p5d * sizeof(double);
	nstreams = 1;
	//size_block_t3=size_t3 / nstreams;
	//size_el_block_t3=size_block_t3 / sizeof(double);
  /*  if(first==1)
    {
        t3_d = (double *) getGpuMem(size_t3);
        cudaMemset(t3_d,0,size_t3*sizeof(double));
        first = 0;
    }
*/
//	t3_d = (double *) getGpuMem(size_t3);
	t2_d = (double *) getGpuMem(size_t2);
	v2_d = (double *) getGpuMem(size_v2);
	//t3_p = (double *) getHostMem(size_t3);
	streams = (cudaStream_t *) malloc(nstreams * sizeof(cudaStream_t));
	assert(streams != NULL);
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaStreamCreate(&streams[i]));
	}
	CUDA_SAFE(cudaMemcpy(t2_d, t2, size_t2, cudaMemcpyHostToDevice));
	CUDA_SAFE(cudaMemcpy(v2_d, v2, size_v2, cudaMemcpyHostToDevice));

	p4ld_t2 = 1;
	h1ld_t2 = p4d;

	h3ld_v2 = 1;
	h2ld_v2 = h3d;
	p6ld_v2 = h3d * h2d;
//	p5ld_v2 = p6d * h3d * p7d;
	h3ld_t3 = 1;
	h2ld_t3 = h3d;
	h1ld_t3 = h2d * h3d;
	p4ld_t3 = h1d * h2d * h3d;
//	p5ld_t3 = p6d * h1d * h2d * h3d;
	p6ld_t3 = p4d * h1d * h2d * h3d;
  size_t total_x = h3d*h2d*p6d*p5d;
  dim3 dimBlock(T2*T1);dim3 dimGrid(DIV_UB(total_x,T2*T1), 1);
  for(i=0;i<nstreams;++i){
    sd_t_s1_7_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d*p6d,p4ld_t2,h1ld_t2,h3ld_v2,h2ld_v2,p6ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,t3_s_d,t2_d,v2_d,i,total_x);
		CHECK_ERR("Kernel execution failed");
	}
/*
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaMemcpyAsync(((char *) t3_p) + i * size_block_t3, ((char *) t3_s_d) + i * size_block_t3, size_block_t3, cudaMemcpyDeviceToHost, streams[i]));
	}

	stream = 0;
	while (stream < nstreams) {
		while (cudaStreamQuery(streams[stream]) != cudaSuccess);
		double         *src = &t3_p[stream * size_el_block_t3];
		double         *dst = &t3[stream * size_el_block_t3];
		for (i = 0; i < size_el_block_t3; ++i) {
			dst[i] = src[i];
		}
		stream++;
	}*/
	cudaDeviceSynchronize();
	//CUDA_SAFE(cudaMemcpy(((char *) t3) , ((char *) t3_s_d) , size_t3, cudaMemcpyDeviceToHost));

	for (i = 0; i < nstreams; ++i) {
		cudaStreamDestroy(streams[i]);
	}
//	freeGpuMem(t3_d);
	freeGpuMem(t2_d);
	freeGpuMem(v2_d);
	//freeHostMem(t3_p);
	free(streams);
}
#undef T1
#undef T2
#undef Tcomm
           void 
sd_t_s1_7_cuda_(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d, double *t3, double *t2, double *v2)
{
	sd_t_s1_7_cuda((size_t) *h1d, (size_t) *h2d, (size_t) *h3d, (size_t) *p4d, (size_t) *p5d, (size_t) *p6d, t3, t2, v2);
}
#define T1 16
#define T2 16
#define Tcomm 16
__global__ void sd_t_s1_8_kernel(size_t h1d,size_t h2d,size_t h3d,size_t p4d,size_t p6d,size_t p4ld_t2,size_t h1ld_t2,size_t h3ld_v2,size_t h2ld_v2,size_t p6ld_v2,size_t h3ld_t3,size_t h2ld_t3,size_t h1ld_t3,size_t p6ld_t3,size_t p4ld_t3,double *t3d, double *t2_d, double *v2_d,size_t p4, size_t total_x) {
  size_t h1,h2,h3,p6;
  __shared__ double t2_shm[T1*4*Tcomm];
  
  for(size_t i=threadIdx.x;i<h1d*p4d;i+=blockDim.x)
  if(i<h1d*p4d)
  t2_shm[i] = t2_d[i];
  size_t rest_x=blockIdx.x;
  size_t thread_x = T2*T1 * rest_x + threadIdx.x;
  rest_x = thread_x;
    __syncthreads();
/* the following computation may need to happen inside the loop */
  for(size_t i=0;i<total_x;i+=gridDim.x*blockDim.x)
  {
    rest_x += i;
  	h3=rest_x%h3d;
  	rest_x=rest_x/h3d;
  	h2=rest_x%h2d;
  	rest_x=rest_x/h2d;
  	p6=rest_x%p6d;

    if((thread_x+i)<total_x)
  	for(h1=0;h1<h1d;h1++)
  	for(p4=0;p4<p4d;p4++)
  	{
     	t3d[h3*h3ld_t3+h2*h2ld_t3+h1*h1ld_t3+p6*p6ld_t3+p4*p4ld_t3]-=t2_shm[h1*p4d+p4]*v2_d[h3*h3ld_v2+h2*h2ld_v2+p6*p6ld_v2];
  	}
  }
    __syncthreads();
}
/*----------------------------------------------------------------------*
 *t3[h3,h1,h2,p4,p6,p5] -= t2[p4,h1] * v2[h3,h2,p6,p5]
 *----------------------------------------------------------------------*/
#define T1 16
#define T2 16
#define Tcomm 16
           void 
sd_t_s1_8_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d,  double *t3, double *t2, double *v2)
{
    // double st, et;
  //ckbn    st = timer(); 
  size_t          p4ld_t2, h1ld_t2, h2ld_v2, h3ld_v2, h1ld_t3,
                  p6ld_v2, p4ld_t3, h3ld_t3, h2ld_t3, p6ld_t3;
                  //p7ld_t2, p7ld_v2, p5ld_v2, p5ld_t3;

	size_t          /*size_t3, size_block_t3, size_el_block_t3,*/ size_t2,
	                size_v2;
	cudaStream_t   *streams;
	size_t          nstreams, i=0;
	double          *t2_d, *v2_d;// *t3_p;
	//size_t3 = h3d * h2d * h1d * p6d * p5d * p4d * sizeof(double);
	size_t2 = p4d * h1d * sizeof(double);
	size_v2 = h3d * h2d * p6d * p5d * sizeof(double);
	nstreams = 1;
	//size_block_t3=size_t3 / nstreams;
	//size_el_block_t3=size_block_t3 / sizeof(double);
  /*  if(first==1)
    {
        t3_d = (double *) getGpuMem(size_t3);
        cudaMemset(t3_d,0,size_t3*sizeof(double));
        first = 0;
    }
*/
//	t3_d = (double *) getGpuMem(size_t3);
	t2_d = (double *) getGpuMem(size_t2);
	v2_d = (double *) getGpuMem(size_v2);
	//t3_p = (double *) getHostMem(size_t3);
	streams = (cudaStream_t *) malloc(nstreams * sizeof(cudaStream_t));
	assert(streams != NULL);
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaStreamCreate(&streams[i]));
	}
	CUDA_SAFE(cudaMemcpy(t2_d, t2, size_t2, cudaMemcpyHostToDevice));
	CUDA_SAFE(cudaMemcpy(v2_d, v2, size_v2, cudaMemcpyHostToDevice));

	p4ld_t2 = 1;
	h1ld_t2 = p4d;

	h3ld_v2 = 1;
	h2ld_v2 = h3d;
	p6ld_v2 = h3d * h2d;
//	p5ld_v2 = p6d * h3d * p7d;
	h3ld_t3 = 1;
	h1ld_t3 = h3d;
	h2ld_t3 = h1d * h3d;
	p4ld_t3 = h1d * h2d * h3d;
//	p5ld_t3 = p6d * h1d * h2d * h3d;
	p6ld_t3 = p4d * h1d * h2d * h3d;
  size_t total_x = h3d*h2d*p6d*p5d;
  dim3 dimBlock(T2*T1);dim3 dimGrid(DIV_UB(total_x,T2*T1), 1);
  for(i=0;i<nstreams;++i){
    sd_t_s1_8_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d*p6d,p4ld_t2,h1ld_t2,h3ld_v2,h2ld_v2,p6ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,t3_s_d,t2_d,v2_d,i,total_x);
		CHECK_ERR("Kernel execution failed");
	}
/*
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaMemcpyAsync(((char *) t3_p) + i * size_block_t3, ((char *) t3_s_d) + i * size_block_t3, size_block_t3, cudaMemcpyDeviceToHost, streams[i]));
	}
	stream = 0;
	while (stream < nstreams) {
		while (cudaStreamQuery(streams[stream]) != cudaSuccess);
		double         *src = &t3_p[stream * size_el_block_t3];
		double         *dst = &t3[stream * size_el_block_t3];
		for (i = 0; i < size_el_block_t3; ++i) {
			dst[i] = src[i];
		}
		stream++;
	}*/
	cudaDeviceSynchronize();
//	CUDA_SAFE(cudaMemcpy(((char *) t3) , ((char *) t3_s_d) , size_t3, cudaMemcpyDeviceToHost));

	for (i = 0; i < nstreams; ++i) {
		cudaStreamDestroy(streams[i]);
	}
//	freeGpuMem(t3_d);
	freeGpuMem(t2_d);
	freeGpuMem(v2_d);
	//freeHostMem(t3_p);
	free(streams);
}
           void 
sd_t_s1_8_cuda_(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d, double *t3, double *t2, double *v2)
{
	sd_t_s1_8_cuda((size_t) *h1d, (size_t) *h2d, (size_t) *h3d, (size_t) *p4d, (size_t) *p5d, (size_t) *p6d, t3, t2, v2);
}
/*----------------------------------------------------------------------*
 *t3[h1,h3,h2,p4,p6,p5] -= t2[p4,h1] * v2[h3,h2,p6,p5]
 *----------------------------------------------------------------------*/
           void 
sd_t_s1_9_cuda(size_t h1d, size_t h2d, size_t h3d, size_t p4d, size_t p5d, size_t p6d,  double *t3, double *t2, double *v2)
{
    // double st, et;
  //ckbn    st = timer(); 
  size_t          p4ld_t2, h1ld_t2, h2ld_v2, h3ld_v2, h1ld_t3,
                  p6ld_v2, p4ld_t3, h3ld_t3, h2ld_t3, p6ld_t3;
                  //p7ld_t2, p7ld_v2, p5ld_v2, p5ld_t3;

	size_t          /*size_t3, size_block_t3, size_el_block_t3,*/ size_t2,
	                size_v2;
	cudaStream_t   *streams;
	size_t          nstreams, i=0;
	double          *t2_d, *v2_d;// *t3_p;
	//size_t3 = h3d * h2d * h1d * p6d * p5d * p4d * sizeof(double);
	size_t2 = p4d * h1d * sizeof(double);
	size_v2 = h3d * h2d * p6d * p5d * sizeof(double);
	nstreams = 1;
	//size_block_t3=size_t3 / nstreams;
	//size_el_block_t3=size_block_t3 / sizeof(double);
  /*  if(first==1)
    {
        t3_d = (double *) getGpuMem(size_t3);
        cudaMemset(t3_d,0,size_t3*sizeof(double));
        first = 0;
    }
*/
//	t3_d = (double *) getGpuMem(size_t3);
	t2_d = (double *) getGpuMem(size_t2);
	v2_d = (double *) getGpuMem(size_v2);
	//t3_p = (double *) getHostMem(size_t3);
	streams = (cudaStream_t *) malloc(nstreams * sizeof(cudaStream_t));
	assert(streams != NULL);
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaStreamCreate(&streams[i]));
	}
	CUDA_SAFE(cudaMemcpy(t2_d, t2, size_t2, cudaMemcpyHostToDevice));
	CUDA_SAFE(cudaMemcpy(v2_d, v2, size_v2, cudaMemcpyHostToDevice));

	p4ld_t2 = 1;
	h1ld_t2 = p4d;

	h3ld_v2 = 1;
	h2ld_v2 = h3d;
	p6ld_v2 = h3d * h2d;
//	p5ld_v2 = p6d * h3d * p7d;
	h1ld_t3 = 1;
	h3ld_t3 = h1d;
	h2ld_t3 = h1d * h3d;
	p4ld_t3 = h1d * h2d * h3d;
//	p5ld_t3 = p6d * h1d * h2d * h3d;
	p6ld_t3 = p4d * h1d * h2d * h3d;
  size_t total_x = h3d*h2d*p6d*p5d;
  dim3 dimBlock(T2*T1);dim3 dimGrid(DIV_UB(total_x,T2*T1), 1);
  for(i=0;i<nstreams;++i){
    sd_t_s1_7_kernel<<<dimGrid,dimBlock,0,streams[i]>>>(h1d,h2d,h3d,p4d,p5d*p6d,p4ld_t2,h1ld_t2,h3ld_v2,h2ld_v2,p6ld_v2,h3ld_t3,h2ld_t3,h1ld_t3,p6ld_t3,p4ld_t3,t3_s_d,t2_d,v2_d,i,total_x);
		CHECK_ERR("Kernel execution failed");
	}
/*
	for (i = 0; i < nstreams; ++i) {
		CUDA_SAFE(cudaMemcpyAsync(((char *) t3_p) + i * size_block_t3, ((char *) t3_s_d) + i * size_block_t3, size_block_t3, cudaMemcpyDeviceToHost, streams[i]));
	}
	stream = 0;
	while (stream < nstreams) {
		while (cudaStreamQuery(streams[stream]) != cudaSuccess);
		double         *src = &t3_p[stream * size_el_block_t3];
		double         *dst = &t3[stream * size_el_block_t3];
		for (i = 0; i < size_el_block_t3; ++i) {
			dst[i] = src[i];
		}
		stream++;
	}*/
	cudaDeviceSynchronize();
	//CUDA_SAFE(cudaMemcpy(((char *) t3) , ((char *) t3_s_d) , size_t3, cudaMemcpyDeviceToHost));

//  printf("out is %lf\n", t3_p[0]);
	for (i = 0; i < nstreams; ++i) {
		cudaStreamDestroy(streams[i]);
	}
	//freeGpuMem(t3_d);
	freeGpuMem(t2_d);
	freeGpuMem(v2_d);
	//freeHostMem(t3_p);
	free(streams);
}
           void 
sd_t_s1_9_cuda_(Integer * h1d, Integer * h2d, Integer * h3d, Integer * p4d, Integer * p5d, Integer * p6d,  double *t3, double *t2, double *v2)
{
	sd_t_s1_9_cuda((size_t) *h1d, (size_t) *h2d, (size_t) *h3d, (size_t) *p4d, (size_t) *p5d, (size_t) *p6d,  t3, t2, v2);
}

#define FUSION_SIZE_SLICE_1_H3  4
#define FUSION_SIZE_SLICE_1_H2  4
#define FUSION_SIZE_SLICE_1_H1  4
#define FUSION_SIZE_SLICE_1_P6  4
#define FUSION_SIZE_SLICE_1_P5  4
#define FUSION_SIZE_SLICE_1_P4  4
#define FUSION_SIZE_SLICE_1_P7  16

#define FUSION_SIZE_SLICE_2_H3  4
#define FUSION_SIZE_SLICE_2_H2  4
#define FUSION_SIZE_SLICE_2_H1  4
#define FUSION_SIZE_SLICE_2_P6  4
#define FUSION_SIZE_SLICE_2_P5  4
#define FUSION_SIZE_SLICE_2_P4  4
#define FUSION_SIZE_SLICE_2_P7  16

#define FUSION_SIZE_INT_UNIT 	FUSION_SIZE_SLICE_1_P7

#define FUSION_SIZE_TB_1_X 	    FUSION_SIZE_SLICE_1_H3 * FUSION_SIZE_SLICE_1_H2
#define FUSION_SIZE_TB_1_Y 	    FUSION_SIZE_SLICE_1_P6 * FUSION_SIZE_SLICE_1_H1
#define FUSION_SIZE_REG_1_X 	FUSION_SIZE_SLICE_1_P5
#define FUSION_SIZE_REG_1_Y 	FUSION_SIZE_SLICE_1_P4

#define FUSION_SIZE_TB_2_X 	    FUSION_SIZE_SLICE_2_H3 * FUSION_SIZE_SLICE_2_H2
#define FUSION_SIZE_TB_2_Y 	    FUSION_SIZE_SLICE_2_P4 * FUSION_SIZE_SLICE_2_H1
#define FUSION_SIZE_REG_2_X 	FUSION_SIZE_SLICE_2_P5
#define FUSION_SIZE_REG_2_Y     FUSION_SIZE_SLICE_2_P6

#define CEIL(a, b)              (((a) + (b) - 1) / (b))

//
__constant__ int list_stride_t2[9];
__constant__ int list_stride_v2[9];

#define DEBUG_ENALBLE_ALL_KERNEL

/*
    doubles (d1)
*/
// kernel: d1_1
__global__ void kernel_ccsdT_sd1_1(double* t3, 
    double* d_t2_1, double* d_v2_1, 
    int size_h3,    int size_h2,    int size_h1,    int size_p6,    int size_p5,    int size_p4,    int size_h7, 
    int numBlk_h3,  int numBlk_h2,  int numBlk_h1,  int numBlk_p6,  int numBlk_p5,  int numBlk_p4,
    int stride_reg_x, int stride_reg_y,
    int size_internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_2_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_2_H3;
    int idx_p4 = threadIdx.y % FUSION_SIZE_SLICE_2_P4;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_2_P4;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }

    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }

    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 +  
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_p4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < size_internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - size_internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p4 < rng_p4 && idx_h1 < rng_h1 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_2_Y] = d_t2_1[(blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_p4 + (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + ll + (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1) * size_p5) * size_p4) * size_h7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && threadIdx.y < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p6; ll++)
        {
            sm_b[threadIdx.y][threadIdx.x + ll * FUSION_SIZE_TB_2_X] = d_v2_1[blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + ll) * size_h2) * size_h3 + (threadIdx.y + l) * list_stride_v2[6]];
        }
        __syncthreads();

        // Cross-Product: -1
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            //temp_bv[0] = sm_b[ll][d_v2_1_offset[l_idx_t3] + 0];
            temp_bv[0] = sm_b[ll][idx_h3 + (idx_h2) * FUSION_SIZE_SLICE_2_H3 + 0];
            temp_bv[1] = sm_b[ll][idx_h3 + (idx_h2) * FUSION_SIZE_SLICE_2_H3 + 16];
            temp_bv[2] = sm_b[ll][idx_h3 + (idx_h2) * FUSION_SIZE_SLICE_2_H3 + 32];
            temp_bv[3] = sm_b[ll][idx_h3 + (idx_h2) * FUSION_SIZE_SLICE_2_H3 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                //temp_av = sm_a[ll][d_t2_1_offset[l_idx_t3] + (xx * 16)];
                temp_av = sm_a[ll][idx_p4 + (idx_h1) * FUSION_SIZE_SLICE_2_P4 + (xx * 16)];

                reg_tile[0][xx] -= temp_av * temp_bv[0];
                reg_tile[1][xx] -= temp_av * temp_bv[1];
                reg_tile[2][xx] -= temp_av * temp_bv[2];
                reg_tile[3][xx] -= temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d1_1
void jk_ccsd_t_d1_1(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_h7, double* host_t3, double* host_t2, double* host_v2)
{
	// # of Blocks for Each Kernel
    // int	num_blocks_kernel_1;
    int num_blocks_kernel_2;
    int size_internal = (int)size_h7;
    
	// Device Memory for Inputs and Output
    double *dev_t3;
	double *dev_t2;
	double *dev_v2;

    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);	
	// cudaMalloc((void**) &dev_t2, sizeof(double) * size_h1 * size_p5 * size_p4 * size_h7);
	// cudaMalloc((void**) &dev_v2, sizeof(double) * size_h7 * size_p6 * size_h2 * size_h3);

    size_t size_t2 = (sizeof(double) * size_h1 * size_p5 * size_p4 * size_h7);
	size_t size_v2 = (sizeof(double) * size_h7 * size_p6 * size_h2 * size_h3);

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h1 * size_p5 * size_p4 * size_h7, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h7 * size_p6 * size_h2 * size_h3, cudaMemcpyHostToDevice);

    // num_blocks_kernel_1 = CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);
    num_blocks_kernel_2 = CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

	// Depends on # of Fused Kernel
	// dim3 gridsize_1(num_blocks_kernel_1);
	// dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

	dim3 gridsize_2(num_blocks_kernel_2);
	dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

	int	str_sd2_t3_h3 = 1;
	int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
	int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
	int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
	int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
	// int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

	// int str_reg_x_1 = str_sd2_t3_p5;
	// int str_reg_y_1 = str_sd2_t3_p4;
	int str_reg_x_2 = str_sd2_t3_p5;
	int str_reg_y_2 = str_sd2_t3_p6;

    int* list_stride_sd1_v2_1 = (int*)malloc(sizeof(int) * 9);
    list_stride_sd1_v2_1[0] = size_p4 * size_h2 * size_h3;
	list_stride_sd1_v2_1[1] = size_p4 * size_h1 * size_h3;
	list_stride_sd1_v2_1[2] = size_p4 * size_h1 * size_h2; 
	list_stride_sd1_v2_1[3] = size_p5 * size_h2 * size_h3;
	list_stride_sd1_v2_1[4] = size_p5 * size_h1 * size_h3;
  list_stride_sd1_v2_1[5] = size_p5 * size_h1 * size_h2;

  list_stride_sd1_v2_1[6] = size_p6 * size_h2 * size_h3;
  list_stride_sd1_v2_1[7] = size_p6 * size_h1 * size_h3;
  list_stride_sd1_v2_1[8] = size_p6 * size_h1 * size_h2;

  cudaMemcpyToSymbol(list_stride_v2, list_stride_sd1_v2_1, sizeof(int) * 9);

  // 
  dev_t3 = t3_d;

  // cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);

#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd1_1<<<gridsize_2, blocksize_2>>>(dev_t3, 
    dev_t2, dev_v2, 
    (int)size_h3, (int)size_h2, (int)size_h1, (int)size_p6, (int)size_p5, (int)size_p4, (int)size_h7,
    CEIL(size_h3, FUSION_SIZE_SLICE_2_H3),CEIL(size_h2, FUSION_SIZE_SLICE_2_H2),CEIL(size_h1, FUSION_SIZE_SLICE_2_H1),
    CEIL(size_p6, FUSION_SIZE_SLICE_2_P6),CEIL(size_p5, FUSION_SIZE_SLICE_2_P5),CEIL(size_p4, FUSION_SIZE_SLICE_2_P4),
    str_reg_x_2, str_reg_y_2,
    size_internal);
#endif

  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

    // Copy the Result from Device to Host
	// cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost);

	// cudaFree()
    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d1_2
__global__ void kernel_ccsdT_sd1_2(double* t3, 
    double* d_t2_2, double* d_v2_2, 
    int size_h3,    int size_h2,    int size_h1,    int size_p6,    int size_p5,    int size_p4,    int size_h7, 
    int numBlk_h3,  int numBlk_h2,  int numBlk_h1,  int numBlk_p6,  int numBlk_p5,  int numBlk_p4,
    int stride_reg_x, int stride_reg_y,
    int size_internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_2_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_2_H3;
    int idx_p4 = threadIdx.y % FUSION_SIZE_SLICE_2_P4;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_2_P4;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }

    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }

    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 +  
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_p4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < size_internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - size_internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p4 < rng_p4 && idx_h1 < rng_h2 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_2_Y] = d_t2_2[(blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_p4 + (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + ll + (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h1) * size_p5) * size_p4) * size_h7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_h3 < rng_h3 && idx_h2 < rng_h1 && threadIdx.y < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p6; ll++)
        {
            sm_b[threadIdx.y][threadIdx.x + ll * FUSION_SIZE_TB_2_X] = d_v2_2[(blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h2 + (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + ll) * size_h1) * size_h3) + (threadIdx.y + l) * list_stride_v2[7]];
        }
        __syncthreads();

        // Cross-Product: -1
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            //temp_bv[0] = sm_b[ll][d_v2_2_offset[l_idx_t3] + 0];
            temp_bv[0] = sm_b[ll][idx_h3 + (idx_h1) * FUSION_SIZE_SLICE_2_H3 + 0];
            temp_bv[1] = sm_b[ll][idx_h3 + (idx_h1) * FUSION_SIZE_SLICE_2_H3 + 16];
            temp_bv[2] = sm_b[ll][idx_h3 + (idx_h1) * FUSION_SIZE_SLICE_2_H3 + 32];
            temp_bv[3] = sm_b[ll][idx_h3 + (idx_h1) * FUSION_SIZE_SLICE_2_H3 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                //temp_av = sm_a[ll][d_t2_2_offset[l_idx_t3] + (xx * 16)];
                temp_av = sm_a[ll][idx_p4 + (idx_h2) * FUSION_SIZE_SLICE_2_P4 + (xx * 16)];

                reg_tile[0][xx] += temp_av * temp_bv[0];
                reg_tile[1][xx] += temp_av * temp_bv[1];
                reg_tile[2][xx] += temp_av * temp_bv[2];
                reg_tile[3][xx] += temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d1_2
void jk_ccsd_t_d1_2(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_h7, double* host_t3, double* host_t2, double* host_v2)
{
	// # of Blocks for Each Kernel
    // int	num_blocks_kernel_1;
    int num_blocks_kernel_2;
    int size_internal = (int)size_h7;
    
	// Device Memory for Inputs and Output
    double *dev_t3;
	double *dev_t2;
	double *dev_v2;

    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
	// cudaMalloc((void**) &dev_t2, sizeof(double) * size_h2 * size_p5 * size_p4 * size_h7);
	// cudaMalloc((void**) &dev_v2, sizeof(double) * size_h7 * size_p6 * size_h1 * size_h3);

    size_t size_t2 = (sizeof(double) * size_h2 * size_p5 * size_p4 * size_h7);
    size_t size_v2 = (sizeof(double) * size_h7 * size_p6 * size_h1 * size_h3);

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h2 * size_p5 * size_p4 * size_h7, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h7 * size_p6 * size_h1 * size_h3, cudaMemcpyHostToDevice);

    // num_blocks_kernel_1 = CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);
    num_blocks_kernel_2 = CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

	// Depends on # of Fused Kernel
	// dim3 gridsize_1(num_blocks_kernel_1);
	// dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

	dim3 gridsize_2(num_blocks_kernel_2);
	dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

	int	str_sd2_t3_h3 = 1;
	int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
	int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
	int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
	int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
	// int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

	// int str_reg_x_1 = str_sd2_t3_p5;
	// int str_reg_y_1 = str_sd2_t3_p4;
	int str_reg_x_2 = str_sd2_t3_p5;
	int str_reg_y_2 = str_sd2_t3_p6;

    int* list_stride_sd1_v2_1 = (int*)malloc(sizeof(int) * 9);
    list_stride_sd1_v2_1[0] = size_p4 * size_h2 * size_h3;
	list_stride_sd1_v2_1[1] = size_p4 * size_h1 * size_h3;
	list_stride_sd1_v2_1[2] = size_p4 * size_h1 * size_h2; 
	list_stride_sd1_v2_1[3] = size_p5 * size_h2 * size_h3;
	list_stride_sd1_v2_1[4] = size_p5 * size_h1 * size_h3;
    list_stride_sd1_v2_1[5] = size_p5 * size_h1 * size_h2;

    list_stride_sd1_v2_1[6] = size_p6 * size_h2 * size_h3;
    list_stride_sd1_v2_1[7] = size_p6 * size_h1 * size_h3;
    list_stride_sd1_v2_1[8] = size_p6 * size_h1 * size_h2;

    cudaMemcpyToSymbol(list_stride_v2, list_stride_sd1_v2_1, sizeof(int) * 9);

    // 
    dev_t3 = t3_d;

#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd1_2<<<gridsize_2, blocksize_2>>>(dev_t3, 
    dev_t2, dev_v2, 
    (int)size_h3, (int)size_h2, (int)size_h1, (int)size_p6, (int)size_p5, (int)size_p4, (int)size_h7,
    CEIL(size_h3, FUSION_SIZE_SLICE_2_H3),CEIL(size_h2, FUSION_SIZE_SLICE_2_H2),CEIL(size_h1, FUSION_SIZE_SLICE_2_H1),
    CEIL(size_p6, FUSION_SIZE_SLICE_2_P6),CEIL(size_p5, FUSION_SIZE_SLICE_2_P5),CEIL(size_p4, FUSION_SIZE_SLICE_2_P4),
    str_reg_x_2, str_reg_y_2,
    size_internal);
#endif

    // Copy the Result from Device to Host
	// cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost);

	// cudaFree()
    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d1_3
__global__ void kernel_ccsdT_sd1_3(double* t3, 
    double* d_t2_3, double* d_v2_3, 
    int size_h3,    int size_h2,    int size_h1,    int size_p6,    int size_p5,    int size_p4,    int size_h7, 
    int numBlk_h3,  int numBlk_h2,  int numBlk_h1,  int numBlk_p6,  int numBlk_p5,  int numBlk_p4,
    int stride_reg_x, int stride_reg_y,
    int size_internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_2_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_2_H3;
    int idx_p4 = threadIdx.y % FUSION_SIZE_SLICE_2_P4;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_2_P4;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }

    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }

    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 +  
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_p4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < size_internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - size_internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p4 < rng_p4 && idx_h1 < rng_h3 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_2_Y] = d_t2_3[(blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_p4 + (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + ll + (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h1) * size_p5) * size_p4) * size_h7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_h3 < rng_h2 && idx_h2 < rng_h1 && threadIdx.y < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p6; ll++)
        {
            sm_b[threadIdx.y][threadIdx.x + ll * FUSION_SIZE_TB_2_X] = d_v2_3[(blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h3 + (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h2 + (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + ll) * size_h1) * size_h2) + (threadIdx.y + l) * list_stride_v2[8]];
        }
        __syncthreads();

        // Cross-Product: -1
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            //temp_bv[0] = sm_b[ll][d_v2_3_offset[l_idx_t3] + 0];
            temp_bv[0] = sm_b[ll][idx_h2 + (idx_h1) * FUSION_SIZE_SLICE_2_H2 + 0];
            temp_bv[1] = sm_b[ll][idx_h2 + (idx_h1) * FUSION_SIZE_SLICE_2_H2 + 16];
            temp_bv[2] = sm_b[ll][idx_h2 + (idx_h1) * FUSION_SIZE_SLICE_2_H2 + 32];
            temp_bv[3] = sm_b[ll][idx_h2 + (idx_h1) * FUSION_SIZE_SLICE_2_H2 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                //temp_av = sm_a[ll][d_t2_3_offset[l_idx_t3] + (xx * 16)];
                temp_av = sm_a[ll][idx_p4 + (idx_h3) * FUSION_SIZE_SLICE_2_P4 + (xx * 16)];

                reg_tile[0][xx] -= temp_av * temp_bv[0];
                reg_tile[1][xx] -= temp_av * temp_bv[1];
                reg_tile[2][xx] -= temp_av * temp_bv[2];
                reg_tile[3][xx] -= temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d1_3
void jk_ccsd_t_d1_3(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_h7, double* host_t3, double* host_t2, double* host_v2)
{
	// # of Blocks for Each Kernel
    // int	num_blocks_kernel_1;
    int num_blocks_kernel_2;
    int size_internal = (int)size_h7;
    
	// Device Memory for Inputs and Output
    double *dev_t3;
	double *dev_t2;
	double *dev_v2;

    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
	// cudaMalloc((void**) &dev_t2, sizeof(double) * size_h3 * size_p5 * size_p4 * size_h7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_h7 * size_p6 * size_h1 * size_h2);

    size_t size_t2 = (sizeof(double) * size_h3 * size_p5 * size_p4 * size_h7);
    size_t size_v2 = (sizeof(double) * size_h7 * size_p6 * size_h1 * size_h2);

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h3 * size_p5 * size_p4 * size_h7, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h7 * size_p6 * size_h1 * size_h2, cudaMemcpyHostToDevice);

    // num_blocks_kernel_1 = CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);
    num_blocks_kernel_2 = CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

	// Depends on # of Fused Kernel
	// dim3 gridsize_1(num_blocks_kernel_1);
	// dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

	dim3 gridsize_2(num_blocks_kernel_2);
	dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

	int	str_sd2_t3_h3 = 1;
	int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
	int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
	int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
	int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
	// int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

	// int str_reg_x_1 = str_sd2_t3_p5;
	// int str_reg_y_1 = str_sd2_t3_p4;
	int str_reg_x_2 = str_sd2_t3_p5;
	int str_reg_y_2 = str_sd2_t3_p6;

    int* list_stride_sd1_v2_1 = (int*)malloc(sizeof(int) * 9);
    list_stride_sd1_v2_1[0] = size_p4 * size_h2 * size_h3;
	list_stride_sd1_v2_1[1] = size_p4 * size_h1 * size_h3;
	list_stride_sd1_v2_1[2] = size_p4 * size_h1 * size_h2; 
	list_stride_sd1_v2_1[3] = size_p5 * size_h2 * size_h3;
	list_stride_sd1_v2_1[4] = size_p5 * size_h1 * size_h3;
    list_stride_sd1_v2_1[5] = size_p5 * size_h1 * size_h2;

    list_stride_sd1_v2_1[6] = size_p6 * size_h2 * size_h3;
    list_stride_sd1_v2_1[7] = size_p6 * size_h1 * size_h3;
    list_stride_sd1_v2_1[8] = size_p6 * size_h1 * size_h2;

    cudaMemcpyToSymbol(list_stride_v2, list_stride_sd1_v2_1, sizeof(int) * 9);

    // 
    dev_t3 = t3_d;

#ifdef DEBUG_ENALBLE_ALL_KERNEL 
    kernel_ccsdT_sd1_3<<<gridsize_2, blocksize_2>>>(dev_t3, 
    dev_t2, dev_v2, 
    (int)size_h3, (int)size_h2, (int)size_h1, (int)size_p6, (int)size_p5, (int)size_p4, (int)size_h7,
    CEIL(size_h3, FUSION_SIZE_SLICE_2_H3),CEIL(size_h2, FUSION_SIZE_SLICE_2_H2),CEIL(size_h1, FUSION_SIZE_SLICE_2_H1),
    CEIL(size_p6, FUSION_SIZE_SLICE_2_P6),CEIL(size_p5, FUSION_SIZE_SLICE_2_P5),CEIL(size_p4, FUSION_SIZE_SLICE_2_P4),
    str_reg_x_2, str_reg_y_2,
    size_internal);
#endif
    // Copy the Result from Device to Host
	// cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost);

	// cudaFree()
    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d1_4
__global__ void kernel_ccsdT_sd1_4(double* t3, 
    double* d_t2_4, double* d_v2_4, 
    int size_h3,    int size_h2,    int size_h1,    int size_p6,    int size_p5,    int size_p4,    int size_h7, 
    int numBlk_h3,  int numBlk_h2,  int numBlk_h1,  int numBlk_p6,  int numBlk_p5,  int numBlk_p4,
    int stride_reg_x, int stride_reg_y,
    int size_internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    //int l_idx_t3                = threadIdx.x + threadIdx.y * FUSION_SIZE_TB_1_X;
    int internal_upperbound     = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = blockIdx.x % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3)) >= FUSION_SIZE_SLICE_1_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_1_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_1_H3;
    }

    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2)) >= FUSION_SIZE_SLICE_1_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_1_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_1_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1)) >= FUSION_SIZE_SLICE_1_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_1_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_1_H1;
    }

    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6)) >= FUSION_SIZE_SLICE_1_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_1_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_1_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5)) >= FUSION_SIZE_SLICE_1_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_1_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_1_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4)) >= FUSION_SIZE_SLICE_1_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_1_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_1_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < size_internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - size_internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_p6 && idx_h1 < rng_h1 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_4[(blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h1) * size_p6) * size_p5) * size_h7 + (threadIdx.x + l)];
        
        }

        // Load Input Tensor to Shared Memory
        if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && threadIdx.y < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_b[threadIdx.y][threadIdx.x + ll * FUSION_SIZE_TB_1_X] = d_v2_4[(blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h3 + (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h2 + (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll) * size_h2) * size_h3) + (threadIdx.y + l) * list_stride_v2[0]];
        }
        __syncthreads();

        // Cross-Product: -1
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_b[ll][idx_h3 + (idx_h2) * FUSION_SIZE_SLICE_1_H3 + 0];
            temp_bv[1] = sm_b[ll][idx_h3 + (idx_h2) * FUSION_SIZE_SLICE_1_H3 + 16];
            temp_bv[2] = sm_b[ll][idx_h3 + (idx_h2) * FUSION_SIZE_SLICE_1_H3 + 32];
            temp_bv[3] = sm_b[ll][idx_h3 + (idx_h2) * FUSION_SIZE_SLICE_1_H3 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_a[ll][idx_p6 + (idx_h1) * FUSION_SIZE_SLICE_1_P6 + (xx * 16)];

                reg_tile[0][xx] -= temp_av * temp_bv[0];
                reg_tile[1][xx] -= temp_av * temp_bv[1];
                reg_tile[2][xx] -= temp_av * temp_bv[2];
                reg_tile[3][xx] -= temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    // 
    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d1_4
void jk_ccsd_t_d1_4(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_h7, double* host_t3, double* host_t2, double* host_v2)
{
	// # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int size_internal = (int)size_h7;
    
	// Device Memory for Inputs and Output
    double *dev_t3;
	double *dev_t2;
	double *dev_v2;

    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
	// cudaMalloc((void**) &dev_t2, sizeof(double) * size_h1 * size_p6 * size_p5 * size_h7);
	// cudaMalloc((void**) &dev_v2, sizeof(double) * size_h7 * size_p4 * size_h2 * size_h3);

    size_t size_t2 = (sizeof(double) * size_h1 * size_p6 * size_p5 * size_h7);
	size_t size_v2 = (sizeof(double) * size_h7 * size_p4 * size_h2 * size_h3);

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
	
    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h1 * size_p6 * size_p5 * size_h7, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h7 * size_p4 * size_h2 * size_h3, cudaMemcpyHostToDevice);

    num_blocks_kernel_1 = CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);
    // num_blocks_kernel_2 = CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

	// Depends on # of Fused Kernel
	dim3 gridsize_1(num_blocks_kernel_1);
	dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

	// dim3 gridsize_2(num_blocks_kernel_2);
	// dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

	int	str_sd2_t3_h3 = 1;
	int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
	int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
	int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
	int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
	int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

	int str_reg_x_1 = str_sd2_t3_p5;
	int str_reg_y_1 = str_sd2_t3_p4;
	// int str_reg_x_2 = str_sd2_t3_p5;
	// int str_reg_y_2 = str_sd2_t3_p6;

    int* list_stride_sd1_v2_1 = (int*)malloc(sizeof(int) * 9);
    list_stride_sd1_v2_1[0] = size_p4 * size_h2 * size_h3;
	list_stride_sd1_v2_1[1] = size_p4 * size_h1 * size_h3;
	list_stride_sd1_v2_1[2] = size_p4 * size_h1 * size_h2; 
	list_stride_sd1_v2_1[3] = size_p5 * size_h2 * size_h3;
	list_stride_sd1_v2_1[4] = size_p5 * size_h1 * size_h3;
    list_stride_sd1_v2_1[5] = size_p5 * size_h1 * size_h2;

    list_stride_sd1_v2_1[6] = size_p6 * size_h2 * size_h3;
    list_stride_sd1_v2_1[7] = size_p6 * size_h1 * size_h3;
    list_stride_sd1_v2_1[8] = size_p6 * size_h1 * size_h2;

    cudaMemcpyToSymbol(list_stride_v2, list_stride_sd1_v2_1, sizeof(int) * 9);

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd1_4<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3),CEIL(size_h2, FUSION_SIZE_SLICE_1_H2),CEIL(size_h1, FUSION_SIZE_SLICE_1_H1),
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6),CEIL(size_p5, FUSION_SIZE_SLICE_1_P5),CEIL(size_p4, FUSION_SIZE_SLICE_1_P4),
    str_reg_x_1, str_reg_y_1,
    size_internal);
#endif
    // Copy the Result from Device to Host
	// cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost);

	// cudaFree()
    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d1_5
__global__ void kernel_ccsdT_sd1_5(double* t3, 
    double* d_t2_5, double* d_v2_5, 
    int size_h3,    int size_h2,    int size_h1,    int size_p6,    int size_p5,    int size_p4,    int size_h7, 
    int numBlk_h3,  int numBlk_h2,  int numBlk_h1,  int numBlk_p6,  int numBlk_p5,  int numBlk_p4,
    int stride_reg_x, int stride_reg_y,
    int size_internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    //int l_idx_t3                = threadIdx.x + threadIdx.y * FUSION_SIZE_TB_1_X;
    int internal_upperbound     = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = blockIdx.x % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3)) >= FUSION_SIZE_SLICE_1_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_1_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_1_H3;
    }

    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2)) >= FUSION_SIZE_SLICE_1_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_1_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_1_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1)) >= FUSION_SIZE_SLICE_1_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_1_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_1_H1;
    }

    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6)) >= FUSION_SIZE_SLICE_1_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_1_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_1_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5)) >= FUSION_SIZE_SLICE_1_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_1_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_1_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4)) >= FUSION_SIZE_SLICE_1_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_1_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_1_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < size_internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - size_internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_p6 && idx_h1 < rng_h2 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_5[(blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h1) * size_p6) * size_p5) * size_h7 + (threadIdx.x + l)]; 
        }

        // Load Input Tensor to Shared Memory
        if (idx_h3 < rng_h3 && idx_h2 < rng_h1 && threadIdx.y < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_b[threadIdx.y][threadIdx.x + ll * FUSION_SIZE_TB_1_X] = d_v2_5[(blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h3 + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h2 + (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll) * size_h1) * size_h3) + (threadIdx.y + l) * list_stride_v2[1]];
        }
        __syncthreads();

        // Cross-Product: -1
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_b[ll][idx_h3 + (idx_h1) * FUSION_SIZE_SLICE_1_H3 + 0];
            temp_bv[1] = sm_b[ll][idx_h3 + (idx_h1) * FUSION_SIZE_SLICE_1_H3 + 16];
            temp_bv[2] = sm_b[ll][idx_h3 + (idx_h1) * FUSION_SIZE_SLICE_1_H3 + 32];
            temp_bv[3] = sm_b[ll][idx_h3 + (idx_h1) * FUSION_SIZE_SLICE_1_H3 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_a[ll][idx_p6 + (idx_h2) * FUSION_SIZE_SLICE_1_P6 + (xx * 16)];

                reg_tile[0][xx] += temp_av * temp_bv[0];
                reg_tile[1][xx] += temp_av * temp_bv[1];
                reg_tile[2][xx] += temp_av * temp_bv[2];
                reg_tile[3][xx] += temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d1_5
void jk_ccsd_t_d1_5(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_h7, double* host_t3, double* host_t2, double* host_v2)
{
	// # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int size_internal = (int)size_h7;
    
	// Device Memory for Inputs and Output
    double *dev_t3;
	double *dev_t2;
	double *dev_v2;

    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h2 * size_p6 * size_p5 * size_h7);
	// cudaMalloc((void**) &dev_v2, sizeof(double) * size_h7 * size_p4 * size_h1 * size_h3);

    size_t size_t2 = (sizeof(double) * size_h2 * size_p6 * size_p5 * size_h7);
	size_t size_v2 = (sizeof(double) * size_h7 * size_p4 * size_h1 * size_h3);

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
	
    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h2 * size_p6 * size_p5 * size_h7, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h7 * size_p4 * size_h1 * size_h3, cudaMemcpyHostToDevice);

    num_blocks_kernel_1 = CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);
    // num_blocks_kernel_2 = CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

	// Depends on # of Fused Kernel
	dim3 gridsize_1(num_blocks_kernel_1);
	dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

	// dim3 gridsize_2(num_blocks_kernel_2);
	// dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

	int	str_sd2_t3_h3 = 1;
	int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
	int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
	int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
	int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
	int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

	int str_reg_x_1 = str_sd2_t3_p5;
	int str_reg_y_1 = str_sd2_t3_p4;
	// int str_reg_x_2 = str_sd2_t3_p5;
	// int str_reg_y_2 = str_sd2_t3_p6;

    int* list_stride_sd1_v2_1 = (int*)malloc(sizeof(int) * 9);
    list_stride_sd1_v2_1[0] = size_p4 * size_h2 * size_h3;
	list_stride_sd1_v2_1[1] = size_p4 * size_h1 * size_h3;
	list_stride_sd1_v2_1[2] = size_p4 * size_h1 * size_h2; 
	list_stride_sd1_v2_1[3] = size_p5 * size_h2 * size_h3;
	list_stride_sd1_v2_1[4] = size_p5 * size_h1 * size_h3;
    list_stride_sd1_v2_1[5] = size_p5 * size_h1 * size_h2;

    list_stride_sd1_v2_1[6] = size_p6 * size_h2 * size_h3;
    list_stride_sd1_v2_1[7] = size_p6 * size_h1 * size_h3;
    list_stride_sd1_v2_1[8] = size_p6 * size_h1 * size_h2;

    cudaMemcpyToSymbol(list_stride_v2, list_stride_sd1_v2_1, sizeof(int) * 9);

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd1_5<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3),CEIL(size_h2, FUSION_SIZE_SLICE_1_H2),CEIL(size_h1, FUSION_SIZE_SLICE_1_H1),
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6),CEIL(size_p5, FUSION_SIZE_SLICE_1_P5),CEIL(size_p4, FUSION_SIZE_SLICE_1_P4),
    str_reg_x_1, str_reg_y_1,
    size_internal);
#endif
    // Copy the Result from Device to Host
	// cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost);

	// cudaFree()
    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d1_6
__global__ void kernel_ccsdT_sd1_6(double* t3, 
    double* d_t2_6, double* d_v2_6, 
    int size_h3,    int size_h2,    int size_h1,    int size_p6,    int size_p5,    int size_p4,    int size_h7, 
    int numBlk_h3,  int numBlk_h2,  int numBlk_h1,  int numBlk_p6,  int numBlk_p5,  int numBlk_p4,
    int stride_reg_x, int stride_reg_y,
    int size_internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    //int l_idx_t3                = threadIdx.x + threadIdx.y * FUSION_SIZE_TB_1_X;
    int internal_upperbound     = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = blockIdx.x % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3)) >= FUSION_SIZE_SLICE_1_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_1_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_1_H3;
    }

    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2)) >= FUSION_SIZE_SLICE_1_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_1_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_1_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1)) >= FUSION_SIZE_SLICE_1_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_1_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_1_H1;
    }

    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6)) >= FUSION_SIZE_SLICE_1_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_1_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_1_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5)) >= FUSION_SIZE_SLICE_1_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_1_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_1_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4)) >= FUSION_SIZE_SLICE_1_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_1_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_1_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < size_internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - size_internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1 //63, 21
        if (idx_p6 < rng_p6 && idx_h1 < rng_h3 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_6[(blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h1) * size_p6) * size_p5) * size_h7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_h3 < rng_h2 && idx_h2 < rng_h1 && threadIdx.y < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_b[threadIdx.y][threadIdx.x + ll * FUSION_SIZE_TB_1_X] = d_v2_6[(blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h3 + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h2 + (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll) * size_h1) * size_h2) + (threadIdx.y + l) * list_stride_v2[2]];
        }
        __syncthreads();

        // Cross-Product: -1
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_b[ll][idx_h2 + (idx_h1) * FUSION_SIZE_SLICE_1_H2 + 0];
            temp_bv[1] = sm_b[ll][idx_h2 + (idx_h1) * FUSION_SIZE_SLICE_1_H2 + 16];
            temp_bv[2] = sm_b[ll][idx_h2 + (idx_h1) * FUSION_SIZE_SLICE_1_H2 + 32];
            temp_bv[3] = sm_b[ll][idx_h2 + (idx_h1) * FUSION_SIZE_SLICE_1_H2 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_a[ll][idx_p6 + (idx_h3) * FUSION_SIZE_SLICE_1_P6 + (xx * 16)];

                reg_tile[0][xx] -= temp_av * temp_bv[0];
                reg_tile[1][xx] -= temp_av * temp_bv[1];
                reg_tile[2][xx] -= temp_av * temp_bv[2];
                reg_tile[3][xx] -= temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d1_6
void jk_ccsd_t_d1_6(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_h7, double* host_t3, double* host_t2, double* host_v2)
{
	// # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int size_internal = (int)size_h7;
    
	// Device Memory for Inputs and Output
    double *dev_t3;
	double *dev_t2;
	double *dev_v2;

    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
	// cudaMalloc((void**) &dev_t2, sizeof(double) * size_h3 * size_p6 * size_p5 * size_h7);
	// cudaMalloc((void**) &dev_v2, sizeof(double) * size_h7 * size_p4 * size_h1 * size_h2);

    size_t size_t2 = (sizeof(double) * size_h3 * size_p6 * size_p5 * size_h7);
	size_t size_v2 = (sizeof(double) * size_h7 * size_p4 * size_h1 * size_h2);

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
	
    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h3 * size_p6 * size_p5 * size_h7, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h7 * size_p4 * size_h1 * size_h2, cudaMemcpyHostToDevice);

    num_blocks_kernel_1 = CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);
    // num_blocks_kernel_2 = CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

	// Depends on # of Fused Kernel
	dim3 gridsize_1(num_blocks_kernel_1);
	dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

	// dim3 gridsize_2(num_blocks_kernel_2);
	// dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

	int	str_sd2_t3_h3 = 1;
	int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
	int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
	int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
	int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
	int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

	int str_reg_x_1 = str_sd2_t3_p5;
	int str_reg_y_1 = str_sd2_t3_p4;
	// int str_reg_x_2 = str_sd2_t3_p5;
	// int str_reg_y_2 = str_sd2_t3_p6;

    int* list_stride_sd1_v2_1 = (int*)malloc(sizeof(int) * 9);
    list_stride_sd1_v2_1[0] = size_p4 * size_h2 * size_h3;
	list_stride_sd1_v2_1[1] = size_p4 * size_h1 * size_h3;
	list_stride_sd1_v2_1[2] = size_p4 * size_h1 * size_h2; 
	list_stride_sd1_v2_1[3] = size_p5 * size_h2 * size_h3;
	list_stride_sd1_v2_1[4] = size_p5 * size_h1 * size_h3;
    list_stride_sd1_v2_1[5] = size_p5 * size_h1 * size_h2;

    list_stride_sd1_v2_1[6] = size_p6 * size_h2 * size_h3;
    list_stride_sd1_v2_1[7] = size_p6 * size_h1 * size_h3;
    list_stride_sd1_v2_1[8] = size_p6 * size_h1 * size_h2;

    cudaMemcpyToSymbol(list_stride_v2, list_stride_sd1_v2_1, sizeof(int) * 9);

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd1_6<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3),CEIL(size_h2, FUSION_SIZE_SLICE_1_H2),CEIL(size_h1, FUSION_SIZE_SLICE_1_H1),
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6),CEIL(size_p5, FUSION_SIZE_SLICE_1_P5),CEIL(size_p4, FUSION_SIZE_SLICE_1_P4),
    str_reg_x_1, str_reg_y_1,
    size_internal);
#endif
    // Copy the Result from Device to Host
	// cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost);

	// cudaFree()
    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d1_7
__global__ void kernel_ccsdT_sd1_7(double* t3, 
    double* d_t2_7, double* d_v2_7, 
    int size_h3,    int size_h2,    int size_h1,    int size_p6,    int size_p5,    int size_p4,    int size_h7, 
    int numBlk_h3,  int numBlk_h2,  int numBlk_h1,  int numBlk_p6,  int numBlk_p5,  int numBlk_p4,
    int stride_reg_x, int stride_reg_y,
    int size_internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    //int l_idx_t3                = threadIdx.x + threadIdx.y * FUSION_SIZE_TB_1_X;
    int internal_upperbound     = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = blockIdx.x % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3)) >= FUSION_SIZE_SLICE_1_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_1_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_1_H3;
    }

    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2)) >= FUSION_SIZE_SLICE_1_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_1_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_1_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1)) >= FUSION_SIZE_SLICE_1_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_1_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_1_H1;
    }

    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6)) >= FUSION_SIZE_SLICE_1_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_1_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_1_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5)) >= FUSION_SIZE_SLICE_1_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_1_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_1_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4)) >= FUSION_SIZE_SLICE_1_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_1_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_1_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < size_internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - size_internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_p6 && idx_h1 < rng_h1 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_7[(blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h1) * size_p6) * size_p4) * size_h7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && threadIdx.y < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_b[threadIdx.y][threadIdx.x + ll * FUSION_SIZE_TB_1_X] = d_v2_7[(blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h3 + (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h2 + (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll) * size_h2) * size_h3) + (threadIdx.y + l) * list_stride_v2[3]];
        }
        __syncthreads();

        // Cross-Product: -1
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_a[ll][idx_p6 + (idx_h1) * FUSION_SIZE_SLICE_1_P6 + 0];
            temp_bv[1] = sm_a[ll][idx_p6 + (idx_h1) * FUSION_SIZE_SLICE_1_P6 + 16];
            temp_bv[2] = sm_a[ll][idx_p6 + (idx_h1) * FUSION_SIZE_SLICE_1_P6 + 32];
            temp_bv[3] = sm_a[ll][idx_p6 + (idx_h1) * FUSION_SIZE_SLICE_1_P6 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_b[ll][idx_h3 + (idx_h2) * FUSION_SIZE_SLICE_1_H3 + (xx * 16)];

                reg_tile[0][xx] += temp_av * temp_bv[0];
                reg_tile[1][xx] += temp_av * temp_bv[1];
                reg_tile[2][xx] += temp_av * temp_bv[2];
                reg_tile[3][xx] += temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d1_7
void jk_ccsd_t_d1_7(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_h7, double* host_t3, double* host_t2, double* host_v2)
{
	// # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int size_internal = (int)size_h7;
    
	// Device Memory for Inputs and Output
    double *dev_t3;
	double *dev_t2;
	double *dev_v2;

    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h1 * size_p6 * size_p4 * size_h7);
	// cudaMalloc((void**) &dev_v2, sizeof(double) * size_h7 * size_p5 * size_h2 * size_h3);

    size_t size_t2 = (sizeof(double) * size_h1 * size_p6 * size_p4 * size_h7);
	size_t size_v2 = (sizeof(double) * size_h7 * size_p5 * size_h2 * size_h3);

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h1 * size_p6 * size_p4 * size_h7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h7 * size_p5 * size_h2 * size_h3, cudaMemcpyHostToDevice);
    
    num_blocks_kernel_1 = CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);
    // num_blocks_kernel_2 = CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

	// Depends on # of Fused Kernel
	dim3 gridsize_1(num_blocks_kernel_1);
	dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

	// dim3 gridsize_2(num_blocks_kernel_2);
	// dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

	int	str_sd2_t3_h3 = 1;
	int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
	int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
	int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
	int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
	int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

	int str_reg_x_1 = str_sd2_t3_p5;
	int str_reg_y_1 = str_sd2_t3_p4;
	// int str_reg_x_2 = str_sd2_t3_p5;
	// int str_reg_y_2 = str_sd2_t3_p6;

    int* list_stride_sd1_v2_1 = (int*)malloc(sizeof(int) * 9);
    list_stride_sd1_v2_1[0] = size_p4 * size_h2 * size_h3;
	list_stride_sd1_v2_1[1] = size_p4 * size_h1 * size_h3;
	list_stride_sd1_v2_1[2] = size_p4 * size_h1 * size_h2; 
	list_stride_sd1_v2_1[3] = size_p5 * size_h2 * size_h3;
	list_stride_sd1_v2_1[4] = size_p5 * size_h1 * size_h3;
    list_stride_sd1_v2_1[5] = size_p5 * size_h1 * size_h2;

    list_stride_sd1_v2_1[6] = size_p6 * size_h2 * size_h3;
    list_stride_sd1_v2_1[7] = size_p6 * size_h1 * size_h3;
    list_stride_sd1_v2_1[8] = size_p6 * size_h1 * size_h2;

    cudaMemcpyToSymbol(list_stride_v2, list_stride_sd1_v2_1, sizeof(int) * 9);

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd1_7<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3),CEIL(size_h2, FUSION_SIZE_SLICE_1_H2),CEIL(size_h1, FUSION_SIZE_SLICE_1_H1),
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6),CEIL(size_p5, FUSION_SIZE_SLICE_1_P5),CEIL(size_p4, FUSION_SIZE_SLICE_1_P4),
    str_reg_x_1, str_reg_y_1,
    size_internal);
#endif
    // Copy the Result from Device to Host
	// cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost);

	// cudaFree()
    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d1_8
__global__ void kernel_ccsdT_sd1_8(double* t3, 
    double* d_t2_8, double* d_v2_8, 
    int size_h3,    int size_h2,    int size_h1,    int size_p6,    int size_p5,    int size_p4,    int size_h7, 
    int numBlk_h3,  int numBlk_h2,  int numBlk_h1,  int numBlk_p6,  int numBlk_p5,  int numBlk_p4,
    int stride_reg_x, int stride_reg_y,
    int size_internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    //int l_idx_t3                = threadIdx.x + threadIdx.y * FUSION_SIZE_TB_1_X;
    int internal_upperbound     = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = blockIdx.x % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3)) >= FUSION_SIZE_SLICE_1_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_1_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_1_H3;
    }

    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2)) >= FUSION_SIZE_SLICE_1_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_1_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_1_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1)) >= FUSION_SIZE_SLICE_1_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_1_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_1_H1;
    }

    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6)) >= FUSION_SIZE_SLICE_1_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_1_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_1_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5)) >= FUSION_SIZE_SLICE_1_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_1_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_1_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4)) >= FUSION_SIZE_SLICE_1_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_1_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_1_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < size_internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - size_internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_p6 && idx_h1 < rng_h2 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_8[(blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h1) * size_p6) * size_p4) * size_h7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_h3 < rng_h3 && idx_h2 < rng_h1 && threadIdx.y < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_b[threadIdx.y][threadIdx.x + ll * FUSION_SIZE_TB_1_X] = d_v2_8[(blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h3 + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h2 + (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll) * size_h1) * size_h3) + (threadIdx.y + l) * list_stride_v2[4]];
        }
        __syncthreads();

        // Cross-Product: -1
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_a[ll][idx_p6 + (idx_h2) * FUSION_SIZE_SLICE_1_P6 + 0];
            temp_bv[1] = sm_a[ll][idx_p6 + (idx_h2) * FUSION_SIZE_SLICE_1_P6 + 16];
            temp_bv[2] = sm_a[ll][idx_p6 + (idx_h2) * FUSION_SIZE_SLICE_1_P6 + 32];
            temp_bv[3] = sm_a[ll][idx_p6 + (idx_h2) * FUSION_SIZE_SLICE_1_P6 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_b[ll][idx_h3 + (idx_h1) * FUSION_SIZE_SLICE_1_H3 + (xx * 16)];

                reg_tile[0][xx] -= temp_av * temp_bv[0];
                reg_tile[1][xx] -= temp_av * temp_bv[1];
                reg_tile[2][xx] -= temp_av * temp_bv[2];
                reg_tile[3][xx] -= temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    // 
    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d1_8
void jk_ccsd_t_d1_8(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_h7, double* host_t3, double* host_t2, double* host_v2)
{
	// # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int size_internal = (int)size_h7;
    
	// Device Memory for Inputs and Output
    double *dev_t3;
	double *dev_t2;
	double *dev_v2;

    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h2 * size_p6 * size_p4 * size_h7);
	// cudaMalloc((void**) &dev_v2, sizeof(double) * size_h7 * size_p5 * size_h1 * size_h3);

    size_t size_t2 = (sizeof(double) * size_h2 * size_p6 * size_p4 * size_h7);
	size_t size_v2 = (sizeof(double) * size_h7 * size_p5 * size_h1 * size_h3);

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h2 * size_p6 * size_p4 * size_h7, cudaMemcpyHostToDevice);
	cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h7 * size_p5 * size_h1 * size_h3, cudaMemcpyHostToDevice);    

    num_blocks_kernel_1 = CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);
    // num_blocks_kernel_2 = CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

	// Depends on # of Fused Kernel
	dim3 gridsize_1(num_blocks_kernel_1);
	dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

	// dim3 gridsize_2(num_blocks_kernel_2);
	// dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

	int	str_sd2_t3_h3 = 1;
	int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
	int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
	int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
	int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
	int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

	int str_reg_x_1 = str_sd2_t3_p5;
	int str_reg_y_1 = str_sd2_t3_p4;
	// int str_reg_x_2 = str_sd2_t3_p5;
	// int str_reg_y_2 = str_sd2_t3_p6;

    int* list_stride_sd1_v2_1 = (int*)malloc(sizeof(int) * 9);
    list_stride_sd1_v2_1[0] = size_p4 * size_h2 * size_h3;
	list_stride_sd1_v2_1[1] = size_p4 * size_h1 * size_h3;
	list_stride_sd1_v2_1[2] = size_p4 * size_h1 * size_h2; 
	list_stride_sd1_v2_1[3] = size_p5 * size_h2 * size_h3;
	list_stride_sd1_v2_1[4] = size_p5 * size_h1 * size_h3;
    list_stride_sd1_v2_1[5] = size_p5 * size_h1 * size_h2;

    list_stride_sd1_v2_1[6] = size_p6 * size_h2 * size_h3;
    list_stride_sd1_v2_1[7] = size_p6 * size_h1 * size_h3;
    list_stride_sd1_v2_1[8] = size_p6 * size_h1 * size_h2;

    cudaMemcpyToSymbol(list_stride_v2, list_stride_sd1_v2_1, sizeof(int) * 9);

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd1_8<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3),CEIL(size_h2, FUSION_SIZE_SLICE_1_H2),CEIL(size_h1, FUSION_SIZE_SLICE_1_H1),
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6),CEIL(size_p5, FUSION_SIZE_SLICE_1_P5),CEIL(size_p4, FUSION_SIZE_SLICE_1_P4),
    str_reg_x_1, str_reg_y_1,
    size_internal);
#endif
    // Copy the Result from Device to Host
	// cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost);

	// cudaFree()
    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d1_9
__global__ void kernel_ccsdT_sd1_9(double* t3, 
    double* d_t2_9, double* d_v2_9, 
    int size_h3,    int size_h2,    int size_h1,    int size_p6,    int size_p5,    int size_p4,    int size_h7, 
    int numBlk_h3,  int numBlk_h2,  int numBlk_h1,  int numBlk_p6,  int numBlk_p5,  int numBlk_p4,
    int stride_reg_x, int stride_reg_y,
    int size_internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    //int l_idx_t3                = threadIdx.x + threadIdx.y * FUSION_SIZE_TB_1_X;
    int internal_upperbound     = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = blockIdx.x % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3)) >= FUSION_SIZE_SLICE_1_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_1_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_1_H3;
    }

    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2)) >= FUSION_SIZE_SLICE_1_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_1_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_1_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1)) >= FUSION_SIZE_SLICE_1_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_1_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_1_H1;
    }

    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6)) >= FUSION_SIZE_SLICE_1_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_1_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_1_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5)) >= FUSION_SIZE_SLICE_1_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_1_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_1_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4)) >= FUSION_SIZE_SLICE_1_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_1_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_1_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < size_internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - size_internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_p6 && idx_h1 < rng_h3 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_9[(blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_p6 + (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h1) * size_p6) * size_p4) * size_h7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_h3 < rng_h2 && idx_h2 < rng_h1 && threadIdx.y < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_b[threadIdx.y][threadIdx.x + ll * FUSION_SIZE_TB_1_X] = d_v2_9[(blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h3 + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_h2 + (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll) * size_h1) * size_h2) + (threadIdx.y + l) * list_stride_v2[5]];
        }
        __syncthreads();

        // Cross-Product: -1
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_a[ll][idx_p6 + (idx_h3) * FUSION_SIZE_SLICE_1_P6 + 0];
            temp_bv[1] = sm_a[ll][idx_p6 + (idx_h3) * FUSION_SIZE_SLICE_1_P6 + 16];
            temp_bv[2] = sm_a[ll][idx_p6 + (idx_h3) * FUSION_SIZE_SLICE_1_P6 + 32];
            temp_bv[3] = sm_a[ll][idx_p6 + (idx_h3) * FUSION_SIZE_SLICE_1_P6 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_b[ll][idx_h2 + (idx_h1) * FUSION_SIZE_SLICE_1_H2 + (xx * 16)];

                reg_tile[0][xx] += temp_av * temp_bv[0];
                reg_tile[1][xx] += temp_av * temp_bv[1];
                reg_tile[2][xx] += temp_av * temp_bv[2];
                reg_tile[3][xx] += temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d1_9
void jk_ccsd_t_d1_9(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_h7, double* host_t3, double* host_t2, double* host_v2)
{
	// # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int size_internal = (int)size_h7;
    
	// Device Memory for Inputs and Output
    double *dev_t3;
	double *dev_t2;
	double *dev_v2;

    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
	// cudaMalloc((void**) &dev_t2, sizeof(double) * size_h3 * size_p6 * size_p4 * size_h7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_h7 * size_p5 * size_h1 * size_h2);

    size_t size_t2 = (sizeof(double) * size_h3 * size_p6 * size_p4 * size_h7);
    size_t size_v2 = (sizeof(double) * size_h7 * size_p5 * size_h1 * size_h2);

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);    
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h3 * size_p6 * size_p4 * size_h7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h7 * size_p5 * size_h1 * size_h2, cudaMemcpyHostToDevice);

    num_blocks_kernel_1 = CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);
    // num_blocks_kernel_2 = CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

	// Depends on # of Fused Kernel
	dim3 gridsize_1(num_blocks_kernel_1);
	dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

	// dim3 gridsize_2(num_blocks_kernel_2);
	// dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

	int	str_sd2_t3_h3 = 1;
	int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
	int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
	int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
	int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
	int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

	int str_reg_x_1 = str_sd2_t3_p5;
	int str_reg_y_1 = str_sd2_t3_p4;
	// int str_reg_x_2 = str_sd2_t3_p5;
	// int str_reg_y_2 = str_sd2_t3_p6;

    int* list_stride_sd1_v2_1 = (int*)malloc(sizeof(int) * 9);
    list_stride_sd1_v2_1[0] = size_p4 * size_h2 * size_h3;
	list_stride_sd1_v2_1[1] = size_p4 * size_h1 * size_h3;
	list_stride_sd1_v2_1[2] = size_p4 * size_h1 * size_h2; 
	list_stride_sd1_v2_1[3] = size_p5 * size_h2 * size_h3;
	list_stride_sd1_v2_1[4] = size_p5 * size_h1 * size_h3;
    list_stride_sd1_v2_1[5] = size_p5 * size_h1 * size_h2;

    list_stride_sd1_v2_1[6] = size_p6 * size_h2 * size_h3;
    list_stride_sd1_v2_1[7] = size_p6 * size_h1 * size_h3;
    list_stride_sd1_v2_1[8] = size_p6 * size_h1 * size_h2;

    cudaMemcpyToSymbol(list_stride_v2, list_stride_sd1_v2_1, sizeof(int) * 9);

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd1_9<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3),CEIL(size_h2, FUSION_SIZE_SLICE_1_H2),CEIL(size_h1, FUSION_SIZE_SLICE_1_H1),
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6),CEIL(size_p5, FUSION_SIZE_SLICE_1_P5),CEIL(size_p4, FUSION_SIZE_SLICE_1_P4),
    str_reg_x_1, str_reg_y_1,
    size_internal);
#endif
    // Copy the Result from Device to Host
	// cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost);

	// cudaFree()
    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

/*
    doubles (d2)
*/
// kernel: d2_1
__global__ void kernel_ccsdT_sd2_1(double* t3, 
    double* d_t2_1, double* d_v2_1, 
    int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
    int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
    int stride_reg_x, int stride_reg_y, int internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   	= 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    // Common for Threads within a Thread Block
    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }
    
    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }
    
    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_h1 && idx_h1 < rng_h2 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_1[(blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_p6 + (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h1) * size_h1) * size_p4) * size_p7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_p6 < rng_h3 && idx_h1 < rng_p6 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_b[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_v2_1[(blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_p6 + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_h1 + (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll) * size_p6) * size_h3) * size_p7 + (threadIdx.x + l)];
        }
        __syncthreads();

        // Cross-Product: 16
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {   
            temp_bv[0] = sm_a[ll][idx_h1 + (idx_h2) * FUSION_SIZE_SLICE_1_H1 + 0];
            temp_bv[1] = sm_a[ll][idx_h1 + (idx_h2) * FUSION_SIZE_SLICE_1_H1 + 16];
            temp_bv[2] = sm_a[ll][idx_h1 + (idx_h2) * FUSION_SIZE_SLICE_1_H1 + 32];
            temp_bv[3] = sm_a[ll][idx_h1 + (idx_h2) * FUSION_SIZE_SLICE_1_H1 + 48];
            
            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_b[ll][idx_h3 + (idx_p6) * FUSION_SIZE_SLICE_1_H3 + (xx * 16)];

                reg_tile[0][xx] -= temp_av * temp_bv[0];
                reg_tile[1][xx] -= temp_av * temp_bv[1];
                reg_tile[2][xx] -= temp_av * temp_bv[2];
                reg_tile[3][xx] -= temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    // 
    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d2_1
void jk_ccsd_t_d2_1(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_p7, double* host_t3, double* host_t2, double* host_v2)
{
    // # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int internal = size_p7;

    // Device Memory for Inputs and Output
    double *dev_t3;
    double *dev_t2;
    double *dev_v2;
    
    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h2 * size_h1 * size_p4 * size_p7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_p5 * size_p6 * size_h3 * size_p7);

    size_t size_t2 = sizeof(double) * size_h2 * size_h1 * size_p4 * size_p7;
    size_t size_v2 = sizeof(double) * size_p5 * size_p6 * size_h3 * size_p7;

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h2 * size_h1 * size_p4 * size_p7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_p5 * size_p6 * size_h3 * size_p7, cudaMemcpyHostToDevice);
    
    num_blocks_kernel_1 =   CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * 
                            CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);

    // num_blocks_kernel_2 =   CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * 
    //                         CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

    
    // (5) launch kernel(s)
    // Depends on # of Fused Kernel
    dim3 gridsize_1(num_blocks_kernel_1);
    dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

    // dim3 gridsize_2(num_blocks_kernel_2);
    // dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

    int	str_sd2_t3_h3 = 1;
    int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
    int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
    int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
    int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
    int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

    int str_reg_x_1 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    int str_reg_y_1 = str_sd2_t3_p4;	// STR_SD2_T3_P4
    // int str_reg_x_2 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    // int str_reg_y_2 = str_sd2_t3_p6;	// SDT_SD2_T3_P6

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd2_1<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3), CEIL(size_h2, FUSION_SIZE_SLICE_1_H2), CEIL(size_h1, FUSION_SIZE_SLICE_1_H1), 
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6), CEIL(size_p5, FUSION_SIZE_SLICE_1_P5), CEIL(size_p4, FUSION_SIZE_SLICE_1_P4), 
    str_reg_x_1, str_reg_y_1,
    internal);
#endif
    // 
    // cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyDeviceToHost);

    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d2_2
__global__ void kernel_ccsdT_sd2_2(double* t3, 
    double* d_t2_2, double* d_v2_2, 
    int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
    int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
    int stride_reg_x, int stride_reg_y, int internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   	= 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    // Common for Threads within a Thread Block
    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }
    
    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }
    
    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_h2 && idx_h1 < rng_h3 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_2[(blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll + (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_p6 + (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h1) * size_h2) * size_p4) * size_p7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_p6 < rng_h1 && idx_h1 < rng_p6 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_b[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_v2_2[(blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_p6 + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_h1 + (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll) * size_p6) * size_h1) * size_p7 + (threadIdx.x + l)];
        }
        __syncthreads();

        // Cross-Product: 16
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_a[ll][idx_h2 + (idx_h3) * FUSION_SIZE_SLICE_1_H2 + 0];
            temp_bv[1] = sm_a[ll][idx_h2 + (idx_h3) * FUSION_SIZE_SLICE_1_H2 + 16];
            temp_bv[2] = sm_a[ll][idx_h2 + (idx_h3) * FUSION_SIZE_SLICE_1_H2 + 32];
            temp_bv[3] = sm_a[ll][idx_h2 + (idx_h3) * FUSION_SIZE_SLICE_1_H2 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_b[ll][idx_h1 + (idx_p6) * FUSION_SIZE_SLICE_1_H1 + (xx * 16)];

                reg_tile[0][xx] -= temp_av * temp_bv[0];
                reg_tile[1][xx] -= temp_av * temp_bv[1];
                reg_tile[2][xx] -= temp_av * temp_bv[2];
                reg_tile[3][xx] -= temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    // 
    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d2_2
void jk_ccsd_t_d2_2(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_p7, double* host_t3, double* host_t2, double* host_v2)
{
    // # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int internal = size_p7;

    // Device Memory for Inputs and Output
    double *dev_t3;
    double *dev_t2;
    double *dev_v2;
    
    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h3 * size_h2 * size_p4 * size_p7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_p5 * size_p6 * size_h1 * size_p7);

    size_t size_t2 = sizeof(double) * size_h3 * size_h2 * size_p4 * size_p7;
    size_t size_v2 = sizeof(double) * size_p5 * size_p6 * size_h1 * size_p7;

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h3 * size_h2 * size_p4 * size_p7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_p5 * size_p6 * size_h1 * size_p7, cudaMemcpyHostToDevice);
    
    num_blocks_kernel_1 =   CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * 
                            CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);

    // num_blocks_kernel_2 =   CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * 
    //                         CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

    
    // (5) launch kernel(s)
    // Depends on # of Fused Kernel
    dim3 gridsize_1(num_blocks_kernel_1);
    dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

    // dim3 gridsize_2(num_blocks_kernel_2);
    // dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

    int	str_sd2_t3_h3 = 1;
    int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
    int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
    int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
    int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
    int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

    int str_reg_x_1 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    int str_reg_y_1 = str_sd2_t3_p4;	// STR_SD2_T3_P4
    // int str_reg_x_2 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    // int str_reg_y_2 = str_sd2_t3_p6;	// SDT_SD2_T3_P6

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd2_2<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3), CEIL(size_h2, FUSION_SIZE_SLICE_1_H2), CEIL(size_h1, FUSION_SIZE_SLICE_1_H1), 
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6), CEIL(size_p5, FUSION_SIZE_SLICE_1_P5), CEIL(size_p4, FUSION_SIZE_SLICE_1_P4), 
    str_reg_x_1, str_reg_y_1,
    internal);
#endif
    // 
    // cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyDeviceToHost);

    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d2_3
__global__ void kernel_ccsdT_sd2_3(double* t3, 
    double* d_t2_3, double* d_v2_3, 
    int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
    int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
    int stride_reg_x, int stride_reg_y, int internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   	= 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    // Common for Threads within a Thread Block
    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }
    
    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }
    
    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_h1 && idx_h1 < rng_h3 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_3[(blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_p6 + (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h1) * size_h1) * size_p4) * size_p7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_p6 < rng_h2 && idx_h1 < rng_p6 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_b[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_v2_3[(blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_p6 + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_h1 + (blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll) * size_p6) * size_h2) * size_p7 + (threadIdx.x + l)];
        }
        __syncthreads();

        // Cross-Product: 16
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_a[ll][idx_h1 + (idx_h3) * FUSION_SIZE_SLICE_1_H1 + 0];
            temp_bv[1] = sm_a[ll][idx_h1 + (idx_h3) * FUSION_SIZE_SLICE_1_H1 + 16];
            temp_bv[2] = sm_a[ll][idx_h1 + (idx_h3) * FUSION_SIZE_SLICE_1_H1 + 32];
            temp_bv[3] = sm_a[ll][idx_h1 + (idx_h3) * FUSION_SIZE_SLICE_1_H1 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_b[ll][idx_h2 + (idx_p6) * FUSION_SIZE_SLICE_1_H2 + (xx * 16)];

                reg_tile[0][xx] += temp_av * temp_bv[0];
                reg_tile[1][xx] += temp_av * temp_bv[1];
                reg_tile[2][xx] += temp_av * temp_bv[2];
                reg_tile[3][xx] += temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    // 
    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d2_3
void jk_ccsd_t_d2_3(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_p7, double* host_t3, double* host_t2, double* host_v2)
{
    // # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int internal = size_p7;

    // Device Memory for Inputs and Output
    double *dev_t3;
    double *dev_t2;
    double *dev_v2;
    
    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h3 * size_h1 * size_p4 * size_p7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_p5 * size_p6 * size_h2 * size_p7);

    size_t size_t2 = sizeof(double) * size_h3 * size_h1 * size_p4 * size_p7;
    size_t size_v2 = sizeof(double) * size_p5 * size_p6 * size_h2 * size_p7;

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h3 * size_h1 * size_p4 * size_p7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_p5 * size_p6 * size_h2 * size_p7, cudaMemcpyHostToDevice);
    
    num_blocks_kernel_1 =   CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * 
                            CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);

    // num_blocks_kernel_2 =   CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * 
    //                         CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);
    
    // (5) launch kernel(s)
    // Depends on # of Fused Kernel
    dim3 gridsize_1(num_blocks_kernel_1);
    dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

    // dim3 gridsize_2(num_blocks_kernel_2);
    // dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

    int	str_sd2_t3_h3 = 1;
    int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
    int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
    int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
    int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
    int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

    int str_reg_x_1 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    int str_reg_y_1 = str_sd2_t3_p4;	// STR_SD2_T3_P4
    // int str_reg_x_2 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    // int str_reg_y_2 = str_sd2_t3_p6;	// SDT_SD2_T3_P6

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd2_3<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3), CEIL(size_h2, FUSION_SIZE_SLICE_1_H2), CEIL(size_h1, FUSION_SIZE_SLICE_1_H1), 
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6), CEIL(size_p5, FUSION_SIZE_SLICE_1_P5), CEIL(size_p4, FUSION_SIZE_SLICE_1_P4), 
    str_reg_x_1, str_reg_y_1,
    internal);
#endif
    // 
    // cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyDeviceToHost);

    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d2_4
__global__ void kernel_ccsdT_sd2_4(double* t3, 
    double* d_t2_4, double* d_v2_4, 
    int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
    int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
    int stride_reg_x, int stride_reg_y, int internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   	= 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    // Common for Threads within a Thread Block
    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }
    
    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }
    
    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_h1 && idx_h1 < rng_h2 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_4[(blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_p6 + (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_h1) * size_h1) * size_p5) * size_p7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_p6 < rng_h3 && idx_h1 < rng_p6 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_b[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_v2_4[(blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_p6 + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_h1 + (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll) * size_p6) * size_h3) * size_p7 + (threadIdx.x + l)];
        }
        __syncthreads();

        // Cross-Product: 16
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_b[ll][idx_h3 + (idx_p6) * FUSION_SIZE_SLICE_1_H1 + 0];
            temp_bv[1] = sm_b[ll][idx_h3 + (idx_p6) * FUSION_SIZE_SLICE_1_H1 + 16];
            temp_bv[2] = sm_b[ll][idx_h3 + (idx_p6) * FUSION_SIZE_SLICE_1_H1 + 32];
            temp_bv[3] = sm_b[ll][idx_h3 + (idx_p6) * FUSION_SIZE_SLICE_1_H1 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_a[ll][idx_h1 + (idx_h2) * FUSION_SIZE_SLICE_1_H1 + (xx * 16)];

                reg_tile[0][xx] += temp_av * temp_bv[0];
                reg_tile[1][xx] += temp_av * temp_bv[1];
                reg_tile[2][xx] += temp_av * temp_bv[2];
                reg_tile[3][xx] += temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    // 
    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d2_4
void jk_ccsd_t_d2_4(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_p7, double* host_t3, double* host_t2, double* host_v2)
{
    // # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int internal = size_p7;

    // Device Memory for Inputs and Output
    double *dev_t3;
    double *dev_t2;
    double *dev_v2;
    
    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h2 * size_h1 * size_p5 * size_p7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_p4 * size_p6 * size_h3 * size_p7);

    size_t size_t2 = sizeof(double) * size_h2 * size_h1 * size_p5 * size_p7;
    size_t size_v2 = sizeof(double) * size_p4 * size_p6 * size_h3 * size_p7;

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h2 * size_h1 * size_p5 * size_p7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_p4 * size_p6 * size_h3 * size_p7, cudaMemcpyHostToDevice);
    
    num_blocks_kernel_1 =   CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * 
                            CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);

    // num_blocks_kernel_2 =   CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * 
    //                         CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

    // (5) launch kernel(s)
    // Depends on # of Fused Kernel
    dim3 gridsize_1(num_blocks_kernel_1);
    dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

    // dim3 gridsize_2(num_blocks_kernel_2);
    // dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

    int	str_sd2_t3_h3 = 1;
    int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
    int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
    int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
    int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
    int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

    int str_reg_x_1 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    int str_reg_y_1 = str_sd2_t3_p4;	// STR_SD2_T3_P4
    // int str_reg_x_2 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    // int str_reg_y_2 = str_sd2_t3_p6;	// SDT_SD2_T3_P6

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd2_4<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    (int)size_h3, (int)size_h2, (int)size_h1, (int)size_p6, (int)size_p5, (int)size_p4, (int)size_p7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3), CEIL(size_h2, FUSION_SIZE_SLICE_1_H2), CEIL(size_h1, FUSION_SIZE_SLICE_1_H1), 
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6), CEIL(size_p5, FUSION_SIZE_SLICE_1_P5), CEIL(size_p4, FUSION_SIZE_SLICE_1_P4), 
    str_reg_x_1, str_reg_y_1,
    internal);
#endif
    // 
    // cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyDeviceToHost);

    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d2_5
__global__ void kernel_ccsdT_sd2_5(double* t3, 
    double* d_t2_5, double* d_v2_5, 
    int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
    int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
    int stride_reg_x, int stride_reg_y, int internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   	= 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    // Common for Threads within a Thread Block
    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }
    
    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }
    
    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_h2 && idx_h1 < rng_h3 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_5[(blk_idx_p5 * FUSION_SIZE_SLICE_1_P5 + ll + (blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_p6 + (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h1) * size_h2) * size_p5) * size_p7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_p6 < rng_h1 && idx_h1 < rng_p6 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_b[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_v2_5[(blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_p6 + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_h1 + (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll) * size_p6) * size_h1) * size_p7 + (threadIdx.x + l)];
        }
        __syncthreads();

        // Cross-Product: 16
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_b[ll][idx_h1 + (idx_p6) * FUSION_SIZE_SLICE_1_H1 + 0];
            temp_bv[1] = sm_b[ll][idx_h1 + (idx_p6) * FUSION_SIZE_SLICE_1_H1 + 16];
            temp_bv[2] = sm_b[ll][idx_h1 + (idx_p6) * FUSION_SIZE_SLICE_1_H1 + 32];
            temp_bv[3] = sm_b[ll][idx_h1 + (idx_p6) * FUSION_SIZE_SLICE_1_H1 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_a[ll][idx_h2 + (idx_h3) * FUSION_SIZE_SLICE_1_H2 + (xx * 16)];

                reg_tile[0][xx] += temp_av * temp_bv[0];
                reg_tile[1][xx] += temp_av * temp_bv[1];
                reg_tile[2][xx] += temp_av * temp_bv[2];
                reg_tile[3][xx] += temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    // 
    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d2_5
void jk_ccsd_t_d2_5(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_p7, double* host_t3, double* host_t2, double* host_v2)
{
    // # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int internal = size_p7;

    // Device Memory for Inputs and Output
    double *dev_t3;
    double *dev_t2;
    double *dev_v2;
    
    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h3 * size_h2 * size_p5 * size_p7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_p4 * size_p6 * size_h1 * size_p7);

    size_t size_t2 = sizeof(double) * size_h3 * size_h2 * size_p5 * size_p7;
    size_t size_v2 = sizeof(double) * size_p4 * size_p6 * size_h1 * size_p7;

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h3 * size_h2 * size_p5 * size_p7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_p4 * size_p6 * size_h1 * size_p7, cudaMemcpyHostToDevice);
    
    num_blocks_kernel_1 =   CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * 
                            CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);

    // num_blocks_kernel_2 =   CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * 
    //                         CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

    // (5) launch kernel(s)
    // Depends on # of Fused Kernel
    dim3 gridsize_1(num_blocks_kernel_1);
    dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

    // dim3 gridsize_2(num_blocks_kernel_2);
    // dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

    int	str_sd2_t3_h3 = 1;
    int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
    int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
    int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
    int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
    int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

    int str_reg_x_1 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    int str_reg_y_1 = str_sd2_t3_p4;	// STR_SD2_T3_P4
    // int str_reg_x_2 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    // int str_reg_y_2 = str_sd2_t3_p6;	// SDT_SD2_T3_P6

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd2_5<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    (int)size_h3, (int)size_h2, (int)size_h1, (int)size_p6, (int)size_p5, (int)size_p4, (int)size_p7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3), CEIL(size_h2, FUSION_SIZE_SLICE_1_H2), CEIL(size_h1, FUSION_SIZE_SLICE_1_H1), 
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6), CEIL(size_p5, FUSION_SIZE_SLICE_1_P5), CEIL(size_p4, FUSION_SIZE_SLICE_1_P4), 
    str_reg_x_1, str_reg_y_1,
    internal);
#endif
    // 
    // cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyDeviceToHost);

    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d2_6
__global__ void kernel_ccsdT_sd2_6(double* t3, 
    double* d_t2_6, double* d_v2_6, 
    int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
    int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
    int stride_reg_x, int stride_reg_y, int internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   	= 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_1_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_1_H3;
    int idx_p6 = threadIdx.y % FUSION_SIZE_SLICE_1_P6;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_1_P6;

    // Common for Threads within a Thread Block
    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }
    
    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }
    
    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + idx_p6 + 
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p6 < rng_h1 && idx_h1 < rng_h3 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_t2_6[(blk_idx_p5 * FUSION_SIZE_SLICE_1_P6 + ll + (blk_idx_h1 * FUSION_SIZE_SLICE_1_H1 + idx_p6 + (blk_idx_h3 * FUSION_SIZE_SLICE_1_H3 + idx_h1) * size_h1) * size_p5) * size_p7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_p6 < rng_h2 && idx_h1 < rng_p6 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p4; ll++)
        {
            sm_b[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_1_Y] = d_v2_6[(blk_idx_h2 * FUSION_SIZE_SLICE_1_H2 + idx_p6 + (blk_idx_p6 * FUSION_SIZE_SLICE_1_P6 + idx_h1 + (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + ll) * size_p6) * size_h2) * size_p7 + (threadIdx.x + l)];
        }
        __syncthreads();

        // Cross-Product: 16
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_b[ll][idx_h2 + (idx_p6) * FUSION_SIZE_SLICE_1_H2 + 0];
            temp_bv[1] = sm_b[ll][idx_h2 + (idx_p6) * FUSION_SIZE_SLICE_1_H2 + 16];
            temp_bv[2] = sm_b[ll][idx_h2 + (idx_p6) * FUSION_SIZE_SLICE_1_H2 + 32];
            temp_bv[3] = sm_b[ll][idx_h2 + (idx_p6) * FUSION_SIZE_SLICE_1_H2 + 48];

            for (int xx = 0; xx < 4; xx++)	// 4 -> rng_p4: Local Transactions...
            {
                temp_av = sm_a[ll][idx_h1 + (idx_h3) * FUSION_SIZE_SLICE_1_H1 + (xx * 16)];

                reg_tile[0][xx] -= temp_av * temp_bv[0];
                reg_tile[1][xx] -= temp_av * temp_bv[1];
                reg_tile[2][xx] -= temp_av * temp_bv[2];
                reg_tile[3][xx] -= temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    // 
    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_h1)
    {
        if (rng_p4 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p4 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p4 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p4 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d2_6
void jk_ccsd_t_d2_6(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_p7, double* host_t3, double* host_t2, double* host_v2)
{
    // # of Blocks for Each Kernel
    int	num_blocks_kernel_1;
    // int num_blocks_kernel_2;
    int internal = size_p7;

    // Device Memory for Inputs and Output
    double *dev_t3;
    double *dev_t2;
    double *dev_v2;
    
    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h3 * size_h1 * size_p5 * size_p7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_p4 * size_p6 * size_h2 * size_p7);

    size_t size_t2 = sizeof(double) * size_h3 * size_h1 * size_p5 * size_p7;
    size_t size_v2 = sizeof(double) * size_p4 * size_p6 * size_h2 * size_p7;

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // 
    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h3 * size_h1 * size_p5 * size_p7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_p4 * size_p6 * size_h2 * size_p7, cudaMemcpyHostToDevice);
    
    num_blocks_kernel_1 =   CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * 
                            CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);

    // num_blocks_kernel_2 =   CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * 
    //                         CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

    // (5) launch kernel(s)
    // Depends on # of Fused Kernel
    dim3 gridsize_1(num_blocks_kernel_1);
    dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

    // dim3 gridsize_2(num_blocks_kernel_2);
    // dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

    int	str_sd2_t3_h3 = 1;
    int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
    int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
    int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
    int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
    int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

    int str_reg_x_1 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    int str_reg_y_1 = str_sd2_t3_p4;	// STR_SD2_T3_P4
    // int str_reg_x_2 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    // int str_reg_y_2 = str_sd2_t3_p6;	// SDT_SD2_T3_P6

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd2_6<<<gridsize_1, blocksize_1>>>(dev_t3, 
    dev_t2, dev_v2, 
    (int)size_h3, (int)size_h2, (int)size_h1, (int)size_p6, (int)size_p5, (int)size_p4, (int)size_p7,
    CEIL(size_h3, FUSION_SIZE_SLICE_1_H3), CEIL(size_h2, FUSION_SIZE_SLICE_1_H2), CEIL(size_h1, FUSION_SIZE_SLICE_1_H1), 
    CEIL(size_p6, FUSION_SIZE_SLICE_1_P6), CEIL(size_p5, FUSION_SIZE_SLICE_1_P5), CEIL(size_p4, FUSION_SIZE_SLICE_1_P4), 
    str_reg_x_1, str_reg_y_1,
    internal);
#endif
    // 
    // cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyDeviceToHost);

    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d2_7
__global__ void kernel_ccsdT_sd2_7(double* t3, 
    double* d_t2_7, double* d_v2_7, 
    int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
    int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
    int stride_reg_x, int stride_reg_y, int internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_2_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_2_H3;
    int idx_p4 = threadIdx.y % FUSION_SIZE_SLICE_2_P4;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_2_P4;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }
    
    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }
    
    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 +  
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_p4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p4 < rng_h1 && idx_h1 < rng_h2 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p6; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_2_Y] = d_t2_7[(blk_idx_p6 *  FUSION_SIZE_SLICE_2_P6 + ll + (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_p4 + (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h1) * size_h1) * size_p6) * size_p7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_p4 < rng_h3 && idx_h1 < rng_p4 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_b[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_2_Y] = d_v2_7[(blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_p4 + (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + ll + (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_h1) * size_p5) * size_h3) * size_p7 + (threadIdx.x + l)];
        }
        __syncthreads();

        // Cross-Product: 16
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_a[ll][idx_h1 + (idx_h2) * FUSION_SIZE_SLICE_2_H1 + 0];
            temp_bv[1] = sm_a[ll][idx_h1 + (idx_h2) * FUSION_SIZE_SLICE_2_H1 + 16];
            temp_bv[2] = sm_a[ll][idx_h1 + (idx_h2) * FUSION_SIZE_SLICE_2_H1 + 32];
            temp_bv[3] = sm_a[ll][idx_h1 + (idx_h2) * FUSION_SIZE_SLICE_2_H1 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_b[ll][idx_h3 + (idx_p4) * FUSION_SIZE_SLICE_2_H3 + (xx * 16)];

                reg_tile[0][xx] -= temp_av * temp_bv[0];
                reg_tile[1][xx] -= temp_av * temp_bv[1];
                reg_tile[2][xx] -= temp_av * temp_bv[2];
                reg_tile[3][xx] -= temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    // 
    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d2_7
void jk_ccsd_t_d2_7(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_p7, double* host_t3, double* host_t2, double* host_v2)
{
    // # of Blocks for Each Kernel
    // int	num_blocks_kernel_1;
    int num_blocks_kernel_2;
    int internal = size_p7;

    // Device Memory for Inputs and Output
    double *dev_t3;
    double *dev_t2;
    double *dev_v2;
    
    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h2 * size_h1 * size_p6 * size_p7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_p4 * size_p5 * size_h3 * size_p7);

    size_t size_t2 = sizeof(double) * size_h2 * size_h1 * size_p6 * size_p7;
    size_t size_v2 = sizeof(double) * size_p4 * size_p5 * size_h3 * size_p7;

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h2 * size_h1 * size_p6 * size_p7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_p4 * size_p5 * size_h3 * size_p7, cudaMemcpyHostToDevice);
    
    // num_blocks_kernel_1 =   CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * 
    //                         CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);

    num_blocks_kernel_2 =   CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * 
                            CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

    // (5) launch kernel(s)
    // Depends on # of Fused Kernel
    // dim3 gridsize_1(num_blocks_kernel_1);
    // dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

    dim3 gridsize_2(num_blocks_kernel_2);
    dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

    int	str_sd2_t3_h3 = 1;
    int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
    int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
    int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
    int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
    // int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

    // int str_reg_x_1 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    // int str_reg_y_1 = str_sd2_t3_p4;	// STR_SD2_T3_P4
    int str_reg_x_2 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    int str_reg_y_2 = str_sd2_t3_p6;	// SDT_SD2_T3_P6

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd2_7<<<gridsize_2, blocksize_2>>>(dev_t3, 
    dev_t2, dev_v2, 
    (int)size_h3, (int)size_h2, (int)size_h1, (int)size_p6, (int)size_p5, (int)size_p4, (int)size_p7,
    CEIL(size_h3, FUSION_SIZE_SLICE_2_H3), CEIL(size_h2, FUSION_SIZE_SLICE_2_H2), CEIL(size_h1, FUSION_SIZE_SLICE_2_H1), 
    CEIL(size_p6, FUSION_SIZE_SLICE_2_P6), CEIL(size_p5, FUSION_SIZE_SLICE_2_P5), CEIL(size_p4, FUSION_SIZE_SLICE_2_P4), 
    str_reg_x_2, str_reg_y_2,
    internal);
#endif
    // 
    // cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyDeviceToHost);

    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d2_8
__global__ void kernel_ccsdT_sd2_8(double* t3, 
    double* d_t2_8, double* d_v2_8, 
    int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
    int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
    int stride_reg_x, int stride_reg_y, int internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_2_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_2_H3;
    int idx_p4 = threadIdx.y % FUSION_SIZE_SLICE_2_P4;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_2_P4;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }
    
    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }
    
    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 +  
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_p4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p4 < rng_h2 && idx_h1 < rng_h3 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p6; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_2_Y] = d_t2_8[(blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + ll + (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_p4 + (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h1) * size_h2) * size_p6) * size_p7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_p4 < rng_h1 && idx_h1 < rng_p4 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_b[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_2_Y] = d_v2_8[(blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_p4 + (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + ll + (blk_idx_p4 * FUSION_SIZE_SLICE_1_P4 + idx_h1) * size_p5) * size_h1) * size_p7 + (threadIdx.x + l)];
        }
        __syncthreads();

        // Cross-Product: 16
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_a[ll][idx_h2 + (idx_h3) * FUSION_SIZE_SLICE_2_H2 + 0];
            temp_bv[1] = sm_a[ll][idx_h2 + (idx_h3) * FUSION_SIZE_SLICE_2_H2 + 16];
            temp_bv[2] = sm_a[ll][idx_h2 + (idx_h3) * FUSION_SIZE_SLICE_2_H2 + 32];
            temp_bv[3] = sm_a[ll][idx_h2 + (idx_h3) * FUSION_SIZE_SLICE_2_H2 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_b[ll][idx_h1 + (idx_p4) * FUSION_SIZE_SLICE_2_H1 + (xx * 16)];

                reg_tile[0][xx] -= temp_av * temp_bv[0];
                reg_tile[1][xx] -= temp_av * temp_bv[1];
                reg_tile[2][xx] -= temp_av * temp_bv[2];
                reg_tile[3][xx] -= temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d2_8
void jk_ccsd_t_d2_8(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_p7, double* host_t3, double* host_t2, double* host_v2)
{
    // # of Blocks for Each Kernel
    // int	num_blocks_kernel_1;
    int num_blocks_kernel_2;
    int internal = size_p7;

    // Device Memory for Inputs and Output
    double *dev_t3;
    double *dev_t2;
    double *dev_v2;
    
    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);    
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h3 * size_h2 * size_p6 * size_p7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_p4 * size_p5 * size_h1 * size_p7);

    size_t size_t2 = sizeof(double) * size_h3 * size_h2 * size_p6 * size_p7;
    size_t size_v2 = sizeof(double) * size_p4 * size_p5 * size_h1 * size_p7;

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h3 * size_h2 * size_p6 * size_p7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_p4 * size_p5 * size_h1 * size_p7, cudaMemcpyHostToDevice);
    
    // num_blocks_kernel_1 =   CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * 
    //                         CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);

    num_blocks_kernel_2 =   CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * 
                            CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

    // (5) launch kernel(s)
    // Depends on # of Fused Kernel
    // dim3 gridsize_1(num_blocks_kernel_1);
    // dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

    dim3 gridsize_2(num_blocks_kernel_2);
    dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

    int	str_sd2_t3_h3 = 1;
    int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
    int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
    int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
    int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
    // int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

    // int str_reg_x_1 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    // int str_reg_y_1 = str_sd2_t3_p4;	// STR_SD2_T3_P4
    int str_reg_x_2 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    int str_reg_y_2 = str_sd2_t3_p6;	// SDT_SD2_T3_P6

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd2_8<<<gridsize_2, blocksize_2>>>(dev_t3, 
    dev_t2, dev_v2, 
    (int)size_h3, (int)size_h2, (int)size_h1, (int)size_p6, (int)size_p5, (int)size_p4, (int)size_p7,
    CEIL(size_h3, FUSION_SIZE_SLICE_2_H3), CEIL(size_h2, FUSION_SIZE_SLICE_2_H2), CEIL(size_h1, FUSION_SIZE_SLICE_2_H1), 
    CEIL(size_p6, FUSION_SIZE_SLICE_2_P6), CEIL(size_p5, FUSION_SIZE_SLICE_2_P5), CEIL(size_p4, FUSION_SIZE_SLICE_2_P4), 
    str_reg_x_2, str_reg_y_2,
    internal);
#endif
    // 
    // cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyDeviceToHost);

    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: d2_9
__global__ void kernel_ccsdT_sd2_9(double* t3, 
    double* d_t2_9, double* d_v2_9, 
    int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
    int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
    int stride_reg_x, int stride_reg_y, int internal)
{
    // For Shared Memory,
    __shared__ double sm_a[16][64 + 1];
    __shared__ double sm_b[16][64 + 1];

    int internal_upperbound   = 0;
    int internal_offset;

    // should support for non-full tiles
    int idx_h3 = threadIdx.x % FUSION_SIZE_SLICE_2_H3;
    int idx_h2 = threadIdx.x / FUSION_SIZE_SLICE_2_H3;
    int idx_p4 = threadIdx.y % FUSION_SIZE_SLICE_2_P4;
    int idx_h1 = threadIdx.y / FUSION_SIZE_SLICE_2_P4;

    int tmp_blkIdx;        
    int blk_idx_p4  = blockIdx.x / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);
    tmp_blkIdx      = blockIdx.x % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6 * numBlk_p5);

    int blk_idx_p5  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1 * numBlk_p6);

    int blk_idx_p6  = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2 * numBlk_h1);
    tmp_blkIdx      = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2 * numBlk_h1);

    int blk_idx_h1 = (tmp_blkIdx) / (numBlk_h3 * numBlk_h2);
    tmp_blkIdx     = (tmp_blkIdx) % (numBlk_h3 * numBlk_h2);

    int blk_idx_h2 = (tmp_blkIdx) / (numBlk_h3);
    int blk_idx_h3 = (tmp_blkIdx) % (numBlk_h3);

    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;

    if ((size_h3 - (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3)) >= FUSION_SIZE_SLICE_2_H3)
    {
        rng_h3 = FUSION_SIZE_SLICE_2_H3;
    }
    else
    {
        rng_h3 = size_h3 % FUSION_SIZE_SLICE_2_H3;
    }
    
    if ((size_h2 - (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2)) >= FUSION_SIZE_SLICE_2_H2)
    {
        rng_h2 = FUSION_SIZE_SLICE_2_H2;
    }
    else
    {
        rng_h2 = size_h2 % FUSION_SIZE_SLICE_2_H2;
    }

    if ((size_h1 - (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1)) >= FUSION_SIZE_SLICE_2_H1)
    {
        rng_h1 = FUSION_SIZE_SLICE_2_H1;
    }
    else
    {
        rng_h1 = size_h1 % FUSION_SIZE_SLICE_2_H1;
    }
    
    if ((size_p6 - (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6)) >= FUSION_SIZE_SLICE_2_P6)
    {
        rng_p6 = FUSION_SIZE_SLICE_2_P6;
    }
    else
    {
        rng_p6 = size_p6 % FUSION_SIZE_SLICE_2_P6;
    }

    if ((size_p5 - (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5)) >= FUSION_SIZE_SLICE_2_P5)
    {
        rng_p5 = FUSION_SIZE_SLICE_2_P5;
    }
    else
    {
        rng_p5 = size_p5 % FUSION_SIZE_SLICE_2_P5;
    }

    if ((size_p4 - (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4)) >= FUSION_SIZE_SLICE_2_P4)
    {
        rng_p4 = FUSION_SIZE_SLICE_2_P4;
    }
    else
    {
        rng_p4 = size_p4 % FUSION_SIZE_SLICE_2_P4;
    }

    int t3_base_thread = blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h3 + 
                        (blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_h2 + 
                        (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_h1 + 
                        (blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 +  
                        (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + 
                        (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_p4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;


    double temp_av;
    double temp_bv[4];
    double reg_tile[4][4];

    for (int i = 0; i < 4; i++)
    for (int j = 0; j < 4; j++)
    reg_tile[i][j] = 0.0;

    // tensor contraction
    #pragma unroll 1
    for (int l = 0; l < internal; l+= FUSION_SIZE_INT_UNIT)
    {
        // Part: Generalized Contraction Index (p7b)
        internal_offset = (l + FUSION_SIZE_INT_UNIT) - internal;
        if (internal_offset > 0) internal_upperbound = internal_offset;

        // Load Input Tensor to Shared Memory: 16:16
        // # of Internal Indices: 1
        if (idx_p4 < rng_h1 && idx_h1 < rng_h3 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p6; ll++)
        {
            sm_a[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_2_Y] = d_t2_9[(blk_idx_p6 * FUSION_SIZE_SLICE_2_P6 + ll + (blk_idx_h1 * FUSION_SIZE_SLICE_2_H1 + idx_p4 + (blk_idx_h3 * FUSION_SIZE_SLICE_2_H3 + idx_h1) * size_h1) * size_p6) * size_p7 + (threadIdx.x + l)];
        }

        // Load Input Tensor to Shared Memory
        if (idx_p4 < rng_h2 && idx_h1 < rng_p4 && threadIdx.x < FUSION_SIZE_INT_UNIT - internal_upperbound)
        for (int ll = 0; ll < rng_p5; ll++)
        {
            sm_b[threadIdx.x][threadIdx.y + ll * FUSION_SIZE_TB_2_Y] = d_v2_9[(blk_idx_h2 * FUSION_SIZE_SLICE_2_H2 + idx_p4 + (blk_idx_p5 * FUSION_SIZE_SLICE_2_P5 + ll + (blk_idx_p4 * FUSION_SIZE_SLICE_2_P4 + idx_h1) * size_p5) * size_h2) * size_p7 + (threadIdx.x + l)];
        }
        __syncthreads();

        // Cross-Product: 16
        // Part: Generalized Threads
        for (int ll = 0; ll < FUSION_SIZE_INT_UNIT - internal_upperbound; ll++)
        {
            temp_bv[0] = sm_a[ll][idx_h1 + (idx_h3) * FUSION_SIZE_SLICE_2_H1 + 0];
            temp_bv[1] = sm_a[ll][idx_h1 + (idx_h3) * FUSION_SIZE_SLICE_2_H1 + 16];
            temp_bv[2] = sm_a[ll][idx_h1 + (idx_h3) * FUSION_SIZE_SLICE_2_H1 + 32];
            temp_bv[3] = sm_a[ll][idx_h1 + (idx_h3) * FUSION_SIZE_SLICE_2_H1 + 48];

            for (int xx = 0 ; xx < 4; xx++)
            {
                temp_av = sm_b[ll][idx_h2 + (idx_p4) * FUSION_SIZE_SLICE_2_H2 + (xx * 16)];

                reg_tile[0][xx] += temp_av * temp_bv[0];
                reg_tile[1][xx] += temp_av * temp_bv[1];
                reg_tile[2][xx] += temp_av * temp_bv[2];
                reg_tile[3][xx] += temp_av * temp_bv[3];
            }
        }
        __syncthreads();
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
            }
            if (rng_p5 == 2)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
            }
            if (rng_p5 == 3)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
            }
            if (rng_p5 == 4)
            {
                reg_tile[0][0] += t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[0][1] += t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[0][2] += t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[0][3] += t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[1][0] += t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[1][1] += t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[1][2] += t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[1][3] += t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[2][0] += t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[2][1] += t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[2][2] += t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[2][3] += t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)];

                reg_tile[3][0] += t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)];
                reg_tile[3][1] += t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)];
                reg_tile[3][2] += t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)];
                reg_tile[3][3] += t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)];
            }
        }
    }

    if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p4 < rng_p4 && idx_h1 < rng_h1)
    {
        if (rng_p6 == 1)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];
            }
        }
        if (rng_p6 == 2)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];
            }
        }
        if (rng_p6 == 3)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];
            }
        }
        if (rng_p6 == 4)
        {
            if (rng_p5 == 1)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
            }
            if (rng_p5 == 2)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
            }
            if (rng_p5 == 3)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
            }
            if (rng_p5 == 4)
            {
                t3[t3_base_thread + (0 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[0][0];
                t3[t3_base_thread + (0 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[0][1];
                t3[t3_base_thread + (0 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[0][2];
                t3[t3_base_thread + (0 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[0][3];

                t3[t3_base_thread + (1 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[1][0];
                t3[t3_base_thread + (1 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[1][1];
                t3[t3_base_thread + (1 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[1][2];
                t3[t3_base_thread + (1 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[1][3];

                t3[t3_base_thread + (2 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[2][0];
                t3[t3_base_thread + (2 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[2][1];
                t3[t3_base_thread + (2 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[2][2];
                t3[t3_base_thread + (2 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[2][3];

                t3[t3_base_thread + (3 * stride_reg_y) + (0 * stride_reg_x)] = reg_tile[3][0];
                t3[t3_base_thread + (3 * stride_reg_y) + (1 * stride_reg_x)] = reg_tile[3][1];
                t3[t3_base_thread + (3 * stride_reg_y) + (2 * stride_reg_x)] = reg_tile[3][2];
                t3[t3_base_thread + (3 * stride_reg_y) + (3 * stride_reg_x)] = reg_tile[3][3];
            }
        }
    }
}

// caller: d2_9
void jk_ccsd_t_d2_9(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, size_t size_p7, double* host_t3, double* host_t2, double* host_v2)
{
    // # of Blocks for Each Kernel
    // int	 num_blocks_kernel_1;
    int num_blocks_kernel_2;
    int internal = size_p7;

    // Device Memory for Inputs and Output
    double *dev_t3;
    double *dev_t2;
    double *dev_v2;
    
    // cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4);
    // cudaMalloc((void**) &dev_t2, sizeof(double) * size_h3 * size_h1 * size_p6 * size_p7);
    // cudaMalloc((void**) &dev_v2, sizeof(double) * size_p4 * size_p5 * size_h2 * size_p7);
    size_t size_t2 = sizeof(double) * size_h3 * size_h1 * size_p6 * size_p7;
    size_t size_v2 = sizeof(double) * size_p4 * size_p5 * size_h2 * size_p7;

    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);

    // cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h3 * size_h1 * size_p6 * size_p7, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_p4 * size_p5 * size_h2 * size_p7, cudaMemcpyHostToDevice);
    
    // num_blocks_kernel_1 =   CEIL(size_h3, FUSION_SIZE_SLICE_1_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_1_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_1_H1) * 
    //                         CEIL(size_p6, FUSION_SIZE_SLICE_1_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_1_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_1_P4);

    num_blocks_kernel_2 =   CEIL(size_h3, FUSION_SIZE_SLICE_2_H3) * CEIL(size_h2, FUSION_SIZE_SLICE_2_H2) * CEIL(size_h1, FUSION_SIZE_SLICE_2_H1) * 
                            CEIL(size_p6, FUSION_SIZE_SLICE_2_P6) * CEIL(size_p5, FUSION_SIZE_SLICE_2_P5) * CEIL(size_p4, FUSION_SIZE_SLICE_2_P4);

    // (5) launch kernel(s)
    // Depends on # of Fused Kernel
    // dim3 gridsize_1(num_blocks_kernel_1);
    // dim3 blocksize_1(FUSION_SIZE_TB_1_X, FUSION_SIZE_TB_1_Y);

    dim3 gridsize_2(num_blocks_kernel_2);
    dim3 blocksize_2(FUSION_SIZE_TB_2_X, FUSION_SIZE_TB_2_Y);

    int	str_sd2_t3_h3 = 1;
    int str_sd2_t3_h2 = str_sd2_t3_h3 * size_h3;
    int str_sd2_t3_h1 = str_sd2_t3_h2 * size_h2;
    int str_sd2_t3_p6 = str_sd2_t3_h1 * size_h1;
    int str_sd2_t3_p5 = str_sd2_t3_p6 * size_p6;
    // int str_sd2_t3_p4 = str_sd2_t3_p5 * size_p5;

    // int str_reg_x_1 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    // int str_reg_y_1 = str_sd2_t3_p4;	// STR_SD2_T3_P4
    int str_reg_x_2 = str_sd2_t3_p5;	// STR_SD2_T3_P5
    int str_reg_y_2 = str_sd2_t3_p6;	// SDT_SD2_T3_P6

    // 
    dev_t3 = t3_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    kernel_ccsdT_sd2_9<<<gridsize_2, blocksize_2>>>(dev_t3, 
    dev_t2, dev_v2, 
    (int)size_h3, (int)size_h2, (int)size_h1, (int)size_p6, (int)size_p5, (int)size_p4, (int)size_p7,
    CEIL(size_h3, FUSION_SIZE_SLICE_2_H3), CEIL(size_h2, FUSION_SIZE_SLICE_2_H2), CEIL(size_h1, FUSION_SIZE_SLICE_2_H1), 
    CEIL(size_p6, FUSION_SIZE_SLICE_2_P6), CEIL(size_p5, FUSION_SIZE_SLICE_2_P5), CEIL(size_p4, FUSION_SIZE_SLICE_2_P4), 
    str_reg_x_2, str_reg_y_2,
    internal);
#endif
    // 
    // cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyDeviceToHost);

    // cudaFree(dev_t3);
    // cudaFree(dev_t2); cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

/*  
    singles
*/
#define JK_CCSD_T_FUSED_S1_SIZE_TILE_H1     4
#define JK_CCSD_T_FUSED_S1_SIZE_TILE_H2     4
#define JK_CCSD_T_FUSED_S1_SIZE_TILE_H3     4
#define JK_CCSD_T_FUSED_S1_SIZE_TILE_P4     4
#define JK_CCSD_T_FUSED_S1_SIZE_TILE_P5     4
#define JK_CCSD_T_FUSED_S1_SIZE_TILE_P6     4

#define JK_CCSD_T_FUSED_S1_SIZE_TB_X        64  // 3 indices mapped to threadIdx.x
#define JK_CCSD_T_FUSED_S1_SIZE_TB_Y        4   // 1 index mapped to threadIdx.y

#define JK_CCSD_T_FUSED_S1_SIZE_REG_X       4   // p5
#define JK_CCSD_T_FUSED_S1_SIZE_REG_Y       4   // p4

// kernel: s1_1
__global__ void jk_ccsd_t_s1_1(double* d_t3, 
double* d_t2_1, double* d_v2_1, 
size_t size_h3,     size_t size_h2,     size_t size_h1,     size_t size_p6,     size_t size_p5,     size_t size_p4, 
size_t num_blks_h3, size_t num_blks_h2, size_t num_blks_h1, size_t num_blks_p6, size_t num_blks_p5, size_t num_blks_p4, 
size_t stride_reg_x, size_t stride_reg_y)
{
    //  Shared Memory
    __shared__ double sm_a[16];     // "T_p4" * T_h1
    __shared__ double sm_b[256];    // T_h3 * T_h2 * T_p6 * "T_p5"

    //  offset-indices
    int idx_p6  = threadIdx.x / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int tmp_idx = threadIdx.x % (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int idx_h2  = tmp_idx     / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    int idx_h3  = threadIdx.x % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    int idx_h1  = threadIdx.y;

    //  blk-indices
    int blk_idx_p4  = blockIdx.x / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    tmp_idx         = blockIdx.x % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    int blk_idx_p5  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    int blk_idx_p6  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1);
    int blk_idx_h1  = tmp_idx    / (num_blks_h3 * num_blks_h2);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2);
    int blk_idx_h2  = tmp_idx    / (num_blks_h3);
    int blk_idx_h3  = blockIdx.x % num_blks_h3;

    //  boundary-checks
    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
    // 
    if ((size_h3 - (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H3) 
        rng_h3 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    else
        rng_h3 = size_h3 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;

    //
    if ((size_h2 - (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) 
        rng_h2 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;
    else
        rng_h2 = size_h2 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;

    //
    if ((size_h1 - (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) 
        rng_h1 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;
    else
        rng_h1 = size_h1 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;

    //
    if ((size_p6 - (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) 
        rng_p6 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;
    else
        rng_p6 = size_p6 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;

    //
    if ((size_p5 - (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) 
        rng_p5 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;
    else
        rng_p5 = size_p5 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;

    //
    if ((size_p4 - (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) 
        rng_p4 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;
    else
        rng_p4 = size_p4 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;

    //
    int t3_based_addr =  blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                        (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                        (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h1 + 
                        (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                        (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + 
                        (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    //
    double tmp_av[4];
    double tmp_bv[4];    
    double reg_tile[4][4];

    //
    for (int i = 0; i < 4; i++) // i -> p4
    for (int j = 0; j < 4; j++) // j -> p5
    reg_tile[i][j] = 0.0; 

    //                                        "x"         "x"
    //  >> s1_1:   t3[h3,h2,h1,p6,p5,p4] -= t2[p4,h1] * v2[h3,h2,p6,p5]
    //
    {
        if (idx_h3 < rng_p4 && idx_h2 < rng_h1 && idx_p6 == 0 && idx_h1 == 0)
        sm_a[idx_h3 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4] = d_t2_1[blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4 + idx_h3 + (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h2) * size_p4];

        if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_p5)
        sm_b[idx_h3 + (idx_h2 + (idx_p6 + (idx_h1) * 4) * 4) * 4] = d_v2_1[blk_idx_h3 * 4 + idx_h3 + (blk_idx_h2 * 4 + idx_h2 + (blk_idx_p6 * 4 + idx_p6 + (blk_idx_p5 * 4 + idx_h1) * size_p6) * size_h2) * size_h3];
        __syncthreads();

        //  "p4"
        tmp_av[0] = sm_a[0 + (idx_h1) * 4];
        tmp_av[1] = sm_a[1 + (idx_h1) * 4];
        tmp_av[2] = sm_a[2 + (idx_h1) * 4];
        tmp_av[3] = sm_a[3 + (idx_h1) * 4];

        //  "p5"
        tmp_bv[0] = sm_b[idx_h3 + (idx_h2 + (idx_p6 + (0) * 4) * 4) * 4];
        tmp_bv[1] = sm_b[idx_h3 + (idx_h2 + (idx_p6 + (1) * 4) * 4) * 4];
        tmp_bv[2] = sm_b[idx_h3 + (idx_h2 + (idx_p6 + (2) * 4) * 4) * 4];
        tmp_bv[3] = sm_b[idx_h3 + (idx_h2 + (idx_p6 + (3) * 4) * 4) * 4];

        //  "p4 x p5"
        reg_tile[0][0] += tmp_av[0] * tmp_bv[0];// * reg_tile[0][0];
        reg_tile[0][1] += tmp_av[0] * tmp_bv[1];// * reg_tile[0][1];
        reg_tile[0][2] += tmp_av[0] * tmp_bv[2];// * reg_tile[0][2];
        reg_tile[0][3] += tmp_av[0] * tmp_bv[3];// * reg_tile[0][3];

        reg_tile[1][0] += tmp_av[1] * tmp_bv[0];// * reg_tile[1][0];
        reg_tile[1][1] += tmp_av[1] * tmp_bv[1];// * reg_tile[1][1];
        reg_tile[1][2] += tmp_av[1] * tmp_bv[2];// * reg_tile[1][2];
        reg_tile[1][3] += tmp_av[1] * tmp_bv[3];// * reg_tile[1][3];

        reg_tile[2][0] += tmp_av[2] * tmp_bv[0];// * reg_tile[2][0];
        reg_tile[2][1] += tmp_av[2] * tmp_bv[1];// * reg_tile[2][1];
        reg_tile[2][2] += tmp_av[2] * tmp_bv[2];// * reg_tile[2][2];
        reg_tile[2][3] += tmp_av[2] * tmp_bv[3];// * reg_tile[2][3];

        reg_tile[3][0] += tmp_av[3] * tmp_bv[0];// * reg_tile[3][0];
        reg_tile[3][1] += tmp_av[3] * tmp_bv[1];// * reg_tile[3][1];
        reg_tile[3][2] += tmp_av[3] * tmp_bv[2];// * reg_tile[3][2];
        reg_tile[3][3] += tmp_av[3] * tmp_bv[3];// * reg_tile[3][3];
    }

    //
    //  to store the output
    //
    if (idx_h1 < rng_h1 && idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6)
    for (int i = 0; i < 4; i++) // p4
    {
        for (int j = 0; j < 4; j++) // p5
        {
            if (i < rng_p4 && j < rng_p5)
            d_t3[t3_based_addr + (i * stride_reg_x) + (j * stride_reg_y)] += reg_tile[i][j];
        }
    }
}

// caller: s1_1
void jk_ccsd_t_s1_1(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, double* host_t3, double* host_t2, double* host_v2)
{
    double *dev_t3;
	double *dev_t2; 
	double *dev_v2; 

    // t3
    // size_t size_t3   = sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;

    // s1_1:   t3[h3,h2,h1,p6,p5,p4] -= t2[p4,h1] * v2[h3,h2,p6,p5]
    size_t size_t2 = sizeof(double) * size_p4 * size_h1;
    size_t size_v2 = sizeof(double) * size_h3 * size_h2 * size_p6 * size_p5;

    // cudaMalloc((void**) &dev_t3, size_t3); 
    // cudaMalloc((void**) &dev_t2, size_t2); 
    // cudaMalloc((void**) &dev_v2, size_v2); 
    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, size_t3, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, size_t2, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, size_v2, cudaMemcpyHostToDevice);

    // 
    size_t num_blks_h3 = CEIL(size_h3, JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    size_t num_blks_h2 = CEIL(size_h2, JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    size_t num_blks_h1 = CEIL(size_h1, JK_CCSD_T_FUSED_S1_SIZE_TILE_H1);
    size_t num_blks_p6 = CEIL(size_p6, JK_CCSD_T_FUSED_S1_SIZE_TILE_P6);
    size_t num_blks_p5 = CEIL(size_p5, JK_CCSD_T_FUSED_S1_SIZE_TILE_P5);
    size_t num_blks_p4 = CEIL(size_p4, JK_CCSD_T_FUSED_S1_SIZE_TILE_P4);

    //
    size_t num_blks_kernel = num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5 * num_blks_p4; 

    //
    dim3 gridsize(num_blks_kernel);
    dim3 blocksize(JK_CCSD_T_FUSED_S1_SIZE_TB_X, JK_CCSD_T_FUSED_S1_SIZE_TB_Y);

    // p4 (x) and p5 (y)
    int stride_reg_x = size_h3 * size_h2 * size_h1 * size_p6 * size_p5;
    int stride_reg_y = size_h3 * size_h2 * size_h1 * size_p6;

    // 
    dev_t3 = t3_s_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    //
    jk_ccsd_t_s1_1<<<gridsize, blocksize>>>(dev_t3, dev_t2, dev_v2, 
                                            size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, 
                                            num_blks_h3, num_blks_h2, num_blks_h1, num_blks_p6, num_blks_p5, num_blks_p4, 
                                            stride_reg_x, stride_reg_y);
#endif
    // cudaMemcpy(host_t3, dev_t3, size_t3, cudaMemcpyDeviceToHost);
    
    // cudaFree(dev_t3);
    // cudaFree(dev_t2);
    // cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: s1_2
__global__ void jk_ccsd_t_s1_2(double* d_t3, 
double* d_t2_2, double* d_v2_2, 
size_t size_h3,     size_t size_h2,     size_t size_h1,     size_t size_p6,     size_t size_p5,     size_t size_p4, 
size_t num_blks_h3, size_t num_blks_h2, size_t num_blks_h1, size_t num_blks_p6, size_t num_blks_p5, size_t num_blks_p4, 
size_t stride_reg_x, size_t stride_reg_y)
{
    //  Shared Memory
    __shared__ double sm_a[16];     // "T_p4" * T_h1
    __shared__ double sm_b[256];    // T_h3 * T_h2 * T_p6 * "T_p5"

    //  offset-indices
    int idx_p6  = threadIdx.x / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int tmp_idx = threadIdx.x % (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int idx_h2  = tmp_idx     / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    int idx_h3  = threadIdx.x % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    int idx_h1  = threadIdx.y;

    //  blk-indices
    int blk_idx_p4  = blockIdx.x / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    tmp_idx         = blockIdx.x % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    int blk_idx_p5  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    int blk_idx_p6  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1);
    int blk_idx_h1  = tmp_idx    / (num_blks_h3 * num_blks_h2);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2);
    int blk_idx_h2  = tmp_idx    / (num_blks_h3);
    int blk_idx_h3  = blockIdx.x % num_blks_h3;

    //  boundary-checks
    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
    // 
    if ((size_h3 - (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H3) 
        rng_h3 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    else
        rng_h3 = size_h3 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;

    //
    if ((size_h2 - (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) 
        rng_h2 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;
    else
        rng_h2 = size_h2 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;

    //
    if ((size_h1 - (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) 
        rng_h1 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;
    else
        rng_h1 = size_h1 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;

    //
    if ((size_p6 - (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) 
        rng_p6 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;
    else
        rng_p6 = size_p6 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;

    //
    if ((size_p5 - (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) 
        rng_p5 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;
    else
        rng_p5 = size_p5 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;

    //
    if ((size_p4 - (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) 
        rng_p4 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;
    else
        rng_p4 = size_p4 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;

    //
    int t3_based_addr =  blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                        (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                        (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h1 + 
                        (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                        (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + 
                        (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    //
    double tmp_av[4];
    double tmp_bv[4];    
    double reg_tile[4][4];

    //
    for (int i = 0; i < 4; i++) // i -> p4
    for (int j = 0; j < 4; j++) // j -> p5
    reg_tile[i][j] = 0.0; 

    //                                        "x1,x2"     "x1,x2,x3,y1"
    //  >> s1_2:   t3[h3,h2,h1,p6,p5,p4] -= t2[p4,h2] * v2[h3,h1,p6,p5] (h3,h2,p6), (h1)
    //
    {
        if (idx_h3 < rng_p4 && idx_h2 < rng_h2 && idx_p6 == 0 && idx_h1 == 0)
        sm_a[idx_h3 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4] = d_t2_2[blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4 + idx_h3 + (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2) * size_p4];

        if (idx_h3 < rng_h3 && idx_h2 < rng_h1 && idx_p6 < rng_p6 && idx_h1 < rng_p5)
        sm_b[idx_h3 + (idx_h2 + (idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3] 
        = d_v2_2[blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h2 + 
                (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + idx_h1) * size_p6) * size_h1) * size_h3];
        __syncthreads();

        //  "p4"
        tmp_av[0] = sm_a[0 + (idx_h2) * 4];
        tmp_av[1] = sm_a[1 + (idx_h2) * 4];
        tmp_av[2] = sm_a[2 + (idx_h2) * 4];
        tmp_av[3] = sm_a[3 + (idx_h2) * 4];

        //  "p5"
        tmp_bv[0] = sm_b[idx_h3 + (idx_h1 + (idx_p6 + (0) * 4) * 4) * 4];
        tmp_bv[1] = sm_b[idx_h3 + (idx_h1 + (idx_p6 + (1) * 4) * 4) * 4];
        tmp_bv[2] = sm_b[idx_h3 + (idx_h1 + (idx_p6 + (2) * 4) * 4) * 4];
        tmp_bv[3] = sm_b[idx_h3 + (idx_h1 + (idx_p6 + (3) * 4) * 4) * 4];

        //  "p4 x p5"
        reg_tile[0][0] -= tmp_av[0] * tmp_bv[0];
        reg_tile[0][1] -= tmp_av[0] * tmp_bv[1];
        reg_tile[0][2] -= tmp_av[0] * tmp_bv[2];
        reg_tile[0][3] -= tmp_av[0] * tmp_bv[3];

        reg_tile[1][0] -= tmp_av[1] * tmp_bv[0];
        reg_tile[1][1] -= tmp_av[1] * tmp_bv[1];
        reg_tile[1][2] -= tmp_av[1] * tmp_bv[2];
        reg_tile[1][3] -= tmp_av[1] * tmp_bv[3];

        reg_tile[2][0] -= tmp_av[2] * tmp_bv[0];
        reg_tile[2][1] -= tmp_av[2] * tmp_bv[1];
        reg_tile[2][2] -= tmp_av[2] * tmp_bv[2];
        reg_tile[2][3] -= tmp_av[2] * tmp_bv[3];

        reg_tile[3][0] -= tmp_av[3] * tmp_bv[0];
        reg_tile[3][1] -= tmp_av[3] * tmp_bv[1];
        reg_tile[3][2] -= tmp_av[3] * tmp_bv[2];
        reg_tile[3][3] -= tmp_av[3] * tmp_bv[3];
    }

    //
    //  to store the output
    //
    if (idx_h1 < rng_h1 && idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6)
    for (int i = 0; i < 4; i++) // p4
    {
        for (int j = 0; j < 4; j++) // p5
        {
            if (i < rng_p4 && j < rng_p5)
            d_t3[t3_based_addr + (i * stride_reg_x) + (j * stride_reg_y)] += reg_tile[i][j];
        }
    }
}
    
// caller:s1_2
void jk_ccsd_t_s1_2(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, double* host_t3, double* host_t2, double* host_v2)
{
    double *dev_t3;
    double *dev_t2; 
    double *dev_v2; 

    // t3
    // size_t size_t3   = sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;

    // s1_2:   t3[h3,h2,h1,p6,p5,p4] -= t2[p4,h2] * v2[h3,h1,p6,p5]
    size_t size_t2 = sizeof(double) * size_p4 * size_h2;
    size_t size_v2 = sizeof(double) * size_h3 * size_h1 * size_p6 * size_p5;
    
    // cudaMalloc((void**) &dev_t3, size_t3); 
    // cudaMalloc((void**) &dev_t2, size_t2); 
    // cudaMalloc((void**) &dev_v2, size_v2); 
    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, size_t3, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, size_t2, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, size_v2, cudaMemcpyHostToDevice);

    // 
    size_t num_blks_h3 = CEIL(size_h3, JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    size_t num_blks_h2 = CEIL(size_h2, JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    size_t num_blks_h1 = CEIL(size_h1, JK_CCSD_T_FUSED_S1_SIZE_TILE_H1);
    size_t num_blks_p6 = CEIL(size_p6, JK_CCSD_T_FUSED_S1_SIZE_TILE_P6);
    size_t num_blks_p5 = CEIL(size_p5, JK_CCSD_T_FUSED_S1_SIZE_TILE_P5);
    size_t num_blks_p4 = CEIL(size_p4, JK_CCSD_T_FUSED_S1_SIZE_TILE_P4);

    //
    size_t num_blks_kernel = num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5 * num_blks_p4; 

    //
    dim3 gridsize(num_blks_kernel);
    dim3 blocksize(JK_CCSD_T_FUSED_S1_SIZE_TB_X, JK_CCSD_T_FUSED_S1_SIZE_TB_Y);

    // p4 (x) and p5 (y)
    int stride_reg_x = size_h3 * size_h2 * size_h1 * size_p6 * size_p5;
    int stride_reg_y = size_h3 * size_h2 * size_h1 * size_p6;

    // 
    dev_t3 = t3_s_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    //
    jk_ccsd_t_s1_2<<<gridsize, blocksize>>>(dev_t3, dev_t2, dev_v2, 
                                            size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, 
                                            num_blks_h3, num_blks_h2, num_blks_h1, num_blks_p6, num_blks_p5, num_blks_p4, 
                                            stride_reg_x, stride_reg_y);

    // cudaMemcpy(host_t3, dev_t3, size_t3, cudaMemcpyDeviceToHost);
#endif  
    // cudaFree(dev_t3);
    // cudaFree(dev_t2);
    // cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}
    
// kernel: s1_3
__global__ void jk_ccsd_t_s1_3(double* d_t3, 
double* d_t2_3, double* d_v2_3,
size_t size_h3,     size_t size_h2,     size_t size_h1,     size_t size_p6,     size_t size_p5,     size_t size_p4, 
size_t num_blks_h3, size_t num_blks_h2, size_t num_blks_h1, size_t num_blks_p6, size_t num_blks_p5, size_t num_blks_p4, 
size_t stride_reg_x, size_t stride_reg_y)
{
    //  Shared Memory
    __shared__ double sm_a[16];     // "T_p4" * T_h1
    __shared__ double sm_b[256];    // T_h3 * T_h2 * T_p6 * "T_p5"

    //  offset-indices
    int idx_p6  = threadIdx.x / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int tmp_idx = threadIdx.x % (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int idx_h2  = tmp_idx     / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    int idx_h3  = threadIdx.x % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    int idx_h1  = threadIdx.y;

    //  blk-indices
    int blk_idx_p4  = blockIdx.x / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    tmp_idx         = blockIdx.x % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    int blk_idx_p5  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    int blk_idx_p6  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1);
    int blk_idx_h1  = tmp_idx    / (num_blks_h3 * num_blks_h2);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2);
    int blk_idx_h2  = tmp_idx    / (num_blks_h3);
    int blk_idx_h3  = blockIdx.x % num_blks_h3;

    //  boundary-checks
    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
    // 
    if ((size_h3 - (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H3) 
        rng_h3 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    else
        rng_h3 = size_h3 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;

    //
    if ((size_h2 - (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) 
        rng_h2 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;
    else
        rng_h2 = size_h2 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;

    //
    if ((size_h1 - (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) 
        rng_h1 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;
    else
        rng_h1 = size_h1 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;

    //
    if ((size_p6 - (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) 
        rng_p6 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;
    else
        rng_p6 = size_p6 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;

    //
    if ((size_p5 - (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) 
        rng_p5 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;
    else
        rng_p5 = size_p5 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;

    //
    if ((size_p4 - (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) 
        rng_p4 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;
    else
        rng_p4 = size_p4 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;

    //
    int t3_based_addr =  blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                        (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                        (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h1 + 
                        (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                        (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + 
                        (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    //
    double tmp_av[4];
    double tmp_bv[4];    
    double reg_tile[4][4];

    //
    for (int i = 0; i < 4; i++) // i -> p4
    for (int j = 0; j < 4; j++) // j -> p5
    reg_tile[i][j] = 0.0; 

    //
    //  >> s1_3:   t3[h3,h2,h1,p6,p5,p4] -= t2[p4,h1] * v2[h3,h2,p6,p5] ??
    //  >> s1_3:   t3[h3,h2,h1,p6,p5,p4] += t1[p4,h3] * v2[h2,h1,p6,p5]
    //
    {
        if (idx_h3 < rng_p4 && idx_h2 < rng_h3 && idx_p6 == 0 && idx_h1 == 0)
        sm_a[idx_h3 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4] = d_t2_3[blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4 + idx_h3 + (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h2) * size_p4];

        if (idx_h3 < rng_h2 && idx_h2 < rng_h1 && idx_p6 < rng_p6 && idx_h1 < rng_p5)
        sm_b[idx_h3 + (idx_h2 + (idx_p6 + (idx_h1) * 4) * 4) * 4] = d_v2_3[blk_idx_h2 * 4 + idx_h3 + (blk_idx_h1 * 4 + idx_h2 + (blk_idx_p6 * 4 + idx_p6 + (blk_idx_p5 * 4 + idx_h1) * size_p6) * size_h1) * size_h2];
        __syncthreads();

        //  "p4"
        tmp_av[0] = sm_a[0 + (idx_h3) * 4];
        tmp_av[1] = sm_a[1 + (idx_h3) * 4];
        tmp_av[2] = sm_a[2 + (idx_h3) * 4];
        tmp_av[3] = sm_a[3 + (idx_h3) * 4];

        //  "p5"
        tmp_bv[0] = sm_b[idx_h2 + (idx_h1 + (idx_p6 + (0) * 4) * 4) * 4];
        tmp_bv[1] = sm_b[idx_h2 + (idx_h1 + (idx_p6 + (1) * 4) * 4) * 4];
        tmp_bv[2] = sm_b[idx_h2 + (idx_h1 + (idx_p6 + (2) * 4) * 4) * 4];
        tmp_bv[3] = sm_b[idx_h2 + (idx_h1 + (idx_p6 + (3) * 4) * 4) * 4];

        //  "p4 x p5"
        reg_tile[0][0] += tmp_av[0] * tmp_bv[0];
        reg_tile[0][1] += tmp_av[0] * tmp_bv[1];
        reg_tile[0][2] += tmp_av[0] * tmp_bv[2];
        reg_tile[0][3] += tmp_av[0] * tmp_bv[3];

        reg_tile[1][0] += tmp_av[1] * tmp_bv[0];
        reg_tile[1][1] += tmp_av[1] * tmp_bv[1];
        reg_tile[1][2] += tmp_av[1] * tmp_bv[2];
        reg_tile[1][3] += tmp_av[1] * tmp_bv[3];

        reg_tile[2][0] += tmp_av[2] * tmp_bv[0];
        reg_tile[2][1] += tmp_av[2] * tmp_bv[1];
        reg_tile[2][2] += tmp_av[2] * tmp_bv[2];
        reg_tile[2][3] += tmp_av[2] * tmp_bv[3];

        reg_tile[3][0] += tmp_av[3] * tmp_bv[0];
        reg_tile[3][1] += tmp_av[3] * tmp_bv[1];
        reg_tile[3][2] += tmp_av[3] * tmp_bv[2];
        reg_tile[3][3] += tmp_av[3] * tmp_bv[3];
    }

    //
    //  to store the output
    //
    if (idx_h1 < rng_h1 && idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6)
    for (int i = 0; i < 4; i++) // p4
    {
        for (int j = 0; j < 4; j++) // p5
        {
            if (i < rng_p4 && j < rng_p5)
            d_t3[t3_based_addr + (i * stride_reg_x) + (j * stride_reg_y)] += reg_tile[i][j];
        }
    }
}

// caller: s1_3
void jk_ccsd_t_s1_3(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, double* host_t3, double* host_t2, double* host_v2)
{
    double *dev_t3;
    double *dev_t2; 
    double *dev_v2; 

    // t3
    // size_t size_t3   = sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;

    // s1_3:   t3[h3,h2,h1,p6,p5,p4] += t1[p4,h3] * v2[h2,h1,p6,p5]
    size_t size_t2 = sizeof(double) * size_p4 * size_h3;
    size_t size_v2 = sizeof(double) * size_h2 * size_h1 * size_p6 * size_p5;
    
    // cudaMalloc((void**) &dev_t3, size_t3); 
    // cudaMalloc((void**) &dev_t2, size_t2); 
    // cudaMalloc((void**) &dev_v2, size_v2); 
    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, size_t3, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, size_t2, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, size_v2, cudaMemcpyHostToDevice);

    // 
    size_t num_blks_h3 = CEIL(size_h3, JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    size_t num_blks_h2 = CEIL(size_h2, JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    size_t num_blks_h1 = CEIL(size_h1, JK_CCSD_T_FUSED_S1_SIZE_TILE_H1);
    size_t num_blks_p6 = CEIL(size_p6, JK_CCSD_T_FUSED_S1_SIZE_TILE_P6);
    size_t num_blks_p5 = CEIL(size_p5, JK_CCSD_T_FUSED_S1_SIZE_TILE_P5);
    size_t num_blks_p4 = CEIL(size_p4, JK_CCSD_T_FUSED_S1_SIZE_TILE_P4);

    //
    size_t num_blks_kernel = num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5 * num_blks_p4; 

    //
    dim3 gridsize(num_blks_kernel);
    dim3 blocksize(JK_CCSD_T_FUSED_S1_SIZE_TB_X, JK_CCSD_T_FUSED_S1_SIZE_TB_Y);

    // p4 (x) and p5 (y)
    int stride_reg_x = size_h3 * size_h2 * size_h1 * size_p6 * size_p5;
    int stride_reg_y = size_h3 * size_h2 * size_h1 * size_p6;

    // 
    dev_t3 = t3_s_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    //
    jk_ccsd_t_s1_3<<<gridsize, blocksize>>>(dev_t3, dev_t2, dev_v2, 
                                            size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, 
                                            num_blks_h3, num_blks_h2, num_blks_h1, num_blks_p6, num_blks_p5, num_blks_p4, 
                                            stride_reg_x, stride_reg_y);

    // cudaMemcpy(host_t3, dev_t3, size_t3, cudaMemcpyDeviceToHost);
#endif
    // cudaFree(dev_t3);
    // cudaFree(dev_t2);
    // cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: s1_4
__global__ void jk_ccsd_t_s1_4(double* d_t3, 
double* d_t2_4, double* d_v2_4, 
size_t size_h3,     size_t size_h2,     size_t size_h1,     size_t size_p6,     size_t size_p5,     size_t size_p4, 
size_t num_blks_h3, size_t num_blks_h2, size_t num_blks_h1, size_t num_blks_p6, size_t num_blks_p5, size_t num_blks_p4, 
size_t stride_reg_x, size_t stride_reg_y)
{
    //  Shared Memory
    __shared__ double sm_a[16];     // "T_p4" * T_h1
    __shared__ double sm_b[256];    // T_h3 * T_h2 * T_p6 * "T_p5"

    //  offset-indices
    int idx_p6  = threadIdx.x / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int tmp_idx = threadIdx.x % (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int idx_h2  = tmp_idx     / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    int idx_h3  = threadIdx.x % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    int idx_h1  = threadIdx.y;

    //  blk-indices
    int blk_idx_p4  = blockIdx.x / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    tmp_idx         = blockIdx.x % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    int blk_idx_p5  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    int blk_idx_p6  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1);
    int blk_idx_h1  = tmp_idx    / (num_blks_h3 * num_blks_h2);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2);
    int blk_idx_h2  = tmp_idx    / (num_blks_h3);
    int blk_idx_h3  = blockIdx.x % num_blks_h3;

    //  boundary-checks
    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
    // 
    if ((size_h3 - (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H3) 
        rng_h3 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    else
        rng_h3 = size_h3 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;

    //
    if ((size_h2 - (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) 
        rng_h2 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;
    else
        rng_h2 = size_h2 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;

    //
    if ((size_h1 - (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) 
        rng_h1 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;
    else
        rng_h1 = size_h1 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;

    //
    if ((size_p6 - (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) 
        rng_p6 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;
    else
        rng_p6 = size_p6 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;

    //
    if ((size_p5 - (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) 
        rng_p5 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;
    else
        rng_p5 = size_p5 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;

    //
    if ((size_p4 - (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) 
        rng_p4 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;
    else
        rng_p4 = size_p4 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;

    //
    int t3_based_addr =  blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                        (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                        (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h1 + 
                        (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                        (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + 
                        (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    //
    double tmp_av[4];
    double tmp_bv[4];    
    double reg_tile[4][4];

    //
    for (int i = 0; i < 4; i++) // i -> p4
    for (int j = 0; j < 4; j++) // j -> p5
    reg_tile[i][j] = 0.0; 

    //
    //  >> s1_4:   t3[h3,h2,h1,p6,p5,p4] -= t2[p5,h1] * v2[h3,h2,p6,p4] (h3,h2,p6), (h1)
    //
    {
        if (idx_h3 < rng_p5 && idx_h2 < rng_h1 && idx_p6 == 0 && idx_h1 == 0)
        sm_a[idx_h3 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5] 
        = d_t2_4[blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + idx_h3 + 
                (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h2) * size_p5];

        if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6 && idx_h1 < rng_p4)
        sm_b[idx_h3 + (idx_h2 + (idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3] 
        = d_v2_4[blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4 + idx_h1) * size_p6) * size_h2) * size_h3];
        __syncthreads();

        //  "p5"
        tmp_av[0] = sm_a[0 + (idx_h1) * 4];
        tmp_av[1] = sm_a[1 + (idx_h1) * 4];
        tmp_av[2] = sm_a[2 + (idx_h1) * 4];
        tmp_av[3] = sm_a[3 + (idx_h1) * 4];

        //  "p4"
        tmp_bv[0] = sm_b[idx_h3 + (idx_h2 + (idx_p6 + (0) * 4) * 4) * 4];
        tmp_bv[1] = sm_b[idx_h3 + (idx_h2 + (idx_p6 + (1) * 4) * 4) * 4];
        tmp_bv[2] = sm_b[idx_h3 + (idx_h2 + (idx_p6 + (2) * 4) * 4) * 4];
        tmp_bv[3] = sm_b[idx_h3 + (idx_h2 + (idx_p6 + (3) * 4) * 4) * 4];

        //  "p4 x p5"
        reg_tile[0][0] -= tmp_av[0] * tmp_bv[0];
        reg_tile[0][1] -= tmp_av[1] * tmp_bv[0];
        reg_tile[0][2] -= tmp_av[2] * tmp_bv[0];
        reg_tile[0][3] -= tmp_av[3] * tmp_bv[0];

        reg_tile[1][0] -= tmp_av[0] * tmp_bv[1];
        reg_tile[1][1] -= tmp_av[1] * tmp_bv[1];
        reg_tile[1][2] -= tmp_av[2] * tmp_bv[1];
        reg_tile[1][3] -= tmp_av[3] * tmp_bv[1];

        reg_tile[2][0] -= tmp_av[0] * tmp_bv[2];
        reg_tile[2][1] -= tmp_av[1] * tmp_bv[2];
        reg_tile[2][2] -= tmp_av[2] * tmp_bv[2];
        reg_tile[2][3] -= tmp_av[3] * tmp_bv[2];

        reg_tile[3][0] -= tmp_av[0] * tmp_bv[3];
        reg_tile[3][1] -= tmp_av[1] * tmp_bv[3];
        reg_tile[3][2] -= tmp_av[2] * tmp_bv[3];
        reg_tile[3][3] -= tmp_av[3] * tmp_bv[3];
    }

    //
    //  to store the output
    //
    if (idx_h1 < rng_h1 && idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6)
    for (int i = 0; i < 4; i++) // p4
    {
        for (int j = 0; j < 4; j++) // p5
        {
            if (i < rng_p4 && j < rng_p5)
            d_t3[t3_based_addr + (i * stride_reg_x) + (j * stride_reg_y)] += reg_tile[i][j];
        }
    }
}

// caller: s1_4
void jk_ccsd_t_s1_4(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, double* host_t3, double* host_t2, double* host_v2)
{
    double *dev_t3;
    double *dev_t2; 
    double *dev_v2; 

    // t3
    // size_t size_t3   = sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;

    // s1_4:   t3[h3,h2,h1,p6,p5,p4] -= t2[p5,h1] * v2[h3,h2,p6,p4]
    size_t size_t2 = sizeof(double) * size_p5 * size_h1;
    size_t size_v2 = sizeof(double) * size_h3 * size_h2 * size_p6 * size_p4;
    
    // cudaMalloc((void**) &dev_t3, size_t3); 
    // cudaMalloc((void**) &dev_t2, size_t2); 
    // cudaMalloc((void**) &dev_v2, size_v2); 
    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, size_t3, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, size_t2, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, size_v2, cudaMemcpyHostToDevice);

    // 
    size_t num_blks_h3 = CEIL(size_h3, JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    size_t num_blks_h2 = CEIL(size_h2, JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    size_t num_blks_h1 = CEIL(size_h1, JK_CCSD_T_FUSED_S1_SIZE_TILE_H1);
    size_t num_blks_p6 = CEIL(size_p6, JK_CCSD_T_FUSED_S1_SIZE_TILE_P6);
    size_t num_blks_p5 = CEIL(size_p5, JK_CCSD_T_FUSED_S1_SIZE_TILE_P5);
    size_t num_blks_p4 = CEIL(size_p4, JK_CCSD_T_FUSED_S1_SIZE_TILE_P4);

    //
    size_t num_blks_kernel = num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5 * num_blks_p4; 

    //
    dim3 gridsize(num_blks_kernel);
    dim3 blocksize(JK_CCSD_T_FUSED_S1_SIZE_TB_X, JK_CCSD_T_FUSED_S1_SIZE_TB_Y);

    // p4 (x) and p5 (y)
    int stride_reg_x = size_h3 * size_h2 * size_h1 * size_p6 * size_p5;
    int stride_reg_y = size_h3 * size_h2 * size_h1 * size_p6;

    // 
    dev_t3 = t3_s_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    //
    jk_ccsd_t_s1_4<<<gridsize, blocksize>>>(dev_t3, dev_t2, dev_v2, 
                                            size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, 
                                            num_blks_h3, num_blks_h2, num_blks_h1, num_blks_p6, num_blks_p5, num_blks_p4, 
                                            stride_reg_x, stride_reg_y);

    // cudaMemcpy(host_t3, dev_t3, size_t3, cudaMemcpyDeviceToHost);
#endif
    // cudaFree(dev_t3);
    // cudaFree(dev_t2);
    // cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: s1_5
__global__ void jk_ccsd_t_s1_5(double* d_t3, 
double* d_t2_5, double* d_v2_5, 
size_t size_h3,     size_t size_h2,     size_t size_h1,     size_t size_p6,     size_t size_p5,     size_t size_p4, 
size_t num_blks_h3, size_t num_blks_h2, size_t num_blks_h1, size_t num_blks_p6, size_t num_blks_p5, size_t num_blks_p4, 
size_t stride_reg_x, size_t stride_reg_y)
{
    //  Shared Memory
    __shared__ double sm_a[16];     // "T_p4" * T_h1
    __shared__ double sm_b[256];    // T_h3 * T_h2 * T_p6 * "T_p5"

    //  offset-indices
    int idx_p6  = threadIdx.x / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int tmp_idx = threadIdx.x % (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int idx_h2  = tmp_idx     / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    int idx_h3  = threadIdx.x % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    int idx_h1  = threadIdx.y;

    //  blk-indices
    int blk_idx_p4  = blockIdx.x / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    tmp_idx         = blockIdx.x % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    int blk_idx_p5  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    int blk_idx_p6  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1);
    int blk_idx_h1  = tmp_idx    / (num_blks_h3 * num_blks_h2);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2);
    int blk_idx_h2  = tmp_idx    / (num_blks_h3);
    int blk_idx_h3  = blockIdx.x % num_blks_h3;

    //  boundary-checks
    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
    // 
    if ((size_h3 - (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H3) 
        rng_h3 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    else
        rng_h3 = size_h3 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;

    //
    if ((size_h2 - (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) 
        rng_h2 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;
    else
        rng_h2 = size_h2 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;

    //
    if ((size_h1 - (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) 
        rng_h1 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;
    else
        rng_h1 = size_h1 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;

    //
    if ((size_p6 - (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) 
        rng_p6 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;
    else
        rng_p6 = size_p6 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;

    //
    if ((size_p5 - (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) 
        rng_p5 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;
    else
        rng_p5 = size_p5 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;

    //
    if ((size_p4 - (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) 
        rng_p4 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;
    else
        rng_p4 = size_p4 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;

    //
    int t3_based_addr =  blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                        (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                        (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h1 + 
                        (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                        (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + 
                        (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    //
    double tmp_av[4];
    double tmp_bv[4];    
    double reg_tile[4][4];

    //
    for (int i = 0; i < 4; i++) // i -> p4
    for (int j = 0; j < 4; j++) // j -> p5
    reg_tile[i][j] = 0.0; 

    //
    //  >> s1_5:   t3[h3,h2,h1,p6,p5,p4] -= t2[p5,h2] * v2[h3,h1,p6,p4] (h3,h2,p6), (h1)
    //
    {
        if (idx_h3 < rng_p5 && idx_h2 < rng_h2 && idx_p6 == 0 && idx_h1 == 0)
        sm_a[idx_h3 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5] 
        = d_t2_5[blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + idx_h3 + 
                (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2) * size_p5];

        if (idx_h3 < rng_h3 && idx_h2 < rng_h1 && idx_p6 < rng_p6 && idx_h1 < rng_p4)
        sm_b[idx_h3 + (idx_h2 + (idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3] 
        = d_v2_5[blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h2 + 
                (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4 + idx_h1) * size_p6) * size_h1) * size_h3];
        __syncthreads();

        //  "p5"
        tmp_av[0] = sm_a[0 + (idx_h2) * 4];
        tmp_av[1] = sm_a[1 + (idx_h2) * 4];
        tmp_av[2] = sm_a[2 + (idx_h2) * 4];
        tmp_av[3] = sm_a[3 + (idx_h2) * 4];

        //  "p4"
        tmp_bv[0] = sm_b[idx_h3 + (idx_h1 + (idx_p6 + (0) * 4) * 4) * 4];
        tmp_bv[1] = sm_b[idx_h3 + (idx_h1 + (idx_p6 + (1) * 4) * 4) * 4];
        tmp_bv[2] = sm_b[idx_h3 + (idx_h1 + (idx_p6 + (2) * 4) * 4) * 4];
        tmp_bv[3] = sm_b[idx_h3 + (idx_h1 + (idx_p6 + (3) * 4) * 4) * 4];

        //  "p4 x p5"
        reg_tile[0][0] += tmp_av[0] * tmp_bv[0];
        reg_tile[0][1] += tmp_av[1] * tmp_bv[0];
        reg_tile[0][2] += tmp_av[2] * tmp_bv[0];
        reg_tile[0][3] += tmp_av[3] * tmp_bv[0];

        reg_tile[1][0] += tmp_av[0] * tmp_bv[1];
        reg_tile[1][1] += tmp_av[1] * tmp_bv[1];
        reg_tile[1][2] += tmp_av[2] * tmp_bv[1];
        reg_tile[1][3] += tmp_av[3] * tmp_bv[1];

        reg_tile[2][0] += tmp_av[0] * tmp_bv[2];
        reg_tile[2][1] += tmp_av[1] * tmp_bv[2];
        reg_tile[2][2] += tmp_av[2] * tmp_bv[2];
        reg_tile[2][3] += tmp_av[3] * tmp_bv[2];

        reg_tile[3][0] += tmp_av[0] * tmp_bv[3];
        reg_tile[3][1] += tmp_av[1] * tmp_bv[3];
        reg_tile[3][2] += tmp_av[2] * tmp_bv[3];
        reg_tile[3][3] += tmp_av[3] * tmp_bv[3];
    }

    //
    //  to store the output
    //
    if (idx_h1 < rng_h1 && idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6)
    for (int i = 0; i < 4; i++) // p4
    {
        for (int j = 0; j < 4; j++) // p5
        {
            if (i < rng_p4 && j < rng_p5)
            d_t3[t3_based_addr + (i * stride_reg_x) + (j * stride_reg_y)] += reg_tile[i][j];
        }
    }
}

// caller: s1_5
void jk_ccsd_t_s1_5(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, double* host_t3, double* host_t2, double* host_v2)
{
    double *dev_t3;
    double *dev_t2; 
    double *dev_v2; 

    // t3
    // size_t size_t3   = sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;

    // s1_5:   t3[h3,h2,h1,p6,p5,p4] -= t2[p5,h2] * v2[h3,h1,p6,p4]
    size_t size_t2 = sizeof(double) * size_p5 * size_h2;
    size_t size_v2 = sizeof(double) * size_h3 * size_h1 * size_p6 * size_p4;
    
    // cudaMalloc((void**) &dev_t3, size_t3); 
    // cudaMalloc((void**) &dev_t2, size_t2); 
    // cudaMalloc((void**) &dev_v2, size_v2); 
    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, size_t3, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, size_t2, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, size_v2, cudaMemcpyHostToDevice);

    // 
    size_t num_blks_h3 = CEIL(size_h3, JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    size_t num_blks_h2 = CEIL(size_h2, JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    size_t num_blks_h1 = CEIL(size_h1, JK_CCSD_T_FUSED_S1_SIZE_TILE_H1);
    size_t num_blks_p6 = CEIL(size_p6, JK_CCSD_T_FUSED_S1_SIZE_TILE_P6);
    size_t num_blks_p5 = CEIL(size_p5, JK_CCSD_T_FUSED_S1_SIZE_TILE_P5);
    size_t num_blks_p4 = CEIL(size_p4, JK_CCSD_T_FUSED_S1_SIZE_TILE_P4);

    //
    size_t num_blks_kernel = num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5 * num_blks_p4; 

    //
    dim3 gridsize(num_blks_kernel);
    dim3 blocksize(JK_CCSD_T_FUSED_S1_SIZE_TB_X, JK_CCSD_T_FUSED_S1_SIZE_TB_Y);

    // p4 (x) and p5 (y)
    int stride_reg_x = size_h3 * size_h2 * size_h1 * size_p6 * size_p5;
    int stride_reg_y = size_h3 * size_h2 * size_h1 * size_p6;

    // 
    dev_t3 = t3_s_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    //
    jk_ccsd_t_s1_5<<<gridsize, blocksize>>>(dev_t3, dev_t2, dev_v2, 
                                            size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, 
                                            num_blks_h3, num_blks_h2, num_blks_h1, num_blks_p6, num_blks_p5, num_blks_p4, 
                                            stride_reg_x, stride_reg_y);

    // cudaMemcpy(host_t3, dev_t3, size_t3, cudaMemcpyDeviceToHost);
#endif
    // cudaFree(dev_t3);
    // cudaFree(dev_t2);
    // cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: s1_6
__global__ void jk_ccsd_t_s1_6(double* d_t3, 
double* d_t2_6, double* d_v2_6,
size_t size_h3,     size_t size_h2,     size_t size_h1,     size_t size_p6,     size_t size_p5,     size_t size_p4, 
size_t num_blks_h3, size_t num_blks_h2, size_t num_blks_h1, size_t num_blks_p6, size_t num_blks_p5, size_t num_blks_p4, 
size_t stride_reg_x, size_t stride_reg_y)
{
    //  Shared Memory
    __shared__ double sm_a[16];     // "T_p4" * T_h1
    __shared__ double sm_b[256];    // T_h3 * T_h2 * T_p6 * "T_p5"

    //  offset-indices
    int idx_p6  = threadIdx.x / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int tmp_idx = threadIdx.x % (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int idx_h2  = tmp_idx     / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    int idx_h3  = threadIdx.x % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    int idx_h1  = threadIdx.y;

    //  blk-indices
    int blk_idx_p4  = blockIdx.x / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    tmp_idx         = blockIdx.x % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    int blk_idx_p5  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    int blk_idx_p6  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1);
    int blk_idx_h1  = tmp_idx    / (num_blks_h3 * num_blks_h2);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2);
    int blk_idx_h2  = tmp_idx    / (num_blks_h3);
    int blk_idx_h3  = blockIdx.x % num_blks_h3;

    //  boundary-checks
    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
    // 
    if ((size_h3 - (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H3) 
        rng_h3 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    else
        rng_h3 = size_h3 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;

    //
    if ((size_h2 - (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) 
        rng_h2 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;
    else
        rng_h2 = size_h2 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;

    //
    if ((size_h1 - (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) 
        rng_h1 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;
    else
        rng_h1 = size_h1 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;

    //
    if ((size_p6 - (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) 
        rng_p6 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;
    else
        rng_p6 = size_p6 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;

    //
    if ((size_p5 - (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) 
        rng_p5 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;
    else
        rng_p5 = size_p5 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;

    //
    if ((size_p4 - (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) 
        rng_p4 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;
    else
        rng_p4 = size_p4 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;

    //
    int t3_based_addr =  blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                        (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                        (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h1 + 
                        (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                        (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + 
                        (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    //
    double tmp_av[4];
    double tmp_bv[4];    
    double reg_tile[4][4];

    //
    for (int i = 0; i < 4; i++) // i -> p4
    for (int j = 0; j < 4; j++) // j -> p5
    reg_tile[i][j] = 0.0; 

    //
    //  >> s1_6:   t3[h3,h2,h1,p6,p5,p4] -= t2[p5,h3] * v2[h2,h1,p6,p4] (h3,h2,p6), (h1)
    //
    {
        if (idx_h3 < rng_p5 && idx_h2 < rng_h3 && idx_p6 == 0 && idx_h1 == 0)
        sm_a[idx_h3 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5] 
        = d_t2_6[blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + idx_h3 + 
                (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h2) * size_p5];

        if (idx_h3 < rng_h2 && idx_h2 < rng_h1 && idx_p6 < rng_p6 && idx_h1 < rng_p4)
        sm_b[idx_h3 + (idx_h2 + (idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2] 
        = d_v2_6[blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h3 + 
                (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h2 + 
                (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4 + idx_h1) * size_p6) * size_h1) * size_h2];
        __syncthreads();

        //  "p5"
        tmp_av[0] = sm_a[0 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5];
        tmp_av[1] = sm_a[1 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5];
        tmp_av[2] = sm_a[2 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5];
        tmp_av[3] = sm_a[3 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5];

        //  "p4"
        tmp_bv[0] = sm_b[idx_h2 + (idx_h1 + (idx_p6 + (0) * 4) * 4) * 4];
        tmp_bv[1] = sm_b[idx_h2 + (idx_h1 + (idx_p6 + (1) * 4) * 4) * 4];
        tmp_bv[2] = sm_b[idx_h2 + (idx_h1 + (idx_p6 + (2) * 4) * 4) * 4];
        tmp_bv[3] = sm_b[idx_h2 + (idx_h1 + (idx_p6 + (3) * 4) * 4) * 4];

        //  "p4 x p5"
        reg_tile[0][0] -= tmp_av[0] * tmp_bv[0];
        reg_tile[0][1] -= tmp_av[1] * tmp_bv[0];
        reg_tile[0][2] -= tmp_av[2] * tmp_bv[0];
        reg_tile[0][3] -= tmp_av[3] * tmp_bv[0];

        reg_tile[1][0] -= tmp_av[0] * tmp_bv[1];
        reg_tile[1][1] -= tmp_av[1] * tmp_bv[1];
        reg_tile[1][2] -= tmp_av[2] * tmp_bv[1];
        reg_tile[1][3] -= tmp_av[3] * tmp_bv[1];

        reg_tile[2][0] -= tmp_av[0] * tmp_bv[2];
        reg_tile[2][1] -= tmp_av[1] * tmp_bv[2];
        reg_tile[2][2] -= tmp_av[2] * tmp_bv[2];
        reg_tile[2][3] -= tmp_av[3] * tmp_bv[2];

        reg_tile[3][0] -= tmp_av[0] * tmp_bv[3];
        reg_tile[3][1] -= tmp_av[1] * tmp_bv[3];
        reg_tile[3][2] -= tmp_av[2] * tmp_bv[3];
        reg_tile[3][3] -= tmp_av[3] * tmp_bv[3];
    }

    //
    //  to store the output
    //
    if (idx_h1 < rng_h1 && idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6)
    for (int i = 0; i < 4; i++) // p4
    {
        for (int j = 0; j < 4; j++) // p5
        {
            if (i < rng_p4 && j < rng_p5)
            d_t3[t3_based_addr + (i * stride_reg_x) + (j * stride_reg_y)] += reg_tile[i][j];
        }
    }
}

// caller: s1_6
void jk_ccsd_t_s1_6(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, double* host_t3, double* host_t2, double* host_v2)
{
    double *dev_t3;
    double *dev_t2; 
    double *dev_v2; 

    // t3
    // size_t size_t3   = sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;

    // s1_6:   t3[h3,h2,h1,p6,p5,p4] -= t2[p5,h3] * v2[h2,h1,p6,p4]
    size_t size_t2 = sizeof(double) * size_p5 * size_h3;
    size_t size_v2 = sizeof(double) * size_h2 * size_h1 * size_p6 * size_p4;
    
    // cudaMalloc((void**) &dev_t3, size_t3); 
    // cudaMalloc((void**) &dev_t2, size_t2); 
    // cudaMalloc((void**) &dev_v2, size_v2); 
    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, size_t3, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, size_t2, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, size_v2, cudaMemcpyHostToDevice);

    // 
    size_t num_blks_h3 = CEIL(size_h3, JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    size_t num_blks_h2 = CEIL(size_h2, JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    size_t num_blks_h1 = CEIL(size_h1, JK_CCSD_T_FUSED_S1_SIZE_TILE_H1);
    size_t num_blks_p6 = CEIL(size_p6, JK_CCSD_T_FUSED_S1_SIZE_TILE_P6);
    size_t num_blks_p5 = CEIL(size_p5, JK_CCSD_T_FUSED_S1_SIZE_TILE_P5);
    size_t num_blks_p4 = CEIL(size_p4, JK_CCSD_T_FUSED_S1_SIZE_TILE_P4);

    //
    size_t num_blks_kernel = num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5 * num_blks_p4; 

    //
    dim3 gridsize(num_blks_kernel);
    dim3 blocksize(JK_CCSD_T_FUSED_S1_SIZE_TB_X, JK_CCSD_T_FUSED_S1_SIZE_TB_Y);

    // p4 (x) and p5 (y)
    int stride_reg_x = size_h3 * size_h2 * size_h1 * size_p6 * size_p5;
    int stride_reg_y = size_h3 * size_h2 * size_h1 * size_p6;

    // 
    dev_t3 = t3_s_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    //
    jk_ccsd_t_s1_6<<<gridsize, blocksize>>>(dev_t3, dev_t2, dev_v2, 
                                            size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, 
                                            num_blks_h3, num_blks_h2, num_blks_h1, num_blks_p6, num_blks_p5, num_blks_p4, 
                                            stride_reg_x, stride_reg_y);

    // cudaMemcpy(host_t3, dev_t3, size_t3, cudaMemcpyDeviceToHost);
#endif
    // cudaFree(dev_t3);
    // cudaFree(dev_t2);
    // cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: s1_7
__global__ void jk_ccsd_t_s1_7(double* d_t3, 
double* d_t2_7, double* d_v2_7, 
size_t size_h3,     size_t size_h2,     size_t size_h1,     size_t size_p6,     size_t size_p5,     size_t size_p4, 
size_t num_blks_h3, size_t num_blks_h2, size_t num_blks_h1, size_t num_blks_p6, size_t num_blks_p5, size_t num_blks_p4, 
size_t stride_reg_x, size_t stride_reg_y)
{
    //  Shared Memory
    __shared__ double sm_a[16];     // "T_p4" * T_h1
    __shared__ double sm_b[256];    // T_h3 * T_h2 * T_p6 * "T_p5"

    //  offset-indices
    int idx_p6  = threadIdx.x / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int tmp_idx = threadIdx.x % (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int idx_h2  = tmp_idx     / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    int idx_h3  = threadIdx.x % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    int idx_h1  = threadIdx.y;

    //  blk-indices
    int blk_idx_p4  = blockIdx.x / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    tmp_idx         = blockIdx.x % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    int blk_idx_p5  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    int blk_idx_p6  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1);
    int blk_idx_h1  = tmp_idx    / (num_blks_h3 * num_blks_h2);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2);
    int blk_idx_h2  = tmp_idx    / (num_blks_h3);
    int blk_idx_h3  = blockIdx.x % num_blks_h3;

    //  boundary-checks
    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
    // 
    if ((size_h3 - (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H3) 
        rng_h3 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    else
        rng_h3 = size_h3 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;

    //
    if ((size_h2 - (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) 
        rng_h2 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;
    else
        rng_h2 = size_h2 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;

    //
    if ((size_h1 - (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) 
        rng_h1 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;
    else
        rng_h1 = size_h1 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;

    //
    if ((size_p6 - (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) 
        rng_p6 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;
    else
        rng_p6 = size_p6 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;

    //
    if ((size_p5 - (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) 
        rng_p5 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;
    else
        rng_p5 = size_p5 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;

    //
    if ((size_p4 - (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) 
        rng_p4 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;
    else
        rng_p4 = size_p4 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;

    //
    int t3_based_addr =  blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                        (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                        (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h1 + 
                        (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                        (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + 
                        (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    //
    // double tmp_av[4];
    // double tmp_bv[4];    
    double reg_tile[4][4];

    //
    for (int i = 0; i < 4; i++) // i -> p4
    for (int j = 0; j < 4; j++) // j -> p5
    reg_tile[i][j] = 0.0; 

    //
    //  >> s1_7:   t3[h3,h2,h1,p6,p5,p4] -= t2[p6,h1] * v2[h3,h2,p5,p4] (h3,h2,p6), (h1)
    //
    {
        if (idx_h3 < rng_p6 && idx_h2 < rng_h1 && idx_p6 == 0 && idx_h1 == 0)
        sm_a[idx_h3 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] 
        = d_t2_7[blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_h3 + 
                (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h2) * size_p6];

        if (idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p5 && idx_h1 < rng_p4)
        sm_b[idx_h3 + (idx_h2 + (idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3] 
        = d_v2_7[blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + idx_p6 + 
                (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4 + idx_h1) * size_p5) * size_h2) * size_h3];
        __syncthreads();

        //  "p4" x "p5"
        reg_tile[0][0] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (0 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[0][1] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (1 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[0][2] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (2 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[0][3] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (3 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];

        reg_tile[1][0] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (0 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[1][1] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (1 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[1][2] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (2 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[1][3] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (3 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];

        reg_tile[2][0] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (0 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[2][1] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (1 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[2][2] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (2 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[2][3] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (3 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];

        reg_tile[3][0] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (0 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[3][1] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (1 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[3][2] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (2 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[3][3] += sm_a[idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h2 + (3 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        
    }

    //
    //  to store the output
    //
    if (idx_h1 < rng_h1 && idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6)
    for (int i = 0; i < 4; i++) // p4
    {
        for (int j = 0; j < 4; j++) // p5
        {
            if (i < rng_p4 && j < rng_p5)
            d_t3[t3_based_addr + (i * stride_reg_x) + (j * stride_reg_y)] += reg_tile[i][j];
        }
    }
}

// caller: s1_7
void jk_ccsd_t_s1_7(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, double* host_t3, double* host_t2, double* host_v2)
{
    double *dev_t3;
    double *dev_t2; 
    double *dev_v2; 

    // t3
    // size_t size_t3   = sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;

    // s1_7:   t3[h3,h2,h1,p6,p5,p4] -= t2[p6,h1] * v2[h3,h2,p5,p4]
    size_t size_t2 = sizeof(double) * size_p6 * size_h1;
    size_t size_v2 = sizeof(double) * size_h3 * size_h2 * size_p5 * size_p4;
    
    // cudaMalloc((void**) &dev_t3, size_t3); 
    // cudaMalloc((void**) &dev_t2, size_t2); 
    // cudaMalloc((void**) &dev_v2, size_v2); 
    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, size_t3, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, size_t2, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, size_v2, cudaMemcpyHostToDevice);

    // 
    size_t num_blks_h3 = CEIL(size_h3, JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    size_t num_blks_h2 = CEIL(size_h2, JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    size_t num_blks_h1 = CEIL(size_h1, JK_CCSD_T_FUSED_S1_SIZE_TILE_H1);
    size_t num_blks_p6 = CEIL(size_p6, JK_CCSD_T_FUSED_S1_SIZE_TILE_P6);
    size_t num_blks_p5 = CEIL(size_p5, JK_CCSD_T_FUSED_S1_SIZE_TILE_P5);
    size_t num_blks_p4 = CEIL(size_p4, JK_CCSD_T_FUSED_S1_SIZE_TILE_P4);

    //
    size_t num_blks_kernel = num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5 * num_blks_p4; 

    //
    dim3 gridsize(num_blks_kernel);
    dim3 blocksize(JK_CCSD_T_FUSED_S1_SIZE_TB_X, JK_CCSD_T_FUSED_S1_SIZE_TB_Y);

    // p4 (x) and p5 (y)
    int stride_reg_x = size_h3 * size_h2 * size_h1 * size_p6 * size_p5;
    int stride_reg_y = size_h3 * size_h2 * size_h1 * size_p6;

    // 
    dev_t3 = t3_s_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    //
    jk_ccsd_t_s1_7<<<gridsize, blocksize>>>(dev_t3, dev_t2, dev_v2, 
                                            size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, 
                                            num_blks_h3, num_blks_h2, num_blks_h1, num_blks_p6, num_blks_p5, num_blks_p4, 
                                            stride_reg_x, stride_reg_y);

    // cudaMemcpy(host_t3, dev_t3, size_t3, cudaMemcpyDeviceToHost);
#endif
    // cudaFree(dev_t3);
    // cudaFree(dev_t2);
    // cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: s1_8
__global__ void jk_ccsd_t_s1_8(double* d_t3, 
double* d_t2_8, double* d_v2_8, 
size_t size_h3,     size_t size_h2,     size_t size_h1,     size_t size_p6,     size_t size_p5,     size_t size_p4, 
size_t num_blks_h3, size_t num_blks_h2, size_t num_blks_h1, size_t num_blks_p6, size_t num_blks_p5, size_t num_blks_p4, 
size_t stride_reg_x, size_t stride_reg_y)
{
    //  Shared Memory
    __shared__ double sm_a[16];     // "T_p4" * T_h1
    __shared__ double sm_b[256];    // T_h3 * T_h2 * T_p6 * "T_p5"

    //  offset-indices
    int idx_p6  = threadIdx.x / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int tmp_idx = threadIdx.x % (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int idx_h2  = tmp_idx     / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    int idx_h3  = threadIdx.x % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    int idx_h1  = threadIdx.y;

    //  blk-indices
    int blk_idx_p4  = blockIdx.x / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    tmp_idx         = blockIdx.x % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    int blk_idx_p5  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    int blk_idx_p6  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1);
    int blk_idx_h1  = tmp_idx    / (num_blks_h3 * num_blks_h2);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2);
    int blk_idx_h2  = tmp_idx    / (num_blks_h3);
    int blk_idx_h3  = blockIdx.x % num_blks_h3;

    //  boundary-checks
    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
    // 
    if ((size_h3 - (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H3) 
        rng_h3 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    else
        rng_h3 = size_h3 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;

    //
    if ((size_h2 - (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) 
        rng_h2 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;
    else
        rng_h2 = size_h2 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;

    //
    if ((size_h1 - (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) 
        rng_h1 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;
    else
        rng_h1 = size_h1 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;

    //
    if ((size_p6 - (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) 
        rng_p6 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;
    else
        rng_p6 = size_p6 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;

    //
    if ((size_p5 - (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) 
        rng_p5 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;
    else
        rng_p5 = size_p5 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;

    //
    if ((size_p4 - (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) 
        rng_p4 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;
    else
        rng_p4 = size_p4 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;

    //
    int t3_based_addr =  blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                        (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                        (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h1 + 
                        (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                        (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + 
                        (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    //
    // double tmp_av[4];
    // double tmp_bv[4];    
    double reg_tile[4][4];

    //
    for (int i = 0; i < 4; i++) // i -> p4
    for (int j = 0; j < 4; j++) // j -> p5
    reg_tile[i][j] = 0.0; 

    //
    //  >> s1_8:   t3[h3,h2,h1,p6,p5,p4] -= t2[p6,h2] * v2[h3,h1,p5,p4] (h3,h2,p6), (h1)
    //
    {
        if (idx_h3 < rng_p6 && idx_h2 < rng_h2 && idx_p6 == 0 && idx_h1 == 0)
        sm_a[idx_h3 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] 
        = d_t2_8[blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_h3 + 
                (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2) * size_p6];
                
        if (idx_h3 < rng_h3 && idx_h2 < rng_h1 && idx_p6 < rng_p5 && idx_h1 < rng_p4)
        sm_b[idx_h3 + (idx_h2 + (idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3] 
        = d_v2_8[blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h2 + 
                (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + idx_p6 + 
                (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4 + idx_h1) * size_p5) * size_h1) * size_h3];
        __syncthreads();

        //  "p4" x "p5"
        reg_tile[0][0] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (0 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[0][1] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (1 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[0][2] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (2 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[0][3] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (3 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];

        reg_tile[1][0] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (0 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[1][1] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (1 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[1][2] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (2 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[1][3] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (3 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];

        reg_tile[2][0] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (0 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[2][1] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (1 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[2][2] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (2 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[2][3] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (3 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];

        reg_tile[3][0] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (0 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[3][1] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (1 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[3][2] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (2 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
        reg_tile[3][3] -= sm_a[idx_p6 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h3 + (idx_h1 + (3 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3];
    }

    //
    //  to store the output
    //
    if (idx_h1 < rng_h1 && idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6)
    for (int i = 0; i < 4; i++) // p4
    {
        for (int j = 0; j < 4; j++) // p5
        {
            if (i < rng_p4 && j < rng_p5)
            d_t3[t3_based_addr + (i * stride_reg_x) + (j * stride_reg_y)] += reg_tile[i][j];
        }
    }
}

// caller: s1_8
void jk_ccsd_t_s1_8(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, double* host_t3, double* host_t2, double* host_v2)
{
    double *dev_t3;
    double *dev_t2; 
    double *dev_v2; 

    // t3
    // size_t size_t3   = sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;

    // s1_8:   t3[h3,h2,h1,p6,p5,p4] -= t2[p6,h2] * v2[h3,h1,p5,p4]
    size_t size_t2 = sizeof(double) * size_p6 * size_h2;
    size_t size_v2 = sizeof(double) * size_h3 * size_h1 * size_p5 * size_p4;
    
    // cudaMalloc((void**) &dev_t3, size_t3); 
    // cudaMalloc((void**) &dev_t2, size_t2); 
    // cudaMalloc((void**) &dev_v2, size_v2); 
    dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
    // cudaMemcpy(dev_t3, host_t3, size_t3, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_t2, host_t2, size_t2, cudaMemcpyHostToDevice);
    cudaMemcpy(dev_v2, host_v2, size_v2, cudaMemcpyHostToDevice);

    // 
    size_t num_blks_h3 = CEIL(size_h3, JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    size_t num_blks_h2 = CEIL(size_h2, JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    size_t num_blks_h1 = CEIL(size_h1, JK_CCSD_T_FUSED_S1_SIZE_TILE_H1);
    size_t num_blks_p6 = CEIL(size_p6, JK_CCSD_T_FUSED_S1_SIZE_TILE_P6);
    size_t num_blks_p5 = CEIL(size_p5, JK_CCSD_T_FUSED_S1_SIZE_TILE_P5);
    size_t num_blks_p4 = CEIL(size_p4, JK_CCSD_T_FUSED_S1_SIZE_TILE_P4);

    //
    size_t num_blks_kernel = num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5 * num_blks_p4; 

    //
    dim3 gridsize(num_blks_kernel);
    dim3 blocksize(JK_CCSD_T_FUSED_S1_SIZE_TB_X, JK_CCSD_T_FUSED_S1_SIZE_TB_Y);

    // p4 (x) and p5 (y)
    int stride_reg_x = size_h3 * size_h2 * size_h1 * size_p6 * size_p5;
    int stride_reg_y = size_h3 * size_h2 * size_h1 * size_p6;

    // 
    dev_t3 = t3_s_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
    //
    jk_ccsd_t_s1_8<<<gridsize, blocksize>>>(dev_t3, dev_t2, dev_v2, 
                                            size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, 
                                            num_blks_h3, num_blks_h2, num_blks_h1, num_blks_p6, num_blks_p5, num_blks_p4, 
                                            stride_reg_x, stride_reg_y);

    // cudaMemcpy(host_t3, dev_t3, size_t3, cudaMemcpyDeviceToHost);
#endif
    // cudaFree(dev_t3);
    // cudaFree(dev_t2);
    // cudaFree(dev_v2);
    freeGpuMem(dev_t2);
	freeGpuMem(dev_v2);
}

// kernel: s1_9
__global__ void jk_ccsd_t_s1_9(double* d_t3, 
double* d_t2_9, double* d_v2_9,
size_t size_h3,     size_t size_h2,     size_t size_h1,     size_t size_p6,     size_t size_p5,     size_t size_p4, 
size_t num_blks_h3, size_t num_blks_h2, size_t num_blks_h1, size_t num_blks_p6, size_t num_blks_p5, size_t num_blks_p4, 
size_t stride_reg_x, size_t stride_reg_y)
{
    //  Shared Memory
    __shared__ double sm_a[16];     // "T_p4" * T_h1
    __shared__ double sm_b[256];    // T_h3 * T_h2 * T_p6 * "T_p5"

    //  offset-indices
    int idx_p6  = threadIdx.x / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int tmp_idx = threadIdx.x % (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
    int idx_h2  = tmp_idx     / (JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
    int idx_h3  = threadIdx.x % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    int idx_h1  = threadIdx.y;

    //  blk-indices
    int blk_idx_p4  = blockIdx.x / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    tmp_idx         = blockIdx.x % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5);
    int blk_idx_p5  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6);
    int blk_idx_p6  = tmp_idx    / (num_blks_h3 * num_blks_h2 * num_blks_h1);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2 * num_blks_h1);
    int blk_idx_h1  = tmp_idx    / (num_blks_h3 * num_blks_h2);
    tmp_idx         = tmp_idx    % (num_blks_h3 * num_blks_h2);
    int blk_idx_h2  = tmp_idx    / (num_blks_h3);
    int blk_idx_h3  = blockIdx.x % num_blks_h3;

    //  boundary-checks
    int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
    // 
    if ((size_h3 - (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H3) 
        rng_h3 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;
    else
        rng_h3 = size_h3 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H3;

    //
    if ((size_h2 - (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H2) 
        rng_h2 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;
    else
        rng_h2 = size_h2 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H2;

    //
    if ((size_h1 - (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) 
        rng_h1 = JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;
    else
        rng_h1 = size_h1 % JK_CCSD_T_FUSED_S1_SIZE_TILE_H1;

    //
    if ((size_p6 - (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P6) 
        rng_p6 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;
    else
        rng_p6 = size_p6 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P6;

    //
    if ((size_p5 - (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) 
        rng_p5 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;
    else
        rng_p5 = size_p5 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P5;

    //
    if ((size_p4 - (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4)) >= JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) 
        rng_p4 = JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;
    else
        rng_p4 = size_p4 % JK_CCSD_T_FUSED_S1_SIZE_TILE_P4;

    //
    int t3_based_addr =  blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h3 + 
                        (blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h2 + 
                        (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h1 + 
                        (blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_p6 + 
                        (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + 
                        (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

    //
    // double tmp_av[4];
    // double tmp_bv[4];    
    double reg_tile[4][4];

    //
    for (int i = 0; i < 4; i++) // i -> p4
    for (int j = 0; j < 4; j++) // j -> p5
    reg_tile[i][j] = 0.0; 

    //
    //  >> s1_9:   t3[h3,h2,h1,p6,p5,p4] -= t2[p6,h3] * v2[h2,h1,p5,p4] (h3,h2,p6), (h1)
    //
    {
        if (idx_h3 < rng_p6 && idx_h2 < rng_h3 && idx_p6 == 0 && idx_h1 == 0)
        sm_a[idx_h3 + (idx_h2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] 
        = d_t2_9[blk_idx_p6 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6 + idx_h3 + 
                (blk_idx_h3 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H3 + idx_h2) * size_p6];

        if (idx_h3 < rng_h2 && idx_h2 < rng_h1 && idx_p6 < rng_p5 && idx_h1 < rng_p4)
        sm_b[idx_h3 + (idx_h2 + (idx_p6 + (idx_h1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2] 
        = d_v2_9[blk_idx_h2 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2 + idx_h3 + 
                (blk_idx_h1 * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1 + idx_h2 + 
                (blk_idx_p5 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5 + idx_p6 + 
                (blk_idx_p4 * JK_CCSD_T_FUSED_S1_SIZE_TILE_P4 + idx_h1) * size_p5) * size_h1) * size_h2];
        __syncthreads();

        //  "p4" x "p5"
        reg_tile[0][0] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (0 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[0][1] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (1 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[0][2] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (2 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[0][3] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (3 + (0) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];

        reg_tile[1][0] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (0 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[1][1] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (1 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[1][2] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (2 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[1][3] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (3 + (1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];

        reg_tile[2][0] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (0 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[2][1] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (1 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[2][2] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (2 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[2][3] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (3 + (2) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];

        reg_tile[3][0] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (0 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[3][1] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (1 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[3][2] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (2 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
        reg_tile[3][3] += sm_a[idx_p6 + (idx_h3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P6] * sm_b[idx_h2 + (idx_h1 + (3 + (3) * JK_CCSD_T_FUSED_S1_SIZE_TILE_P5) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H1) * JK_CCSD_T_FUSED_S1_SIZE_TILE_H2];
    }

    //
    //  to store the output
    //
    if (idx_h1 < rng_h1 && idx_h3 < rng_h3 && idx_h2 < rng_h2 && idx_p6 < rng_p6)
    for (int i = 0; i < 4; i++) // p4
    {
        for (int j = 0; j < 4; j++) // p5
        {
            if (i < rng_p4 && j < rng_p5)
            d_t3[t3_based_addr + (i * stride_reg_x) + (j * stride_reg_y)] += reg_tile[i][j];
        }
    }
}

// caller: s1_9
void jk_ccsd_t_s1_9(size_t size_h3, size_t size_h2, size_t size_h1, size_t size_p6, size_t size_p5, size_t size_p4, double* host_t3, double* host_t2, double* host_v2)
{
  double *dev_t3;
  double *dev_t2; 
  double *dev_v2; 

  // t3
  // size_t size_t3   = sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;

  // s1_9:   t3[h3,h2,h1,p6,p5,p4] -= t2[p6,h3] * v2[h2,h1,p5,p4]
  size_t size_t2 = sizeof(double) * size_p6 * size_h3;
  size_t size_v2 = sizeof(double) * size_h2 * size_h1 * size_p5 * size_p4;

  // cudaMalloc((void**) &dev_t3, size_t3); 
  // cudaMalloc((void**) &dev_t2, size_t2); 
  // cudaMalloc((void**) &dev_v2, size_v2); 
  dev_t2 = (double *) getGpuMem(size_t2);
	dev_v2 = (double *) getGpuMem(size_v2);
    
  // cudaMemcpy(dev_t3, host_t3, size_t3, cudaMemcpyHostToDevice);
  cudaMemcpy(dev_t2, host_t2, size_t2, cudaMemcpyHostToDevice);
  cudaMemcpy(dev_v2, host_v2, size_v2, cudaMemcpyHostToDevice);

  // 
  size_t num_blks_h3 = CEIL(size_h3, JK_CCSD_T_FUSED_S1_SIZE_TILE_H3);
  size_t num_blks_h2 = CEIL(size_h2, JK_CCSD_T_FUSED_S1_SIZE_TILE_H2);
  size_t num_blks_h1 = CEIL(size_h1, JK_CCSD_T_FUSED_S1_SIZE_TILE_H1);
  size_t num_blks_p6 = CEIL(size_p6, JK_CCSD_T_FUSED_S1_SIZE_TILE_P6);
  size_t num_blks_p5 = CEIL(size_p5, JK_CCSD_T_FUSED_S1_SIZE_TILE_P5);
  size_t num_blks_p4 = CEIL(size_p4, JK_CCSD_T_FUSED_S1_SIZE_TILE_P4);

  //
  size_t num_blks_kernel = num_blks_h3 * num_blks_h2 * num_blks_h1 * num_blks_p6 * num_blks_p5 * num_blks_p4; 

  //
  dim3 gridsize(num_blks_kernel);
  dim3 blocksize(JK_CCSD_T_FUSED_S1_SIZE_TB_X, JK_CCSD_T_FUSED_S1_SIZE_TB_Y);

  // p4 (x) and p5 (y)
  int stride_reg_x = size_h3 * size_h2 * size_h1 * size_p6 * size_p5;
  int stride_reg_y = size_h3 * size_h2 * size_h1 * size_p6;

  // 
  dev_t3 = t3_s_d;
#ifdef DEBUG_ENALBLE_ALL_KERNEL
  //
  jk_ccsd_t_s1_9<<<gridsize, blocksize>>>(dev_t3, dev_t2, dev_v2, 
                                          size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, 
                                          num_blks_h3, num_blks_h2, num_blks_h1, num_blks_p6, num_blks_p5, num_blks_p4, 
                                          stride_reg_x, stride_reg_y);

  // cudaMemcpy(host_t3, dev_t3, size_t3, cudaMemcpyDeviceToHost);
#endif
  // cudaFree(dev_t3);
  // cudaFree(dev_t2);
  // cudaFree(dev_v2);
  freeGpuMem(dev_t2);
  freeGpuMem(dev_v2);
}

// A100 and cuda 11.1 
#if 1

#include <cooperative_groups/memcpy_async.h>
#include <cuda/pipeline> // cuda >= 11.1

#define CUCHK(call) {	\
	cudaError_t err = call; \
	if( cudaSuccess != err) {	\
		fprintf(stderr, "Cuda error in file '%s' in line %i : %s.\n",	\
				__FILE__, __LINE__, cudaGetErrorString(err) );	\
		fflush(stderr); \
		exit(EXIT_FAILURE);	\
}}

#include "tensor_core_helper.cuh" // 

//
#define SIZE_TILE_P7 16
#define SIZE_TILE_H3 4
#define SIZE_TILE_P4 4
#define SIZE_TILE_H2 4
#define SIZE_TILE_H1 4
#define SIZE_TILE_P6 4
#define SIZE_TILE_P5 4
#define SIZE_UNIT_INT SIZE_TILE_P7

// 
#define PAD 4
#define STAGE_ALIGN 32
#define SINGLE_STAGE_SIZE (64 * (PAD + 16))
#define STAGE_OFFSET ((SINGLE_STAGE_SIZE + STAGE_ALIGN - 1) / STAGE_ALIGN) * STAGE_ALIGN
#define NUM_STAGE 2

#define TEST_ENABLE_RT
#define TEST_OLD_STYLE

//------------------------------------------------------------------------------ device helper fuctions
__device__ inline void zero_shared(double *smem) {
	const int t_id = threadIdx.y * blockDim.x + threadIdx.x;
	#pragma unroll
	for (int i = t_id; i < SINGLE_STAGE_SIZE; i += blockDim.x * blockDim.y) {
		smem[i] = 0;
	}
}

#include "ccsd_t_g2s_device_functions.cu"

//------------------------------------------------------------------------------ kernels and callers

//
__global__ void next_unfused_kernel_d1_1(double* dev_t3_d, const double* __restrict__ dev_d1_t2_1, const double* __restrict__ dev_d1_v2_1, 
                                        int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, 
                                        int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
                                        int stride_reg_x, int stride_reg_y, 
                                        int size_internal) 
{
    // 
    auto grid = cooperative_groups::this_grid();
    auto block = cooperative_groups::this_thread_block();

    // For Shared Memory,
    const int lda = 16 + PAD;
    extern __shared__ double sm_block[];
    double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
    double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

    #pragma unroll
    for (int i = 0; i < NUM_STAGE; i++) {
        zero_shared(sm_a + STAGE_OFFSET * i);
        zero_shared(sm_b + STAGE_OFFSET * i);
    }
    block.sync();

    // Allocate shared storage for a N-stage cuda::pipeline:
    cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

    const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
    const int warp_id = thread_id / 32; // 0:7
    WarpRegisterMapping wrm(thread_id);

    const int tile_m = warp_id % 2; // 0:1
    const int tile_n = warp_id / 2; // 0:3

    MmaOperandC op_c;

    int internal_upperbound = 0;
    int internal_offset;

    //  
    //  based on sd2_1
    //  (p6,h2), (h1,h3)
    int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

    int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h1 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h3 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4 + idx_p6) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
    if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
    if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

    // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

    #pragma unroll 1
    for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
        #pragma unroll 1
        for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
        pipeline.producer_acquire();

        const int l_fetch = fetch_batch * SIZE_UNIT_INT;
        const size_t shared_idx = fetch_batch % NUM_STAGE;
        internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
        block.sync();

        if (internal_offset > 0) { 
            internal_upperbound = internal_offset;
            zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
            zero_shared(sm_b + STAGE_OFFSET * shared_idx);
            block.sync();
        }

        if ((idx_h3 < rng_h1) && (idx_h1 < rng_p4) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) { // p4,h1
            g2s_d1_t2_1<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d1_t2_1, 
            blk_idx_h1, 					idx_h3, 
            blk_idx_p5, size_p5, 	
            blk_idx_p4, size_p4,  idx_h1, 
                        size_h7, 	threadIdx.x + l_fetch, 
                        rng_p5, 	pipeline);
        }

        if ((idx_h2 < rng_h2) && (idx_p6 < rng_h3) && threadIdx.y < SIZE_UNIT_INT - internal_upperbound) { // h3,h2
            g2s_d1_v2_1<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d1_v2_1, 
            blk_idx_p6, size_p6,	
            blk_idx_h2, size_h2, 	idx_h2, 
            blk_idx_h3, size_h3, 	idx_p6, 
                                    threadIdx.y + l_fetch, 
                        rng_p6, 	pipeline);
        }
        pipeline.producer_commit();
        }
        pipeline.consumer_wait();
        block.sync();
        const size_t shared_idx = compute_batch % NUM_STAGE;

        #pragma unroll
        for (int ll = 0; ll < 4; ll++) {
        MmaOperandA op_a;
        op_a.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
        MmaOperandB op_b;
        op_b.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
        mma(op_c, op_a, op_b);
        }
        pipeline.consumer_release();
    }
    block.sync(); 

    //     (p6,h2),     (h1,h3)
    // TB_X(p4,h3), TB_Y(h2,h1), REG_X,Y(p5,p6)
    dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p4 && idx_h2 < rng_h3 && idx_h1 < rng_h2 && idx_h3 < rng_h1) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p6 && idx_reg_x < rng_p5) { 
                    dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	}
}

void driver_ccsd_t_d1_1(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, double* host_t3, double* host_t2, double* host_v2) 
{
	// 
	int numTbs = CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * 
              CEIL(size_h1, SIZE_TILE_H1) * CEIL(size_p6, SIZE_TILE_P6) * 
              CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd1_1: t3[h3,h2,h1,p6,p5,p4] -= t2[h7,p4,p5,h1] * v2[h3,h2,p6,h7]
	double* dev_t3; double* dev_t2; double* dev_v2;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_h7 * size_p4 * size_p5 * size_h1));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_h3 * size_h2 * size_p6 * size_h7));

  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h7 * size_p4 * size_p5 * size_h1, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h3 * size_h2 * size_p6 * size_h7, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_h7);

	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p6;
      
  // 
  dev_t3 = t3_d;

	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);

  // 
  // int maxbytes = 98304; // 96 KB
  // CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d1_1, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d1_1<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7, 
  CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
  CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
  stride_reg_x, stride_reg_y,
      size_h7);
  // cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());

  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);


  // cudaFree()
	CUCHK(cudaFree(dev_t2)); CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d1_2(double* dev_t3_d, const double* __restrict__ dev_d1_t2_2, const double* __restrict__ dev_d1_v2_2, 
	// 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
  // 
  auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h3 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4 + idx_p6) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

  #pragma unroll 1
  for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
    #pragma unroll 1
    for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
      pipeline.producer_acquire();

      const int l_fetch = fetch_batch * SIZE_UNIT_INT;
      const size_t shared_idx = fetch_batch % NUM_STAGE;
      internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
      block.sync();

      if (internal_offset > 0) { 
        internal_upperbound = internal_offset;
        zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
        zero_shared(sm_b + STAGE_OFFSET * shared_idx);
        block.sync();
      }

      if ((idx_h3 < rng_h2) && (idx_h1 < rng_p4) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
        g2s_d1_t2_2<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d1_t2_2, 
          blk_idx_h2, 					idx_h3, 
          blk_idx_p5, size_p5, 	
          blk_idx_p4, size_p4,  idx_h1, 
                      size_h7, 	threadIdx.x + l_fetch, 
                      rng_p5, 	pipeline);
      }

      if ((idx_h2 < rng_h1) && (idx_p6 < rng_h3) && threadIdx.y < SIZE_UNIT_INT - internal_upperbound) {
        g2s_d1_v2_2<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d1_v2_2, 
          blk_idx_p6, size_p6,	
          blk_idx_h1, size_h1, 	idx_h2, 
          blk_idx_h3, size_h3, 	idx_p6, 
                                threadIdx.y + l_fetch, 
                      rng_p6, 	pipeline);
      }
      pipeline.producer_commit();
    }
    pipeline.consumer_wait();
    block.sync();
    const size_t shared_idx = compute_batch % NUM_STAGE;

    #pragma unroll
    for (int ll = 0; ll < 4; ll++) {
      MmaOperandA op_a;
      // op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
      op_a.template load_plus<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
      MmaOperandB op_b;
      // op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
      op_b.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
      // mma_t(op_c, op_a, op_b);
      mma(op_c, op_a, op_b);
    }
    pipeline.consumer_release();
  }
  block.sync(); 

  //     (p6,h2),     (h1,h3)
  // TB_X(p4,h3), TB_Y(h1,h2), REG_X,Y(p5,p6)
  dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p4 && idx_h2 < rng_h3 && idx_h1 < rng_h1 && idx_h3 < rng_h2) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p6 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d1_2(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd1_2: t3[h3,h2,h1,p6,p5,p4] += t2[h7,p4,p5,h2] * v2[h3,h1,p6,h7]
	double* dev_t3; double* dev_t2; double* dev_v2;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_h7 * size_p4 * size_p5 * size_h2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_h3 * size_h1 * size_p6 * size_h7));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h7 * size_p4 * size_p5 * size_h2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h3 * size_h1 * size_p6 * size_h7, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_h7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p6;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);

  dev_t3 = t3_d;
  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d1_2, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d1_2<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_h7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

// 
__global__ void next_unfused_kernel_d1_3(double* dev_t3_d, const double* __restrict__ dev_d1_t2_3, const double* __restrict__ dev_d1_v2_3, 
	
  int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
  // 
  auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h3 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h2 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4 + idx_p6) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

  #pragma unroll 1
  for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
    #pragma unroll 1
    for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
      pipeline.producer_acquire();

      const int l_fetch = fetch_batch * SIZE_UNIT_INT;
      const size_t shared_idx = fetch_batch % NUM_STAGE;
      internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
      block.sync();

      if (internal_offset > 0) { 
        internal_upperbound = internal_offset;
        zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
        zero_shared(sm_b + STAGE_OFFSET * shared_idx);
        block.sync();
      }

      if ((idx_h3 < rng_h3) && (idx_h1 < rng_p4) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
        g2s_d1_t2_3<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d1_t2_3, 
          blk_idx_h3, 					idx_h3, 
          blk_idx_p5, size_p5, 	
          blk_idx_p4, size_p4,  idx_h1, 
                      size_h7, 	threadIdx.x + l_fetch, 
                      rng_p5, 	pipeline);
      }

      if ((idx_h2 < rng_h1) && (idx_p6 < rng_h2) && threadIdx.y < SIZE_UNIT_INT - internal_upperbound) {
        g2s_d1_v2_3<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d1_v2_3, 
          blk_idx_p6, size_p6,	
          blk_idx_h1, size_h1, 	idx_h2, 
          blk_idx_h2, size_h2, 	idx_p6, 
                                threadIdx.y + l_fetch, 
                      rng_p6, 	pipeline);
      }
      pipeline.producer_commit();
    }
    pipeline.consumer_wait();
    block.sync();
    const size_t shared_idx = compute_batch % NUM_STAGE;

    #pragma unroll
    for (int ll = 0; ll < 4; ll++) {
      MmaOperandA op_a;
      // op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
      op_a.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
      MmaOperandB op_b;
      // op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
      op_b.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
      // mma_t(op_c, op_a, op_b);
      mma(op_c, op_a, op_b);
    }
    pipeline.consumer_release();
  }
  block.sync(); 

  //     (p6,h2),     (h1,h3)
	// TB_X(p4,h2), TB_X(h1,h3), REG_X,Y(p5,p6)
  dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p4 && idx_h2 < rng_h2 && idx_h1 < rng_h1 && idx_h3 < rng_h3) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p6 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d1_3(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd1_3: t3[h3,h2,h1,p6,p5,p4] -= t2[h7,p4,p5,h3] * v2[h2,h1,p6,h7]
	double* dev_t3; double* dev_t2; double* dev_v2;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_h7 * size_p4 * size_p5 * size_h3));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_h2 * size_h1 * size_p6 * size_h7));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h7 * size_p4 * size_p5 * size_h3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h2 * size_h1 * size_p6 * size_h7, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_h7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p6;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);
  dev_t3 = t3_d;

  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d1_3, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d1_3<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_h7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

// 
__global__ void next_unfused_kernel_d1_4(double* dev_t3_d, const double* __restrict__ dev_d1_t2_4, const double* __restrict__ dev_d1_v2_4, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
  // 
  auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h2,h1), REG_X,Y(p5,p4)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h1 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h3 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h1) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d1_t2_4<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d1_t2_4, 
					blk_idx_h1, 					idx_h3, 
					blk_idx_p6, size_p6,  idx_h1,  	
					blk_idx_p5, size_p5,
											size_h7, 	threadIdx.x + l_fetch, 
											rng_p5, 	pipeline);
			}

			if ((idx_h2 < rng_h2) && (idx_p6 < rng_h3) && threadIdx.y < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d1_v2_4<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d1_v2_4, 
					blk_idx_p4, size_p4,	
					blk_idx_h2, size_h2, 	idx_h2, 
					blk_idx_h3, size_h3, 	idx_p6, 
																threadIdx.y + l_fetch, 
											rng_p4, 	pipeline);
			}
			pipeline.producer_commit();
		}
		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;

		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			// op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			op_a.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			// op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			op_b.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			// mma_t(op_c, op_a, op_b);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h2,h1), REG_X,Y(p5,p4)
  dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h3 && idx_h1 < rng_h2 && idx_h3 < rng_h1) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p4 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d1_4(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd1_4: t3[h3,h2,h1,p6,p5,p4] -= t2[h7,p5,p6,h1] * v2[h3,h2,p4,h7]
	double* dev_t3; double* dev_t2; double* dev_v2;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_h7 * size_p5 * size_p6 * size_h1));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_h3 * size_h2 * size_p4 * size_h7));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h7 * size_p5 * size_p6 * size_h1, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h3 * size_h2 * size_p4 * size_h7, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_h7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p4;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);

  dev_t3 = t3_d;
  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d1_4, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d1_4<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_h7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

// 
__global__ void next_unfused_kernel_d1_5(double* dev_t3_d, const double* __restrict__ dev_d1_t2_5, const double* __restrict__ dev_d1_v2_5, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
  // 
  auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h1,h2),  REG_X,Y(p5,p4)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h3 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h2) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d1_t2_5<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d1_t2_5, 
					blk_idx_h2, 					idx_h3, 
					blk_idx_p6, size_p6,  idx_h1,  	
					blk_idx_p5, size_p5,
											size_h7, 	threadIdx.x + l_fetch, 
											rng_p5, 	pipeline);
			}

			if ((idx_h2 < rng_h1) && (idx_p6 < rng_h3) && threadIdx.y < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d1_v2_5<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d1_v2_5, 
					blk_idx_p4, size_p4,	
					blk_idx_h1, size_h1, 	idx_h2, 
					blk_idx_h3, size_h3, 	idx_p6, 
																threadIdx.y + l_fetch, 
											rng_p4, 	pipeline);
			}
			pipeline.producer_commit();
		}
		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;

		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			// op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			op_a.template load_plus<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			// op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			op_b.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			// mma_t(op_c, op_a, op_b);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h1,h2),  REG_X,Y(p5,p4)
  dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h3 && idx_h1 < rng_h1 && idx_h3 < rng_h2) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p4 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d1_5(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd1_5: t3[h3,h2,h1,p6,p5,p4] += t2[h7,p5,p6,h2] * v2[h3,h1,p4,h7]
	double* dev_t3; double* dev_t2; double* dev_v2;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_h7 * size_p5 * size_p6 * size_h2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_h3 * size_h1 * size_p4 * size_h7));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h7 * size_p5 * size_p6 * size_h2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h3 * size_h1 * size_p4 * size_h7, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_h7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p4;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);

  dev_t3 = t3_d;
  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d1_5, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d1_5<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_h7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d1_6(double* dev_t3_d, const double* __restrict__ dev_d1_t2_6, const double* __restrict__ dev_d1_v2_6, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
  // 
  auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h2), TB_Y(h1,h3), REG_X,Y(p5,p4)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h3 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h2 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 +
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h3) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d1_t2_6<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d1_t2_6, 
					blk_idx_h3, 					idx_h3, 
					blk_idx_p6, size_p6,  idx_h1,  	
					blk_idx_p5, size_p5,
											size_h7, 	threadIdx.x + l_fetch, 
											rng_p5, 	pipeline);
			}

			if ((idx_h2 < rng_h1) && (idx_p6 < rng_h2) && threadIdx.y < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d1_v2_6<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d1_v2_6, 
					blk_idx_p4, size_p4,	
					blk_idx_h1, size_h1, 	idx_h2, 
					blk_idx_h2, size_h2, 	idx_p6, 
																threadIdx.y + l_fetch, 
											rng_p4, 	pipeline);
			}
			pipeline.producer_commit();
		}
		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;

		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			op_a.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			op_b.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 

	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h2), TB_Y(h1,h3), REG_X,Y(p5,p4)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h2 && idx_h1 < rng_h1 && idx_h3 < rng_h3) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p4 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d1_6(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd1_6:  	t3[h3,h2,h1,p6,p5,p4] -= t2[h7,p5,p6,h3] * v2[h2,h1,p4,h7]
	double* dev_t3; double* dev_t2; double* dev_v2;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_h7 * size_p5 * size_p6 * size_h3));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_h2 * size_h1 * size_p4 * size_h7));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h7 * size_p5 * size_p6 * size_h3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h2 * size_h1 * size_p4 * size_h7, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_h7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p4;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);

  dev_t3 = t3_d;
  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d1_6, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d1_6<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_h7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d1_7(double* dev_t3_d, const double* __restrict__ dev_d1_t2_7, const double* __restrict__ dev_d1_v2_7, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
  // 
  auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h2,h1), REG_X,Y(p4,p5)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h1 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h3 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 +  
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
		for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
			#pragma unroll 1
			for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
				pipeline.producer_acquire();

				const int l_fetch = fetch_batch * SIZE_UNIT_INT;
				const size_t shared_idx = fetch_batch % NUM_STAGE;
				internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
				block.sync();

				if (internal_offset > 0) { 
					internal_upperbound = internal_offset;
					zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
					zero_shared(sm_b + STAGE_OFFSET * shared_idx);
					block.sync();
				}

				if ((idx_h3 < rng_h1) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
					g2s_d1_t2_7<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d1_t2_7, 
						blk_idx_h1, 					idx_h3, 
						blk_idx_p6, size_p6,  idx_h1,  	
						blk_idx_p4, size_p4,
												size_h7, 	threadIdx.x + l_fetch, 
												rng_p4, 	pipeline);
				}

				if ((idx_h2 < rng_h2) && (idx_p6 < rng_h3) && threadIdx.y < SIZE_UNIT_INT - internal_upperbound) {
					g2s_d1_v2_7<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d1_v2_7, 
						blk_idx_p5, size_p5,	
						blk_idx_h2, size_h2, 	idx_h2, 
						blk_idx_h3, size_h3, 	idx_p6, 
																	threadIdx.y + l_fetch, 
												rng_p5, 	pipeline);
				}
				pipeline.producer_commit();
			}
			pipeline.consumer_wait();
			block.sync();
			const size_t shared_idx = compute_batch % NUM_STAGE;

			#pragma unroll
			for (int ll = 0; ll < 4; ll++) {
				MmaOperandA op_a;
				// op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
				op_a.template load_plus<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
				MmaOperandB op_b;
				// op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
				op_b.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
				// mma_t(op_c, op_a, op_b);
				mma(op_c, op_a, op_b);
			}
			pipeline.consumer_release();
		}
		block.sync(); 

	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h2,h1), REG_X,Y(p4,p5)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h3 && idx_h1 < rng_h2 && idx_h3 < rng_h1) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p5 && idx_reg_x < rng_p4) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d1_7(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd1_7: t3[h3,h2,h1,p6,p5,p4] += t2[h7,p4,p6,h1] * v2[h3,h2,p5,h7]
	double* dev_t3; double* dev_t2; double* dev_v2;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_h7 * size_p4 * size_p6 * size_h1));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_h3 * size_h2 * size_p5 * size_h7));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h7 * size_p4 * size_p6 * size_h1, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h3 * size_h2 * size_p5 * size_h7, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_h7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p4;
  int stride_reg_y = stride_output_p5;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);

  dev_t3 = t3_d;
  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d1_7, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d1_7<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_h7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d1_8(double* dev_t3_d, const double* __restrict__ dev_d1_t2_8, const double* __restrict__ dev_d1_v2_8, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
  // 
  auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h1,h2), REG_X,Y(p4,p5)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h3 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h2) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d1_t2_8<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d1_t2_8, 
					blk_idx_h2, 					idx_h3, 
					blk_idx_p6, size_p6,  idx_h1,  	
					blk_idx_p4, size_p4,
											size_h7, 	threadIdx.x + l_fetch, 
											rng_p4, 	pipeline);
			}

			if ((idx_h2 < rng_h1) && (idx_p6 < rng_h3) && threadIdx.y < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d1_v2_8<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d1_v2_8, 
					blk_idx_p5, size_p5,	
					blk_idx_h1, size_h1, 	idx_h2, 
					blk_idx_h3, size_h3, 	idx_p6, 
																threadIdx.y + l_fetch, 
											rng_p5, 	pipeline);
			}
			pipeline.producer_commit();
		}
		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;

		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			// op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			op_a.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			// op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			op_b.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			// mma_t(op_c, op_a, op_b);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 

	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h1,h2), REG_X,Y(p4,p5)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h3 && idx_h1 < rng_h1 && idx_h3 < rng_h2) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p5 && idx_reg_x < rng_p4) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d1_8(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd1_8: t3[h3,h2,h1,p6,p5,p4] -= t2[h7,p4,p6,h2] * v2[h3,h1,p5,h7]
	double* dev_t3; double* dev_t2; double* dev_v2;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_h7 * size_p4 * size_p6 * size_h2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_h3 * size_h1 * size_p5 * size_h7));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h7 * size_p4 * size_p6 * size_h2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h3 * size_h1 * size_p5 * size_h7, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_h7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p4;
  int stride_reg_y = stride_output_p5;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);

  dev_t3 = t3_d;
  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d1_8, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d1_8<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_h7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d1_9(double* dev_t3_d, const double* __restrict__ dev_d1_t2_9, const double* __restrict__ dev_d1_v2_9, 
	// 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
  // 
  auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h2), TB_Y(h1,h3), REG_X,Y(p4,p5)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h3 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h2 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
		for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
			#pragma unroll 1
			for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
				pipeline.producer_acquire();

				const int l_fetch = fetch_batch * SIZE_UNIT_INT;
				const size_t shared_idx = fetch_batch % NUM_STAGE;
				internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
				block.sync();

				if (internal_offset > 0) { 
					internal_upperbound = internal_offset;
					zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
					zero_shared(sm_b + STAGE_OFFSET * shared_idx);
					block.sync();
				}

				if ((idx_h3 < rng_h3) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
					g2s_d1_t2_9<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d1_t2_9, 
						blk_idx_h3, 					idx_h3, 
						blk_idx_p6, size_p6,  idx_h1,  	
						blk_idx_p4, size_p4,
												size_h7, 	threadIdx.x + l_fetch, 
												rng_p4, 	pipeline);
				}

				if ((idx_h2 < rng_h1) && (idx_p6 < rng_h2) && threadIdx.y < SIZE_UNIT_INT - internal_upperbound) {
					g2s_d1_v2_9<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d1_v2_9, 
						blk_idx_p5, size_p5,	
						blk_idx_h1, size_h1, 	idx_h2, 
						blk_idx_h2, size_h2, 	idx_p6, 
																	threadIdx.y + l_fetch, 
												rng_p5, 	pipeline);
				}
				pipeline.producer_commit();
			}
			pipeline.consumer_wait();
			block.sync();
			const size_t shared_idx = compute_batch % NUM_STAGE;

			#pragma unroll
			for (int ll = 0; ll < 4; ll++) {
				MmaOperandA op_a;
				// op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
				op_a.template load_plus<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
				MmaOperandB op_b;
				// op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
				op_b.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
				// mma_t(op_c, op_a, op_b);
				mma(op_c, op_a, op_b);
			}
			pipeline.consumer_release();
		}
		block.sync(); 

	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h2), TB_Y(h1,h3), REG_X,Y(p4,p5)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h2 && idx_h1 < rng_h1 && idx_h3 < rng_h3) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p5 && idx_reg_x < rng_p4) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d1_9(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_h7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd1_9: t3[h3,h2,h1,p6,p5,p4] += t2[h7,p4,p6,h3] * v2[h2,h1,p5,h7]
	double* dev_t3; double* dev_t2; double* dev_v2;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_h7 * size_p4 * size_p6 * size_h3));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_h2 * size_h1 * size_p5 * size_h7));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_h7 * size_p4 * size_p6 * size_h3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_h2 * size_h1 * size_p5 * size_h7, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_h7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p4;
  int stride_reg_y = stride_output_p5;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);

  dev_t3 = t3_d;
  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d1_9, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d1_9<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_h7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_h7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * (size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4), cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

///
///
///
__global__ void next_unfused_kernel_d2_1(double* dev_t3_d, const double* __restrict__ dev_d2_t2_1, const double* __restrict__ dev_d2_v2_1, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
	// 
  auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h2), TB_Y(h1,h3), REG_X,Y(p5,p4)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h3 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h2 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h1) && (idx_h1 < rng_h2) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_t2_1<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d2_t2_1, 
					blk_idx_h2, 					idx_h1, 
					blk_idx_h1, size_h1, 	idx_h3, 
					blk_idx_p4, size_p4, 
											size_p7, 	threadIdx.x + l_fetch, rng_p4, pipeline);
			}

			if ((idx_h3 < rng_h3) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_v2_1<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d2_v2_1, 
					blk_idx_p5, 
					blk_idx_p6, size_p6, idx_h1, 
					blk_idx_h3, size_h3, idx_h3, 
											size_p7, threadIdx.x + l_fetch, rng_p5, pipeline);
			}
			pipeline.producer_commit();
		}

		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;

		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			op_a.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 
	
	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h2), TB_Y(h1,h3), REG_X,Y(p5,p4)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h2 && idx_h1 < rng_h1 && idx_h3 < rng_h3) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p4 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d2_1(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd2_1: t3[h3,h2,h1,p6,p5,p4] −= t2[p7,p4,h1,h2] * v2[p7,h3,p6,p5]
	double* dev_t3; double* dev_t2; double* dev_v2;

	size_t size_t3 = size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;
	size_t size_t2 = size_p7 * size_p4 * size_h1 * size_h2;
	size_t size_v2 = size_p7 * size_h3 * size_p6 * size_p5;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_t3));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_t2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_v2));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_t3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_t2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_v2, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_p7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p4;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);
  dev_t3 = t3_d;

  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d2_1, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d2_1<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_p7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_t3, cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d2_2(double* dev_t3_d, const double* __restrict__ dev_d2_t2_2, const double* __restrict__ dev_d2_v2_2, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
	// 
	auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h2,h1), REG_X,Y(p5,p4)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h1 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h3 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h2) && (idx_h1 < rng_h3) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_t2_2<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d2_t2_2, 
					blk_idx_h3, 					idx_h1, 
					blk_idx_h2, size_h2, 	idx_h3, 
					blk_idx_p4, size_p4,  
											size_p7, threadIdx.x + l_fetch, rng_p4, pipeline);
			}

			if ((idx_h3 < rng_h1) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_v2_2<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d2_v2_2, 
					blk_idx_p5, 
					blk_idx_p6, size_p6, idx_h1, 
					blk_idx_h1, size_h1, idx_h3, 
											size_p7, threadIdx.x + l_fetch, rng_p5, pipeline);
			}
			pipeline.producer_commit();
		}

		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;
		
		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			op_a.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 
	
	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h2,h1), REG_X,Y(p5,p4)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h3 && idx_h1 < rng_h2 && idx_h3 < rng_h1) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p4 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d2_2(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd2_2: t3[h3,h2,h1,p6,p5,p4] -= t2[p7,p4,h2,h3] * v2[p7,h1,p6,p5]
	double* dev_t3; double* dev_t2; double* dev_v2;

	size_t size_t3 = size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;
	size_t size_t2 = size_p7 * size_p4 * size_h2 * size_h3;
	size_t size_v2 = size_p7 * size_h1 * size_p6 * size_p5;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_t3));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_t2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_v2));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_t3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_t2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_v2, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_p7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p4;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);
  dev_t3 = t3_d;

  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d2_2, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d2_2<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_p7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_t3, cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d2_3(double* dev_t3_d, const double* __restrict__ dev_d2_t2_3, const double* __restrict__ dev_d2_v2_3, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
	// 
	auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h1,h2), REG_X,Y(p5,p4)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h3 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx);
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h1) && (idx_h1 < rng_h3) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_t2_3<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d2_t2_3,  
					blk_idx_h3, 					idx_h1, 
					blk_idx_h1, size_h1, 	idx_h3, 
					blk_idx_p4, size_p4,  
											size_p7, 	threadIdx.x + l_fetch, rng_p4, pipeline);
			}

			if ((idx_h3 < rng_h2) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_v2_3<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d2_v2_3, 
					blk_idx_p5, 				 	
					blk_idx_p6, size_p6, 	idx_h1, 
					blk_idx_h2, size_h2, 	idx_h3, 
											size_p7, 	threadIdx.x + l_fetch, rng_p5, pipeline);
			}
			pipeline.producer_commit();
		}

		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;
		
		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			// mma_t(op_c, op_a, op_b);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 
	
	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h1,h2), REG_X,Y(p5,p4)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h3 && idx_h1 < rng_h1 && idx_h3 < rng_h2) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p4 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d2_3(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd2_3: t3[h3,h2,h1,p6,p5,p4] += t2[p7,p4,h1,h3] * v2[p7,h2,p6,p5]
	double* dev_t3; double* dev_t2; double* dev_v2;

	size_t size_t3 = size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;
	size_t size_t2 = size_p7 * size_p4 * size_h1 * size_h3;
	size_t size_v2 = size_p7 * size_h2 * size_p6 * size_p5;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_t3));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_t2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_v2));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_t3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_t2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_v2, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_p7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p4;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);
  dev_t3 = t3_d;

  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d2_3, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d2_3<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_p7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_t3, cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d2_4(double* dev_t3_d, const double* __restrict__ dev_d2_t2_4, const double* __restrict__ dev_d2_v2_4, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
	// 
	auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h2), TB_Y(h1,h3), REG_X,Y(p4,p5)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h3 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h2 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx);
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h1) && (idx_h1 < rng_h2) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_t2_4<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d2_t2_4,  
					blk_idx_h2, 					idx_h1, 
					blk_idx_h1, size_h1, 	idx_h3, 
					blk_idx_p5, size_p5,  // reg_y: p5
											size_p7, 	threadIdx.x + l_fetch, rng_p5, pipeline);
			}

			if ((idx_h3 < rng_h3) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_v2_4<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d2_v2_4, 
					blk_idx_p4, 				 	// reg_x: p4
					blk_idx_p6, size_p6, 	idx_h1, 
					blk_idx_h3, size_h3, 	idx_h3, 
											size_p7, 	threadIdx.x + l_fetch, rng_p4, pipeline);
			}
			pipeline.producer_commit();
		}

		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;
		
		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			// mma_t(op_c, op_a, op_b);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 
	
	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h2), TB_Y(h1,h3), REG_X,Y(p4,p5)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h2 && idx_h1 < rng_h1 && idx_h3 < rng_h3) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p5 && idx_reg_x < rng_p4) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d2_4(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd2_4: t3[h3,h2,h1,p6,p5,p4] += t2[p7,p5,h1,h2] * v2[p7,h3,p6,p4]
	double* dev_t3; double* dev_t2; double* dev_v2;

	size_t size_t3 = size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;
	size_t size_t2 = size_p7 * size_p5 * size_h1 * size_h2;
	size_t size_v2 = size_p7 * size_h3 * size_p6 * size_p4;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_t3));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_t2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_v2));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_t3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_t2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_v2, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_p7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p4;
  int stride_reg_y = stride_output_p5;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);
  dev_t3 = t3_d;

  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d2_4, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d2_4<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_p7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_t3, cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d2_5(double* dev_t3_d, const double* __restrict__ dev_d2_t2_5, const double* __restrict__ dev_d2_v2_5, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
	// 
	auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h2,h1), REG_X,Y(p4,p5)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h1 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h3 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h2) && (idx_h1 < rng_h3) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_t2_5<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d2_t2_5, 
					blk_idx_h3, 					idx_h1, 
					blk_idx_h2, size_h2, 	idx_h3, 
					blk_idx_p5, size_p5,  
											size_p7, 	threadIdx.x + l_fetch, rng_p5, pipeline);
			}

			if ((idx_h3 < rng_h1) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_v2_5<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d2_v2_5, 
					blk_idx_p4, 				 	
					blk_idx_p6, size_p6, 	idx_h1, 
					blk_idx_h1, size_h1, 	idx_h3, 
											size_p7, 	threadIdx.x + l_fetch, rng_p4, pipeline);
			}
			pipeline.producer_commit();
		}

		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;
		
		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			// mma_t(op_c, op_a, op_b);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 
	
	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h2,h1), REG_X,Y(p4,p5)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h3 && idx_h1 < rng_h2 && idx_h3 < rng_h1) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p5 && idx_reg_x < rng_p4) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d2_5(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd2_5: t3[h3,h2,h1,p6,p5,p4] += t2[p7,p5,h2,h3] * v2[p7,h1,p6,p4]
	double* dev_t3; double* dev_t2; double* dev_v2;

	size_t size_t3 = size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;
	size_t size_t2 = size_p7 * size_p5 * size_h2 * size_h3;
	size_t size_v2 = size_p7 * size_h1 * size_p6 * size_p4;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_t3));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_t2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_v2));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_t3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_t2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_v2, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_p7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p4;
  int stride_reg_y = stride_output_p5;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);
  dev_t3 = t3_d;

  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d2_5, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d2_5<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_p7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_t3, cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d2_6(double* dev_t3_d, const double* __restrict__ dev_d2_t2_6, const double* __restrict__ dev_d2_v2_6, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
	// 
	auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h1,h2), REG_X,Y(p4,p5) // sd2_6
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h3 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + idx_p6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h1) && (idx_h1 < rng_h3) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_t2_6<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d2_t2_6, 
					blk_idx_h3, 					idx_h1, 
					blk_idx_h1, size_h1, 	idx_h3, 
					blk_idx_p5, size_p5,  
											size_p7, 	threadIdx.x + l_fetch, rng_p5, pipeline);
			}

			if ((idx_h3 < rng_h2) && (idx_h1 < rng_p6) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_v2_6<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d2_v2_6, 
					blk_idx_p4, 				 	
					blk_idx_p6, size_p6, 	idx_h1,
					blk_idx_h2, size_h2, 	idx_h3, 
											size_p7, 	threadIdx.x + l_fetch, rng_p4, pipeline);
			}
			pipeline.producer_commit();
		}

		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;
		
		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			op_a.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			// mma_t(op_c, op_a, op_b);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 
	
	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p6,h3), TB_Y(h1,h2), REG_X,Y(p4,p5) // sd2_6
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p6 && idx_h2 < rng_h3 && idx_h1 < rng_h1 && idx_h3 < rng_h2) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p5 && idx_reg_x < rng_p4) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d2_6(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd2_6: t3[h3,h2,h1,p6,p5,p4] −= t2[p7,p5,h1,h3] * v2[p7,h2,p6,p4]
	double* dev_t3; double* dev_t2; double* dev_v2;

	size_t size_t3 = size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;
	size_t size_t2 = size_p7 * size_p5 * size_h1 * size_h3;
	size_t size_v2 = size_p7 * size_h2 * size_p6 * size_p4;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_t3));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_t2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_v2));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_t3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_t2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_v2, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_p7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p4;
  int stride_reg_y = stride_output_p5;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);
  dev_t3 = t3_d;

  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d2_6, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d2_6<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_p7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_t3, cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d2_7(double* dev_t3_d, const double* __restrict__ dev_d2_t2_7, const double* __restrict__ dev_d2_v2_7, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
	// 
	auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p4,h2), TB_Y(h1,h3), REG(p5,p6)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h3 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h2 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4 + idx_p6) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h1) && (idx_h1 < rng_h2) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_t2_7<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d2_t2_7, 
					blk_idx_h2, 					idx_h1, 
					blk_idx_h1, size_h1, 	idx_h3, 
					blk_idx_p6, size_p6,  
											size_p7, 	threadIdx.x + l_fetch, rng_p6, pipeline);
			}

			if ((idx_h3 < rng_h3) && (idx_h1 < rng_p4) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_v2_7<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d2_v2_7,  
					blk_idx_p4, 				 	idx_h1, 
					blk_idx_p5, size_p5, 
					blk_idx_h3, size_h3, 	idx_h3, 
											size_p7, 	threadIdx.x + l_fetch, rng_p5, pipeline);
			}
			pipeline.producer_commit();
		}

		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;
		
		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			op_a.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			// mma_t(op_c, op_a, op_b);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync();
	
	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p4,h2), TB_Y(h1,h3), REG(p5,p6)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p4 && idx_h2 < rng_h2 && idx_h1 < rng_h1 && idx_h3 < rng_h3) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p6 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d2_7(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd2_7: t3[h3,h2,h1,p6,p5,p4] −= t2[p7,p6,h1,h2] * v2[p7,h3,p5,p4]
	double* dev_t3; double* dev_t2; double* dev_v2;

	size_t size_t3 = size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;
	size_t size_t2 = size_p7 * size_p6 * size_h1 * size_h2;
	size_t size_v2 = size_p7 * size_h3 * size_p5 * size_p4;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_t3));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_t2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_v2));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_t3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_t2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_v2, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_p7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p6;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);
  dev_t3 = t3_d;

  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d2_7, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d2_7<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_p7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_t3, cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d2_8(double* dev_t3_d, const double* __restrict__ dev_d2_t2_8, const double* __restrict__ dev_d2_v2_8, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
	// 
	auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p4,h3), TB_Y(h2,h1), REG_X,Y(p5,p6)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h1 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h3 + 
                    (blk_idx_p6 * SIZE_TILE_P6 +  
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4 + idx_p6) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h2) && (idx_h1 < rng_h3) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_t2_8<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d2_t2_8, 
					blk_idx_h3, 					idx_h1, 
					blk_idx_h2, size_h2, 	idx_h3, 
					blk_idx_p6, size_p6,  
											size_p7, threadIdx.x + l_fetch, rng_p6, pipeline);
			}

			if ((idx_h3 < rng_h1) && (idx_h1 < rng_p4) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_v2_8<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d2_v2_8, 
					blk_idx_p4, 				 	idx_h1, 
					blk_idx_p5, size_p5, 
					blk_idx_h1, size_h1, 	idx_h3, 
											size_p7, 	threadIdx.x + l_fetch, rng_p5, pipeline);
			}
			pipeline.producer_commit();
		}
		pipeline.consumer_wait();
		block.sync();

		const size_t shared_idx = compute_batch % NUM_STAGE;
		// #pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			op_a.template load<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			// mma_t(op_c, op_a, op_b);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 
	
	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p4,h3), TB_Y(h2,h1), REG_X,Y(p5,p6)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p4 && idx_h2 < rng_h3 && idx_h1 < rng_h2 && idx_h3 < rng_h1) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p6 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d2_8(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd2_8: t3[h3,h2,h1,p6,p5,p4] −= t2[p7,p6,h2,h3] * v2[p7,h1,p5,p4]
	double* dev_t3; double* dev_t2; double* dev_v2;

	size_t size_t3 = size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;
	size_t size_t2 = size_p7 * size_p6 * size_h2 * size_h3;
	size_t size_v2 = size_p7 * size_h1 * size_p5 * size_p4;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_t3));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_t2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_v2));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_t3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_t2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_v2, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_p7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p6;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);
  dev_t3 = t3_d;

  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d2_8, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d2_8<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_p7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_t3, cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

__global__ void next_unfused_kernel_d2_9(double* dev_t3_d, const double* __restrict__ dev_d2_t2_9, const double* __restrict__ dev_d2_v2_9, 
	int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, 
	int numBlk_h3, int numBlk_h2, int numBlk_h1, int numBlk_p6, int numBlk_p5, int numBlk_p4, 
	int stride_reg_x, int stride_reg_y, 
	int size_internal) 
{
	// 
  auto grid = cooperative_groups::this_grid();
	auto block = cooperative_groups::this_thread_block();

	// For Shared Memory,
	const int lda = 16 + PAD;
	extern __shared__ double sm_block[];
	double *sm_a = reinterpret_cast<double *>(sm_block) + 0 * STAGE_OFFSET;
	double *sm_b = reinterpret_cast<double *>(sm_block) + NUM_STAGE * STAGE_OFFSET;

	#pragma unroll
	for (int i = 0; i < NUM_STAGE; i++) {
		zero_shared(sm_a + STAGE_OFFSET * i);
		zero_shared(sm_b + STAGE_OFFSET * i);
	}
	block.sync();

	// Allocate shared storage for a N-stage cuda::pipeline:
	cuda::pipeline<cuda::thread_scope_thread> pipeline = cuda::make_pipeline();

	const int thread_id = threadIdx.y * blockDim.x + threadIdx.x;
	const int warp_id = thread_id / 32; // 0:7
	WarpRegisterMapping wrm(thread_id);

	const int tile_m = warp_id % 2; // 0:1
	const int tile_n = warp_id / 2; // 0:3

	MmaOperandC op_c;

	int internal_upperbound = 0;
	int internal_offset;

  //  
  //  based on sd2_1
  //  (p6,h2), (h1,h3)
	int idx_p6 = threadIdx.x % SIZE_TILE_P6; // this is not used for sd2. 
	int idx_h2 = threadIdx.x / SIZE_TILE_P6;
	int idx_h1 = threadIdx.y % SIZE_TILE_H1;
	int idx_h3 = threadIdx.y / SIZE_TILE_H1;

	int blk_idx_p4 = blockIdx.x / (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	int tmp_blkIdx = blockIdx.x % (numBlk_p5 * numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p5 = tmp_blkIdx / (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_p6 * numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_p6 = tmp_blkIdx / (numBlk_h1 * numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h1 * numBlk_h2 * numBlk_h3);

	int blk_idx_h1 = tmp_blkIdx / (numBlk_h2 * numBlk_h3);
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h2 * numBlk_h3);

	int blk_idx_h2 = tmp_blkIdx / numBlk_h3;
	    tmp_blkIdx = tmp_blkIdx % (numBlk_h3);

	int blk_idx_h3 = tmp_blkIdx;

	//     (p6,h2),     (h1,h3)
	// TB_X(p4,h3), TB_Y(h1,h2), REG_X,Y(p5,p6)
  int base_addr_t3 = blk_idx_h3 * SIZE_TILE_H3 + idx_h2 +
                    (blk_idx_h2 * SIZE_TILE_H2 + idx_h3 + 
                    (blk_idx_h1 * SIZE_TILE_H1 + idx_h1 + 
                    (blk_idx_p6 * SIZE_TILE_P6 + 
                    (blk_idx_p5 * SIZE_TILE_P5 + 
                    (blk_idx_p4 * SIZE_TILE_P4 + idx_p6) * size_p5) * size_p6) * size_h1) * size_h2) * size_h3;

	// need to support partial tiles
	int rng_h3, rng_h2, rng_h1, rng_p6, rng_p5, rng_p4;
	if ((size_h3 - (blk_idx_h3 * SIZE_TILE_H3)) >= SIZE_TILE_H3)  { rng_h3 = SIZE_TILE_H3; }
	else                                                          { rng_h3 = size_h3 % SIZE_TILE_H3; }
	
  if ((size_h2 - (blk_idx_h2 * SIZE_TILE_H2)) >= SIZE_TILE_H2)  { rng_h2 = SIZE_TILE_H2; }
	else                                                          { rng_h2 = size_h2 % SIZE_TILE_H2; }
	
  if ((size_h1 - (blk_idx_h1 * SIZE_TILE_H1)) >= SIZE_TILE_H1)  { rng_h1 = SIZE_TILE_H1; }
	else                                                          { rng_h1 = size_h1 % SIZE_TILE_H1; }

	if ((size_p6 - (blk_idx_p6 * SIZE_TILE_P6)) >= SIZE_TILE_P6)  { rng_p6 = SIZE_TILE_P6; }
	else                                                          { rng_p6 = size_p6 % SIZE_TILE_P6; }

	if ((size_p5 - (blk_idx_p5 * SIZE_TILE_P5)) >= SIZE_TILE_P5)  { rng_p5 = SIZE_TILE_P5; }
	else                                                          { rng_p5 = size_p5 % SIZE_TILE_P5; }

	if ((size_p4 - (blk_idx_p4 * SIZE_TILE_P4)) >= SIZE_TILE_P4)  { rng_p4 = SIZE_TILE_P4; }
	else                                                          { rng_p4 = size_p4 % SIZE_TILE_P4; }

  // 
	const size_t num_batches = (size_internal + SIZE_UNIT_INT - 1) / SIZE_UNIT_INT;

	#pragma unroll 1
	for (size_t compute_batch = 0, fetch_batch = 0; compute_batch < num_batches; ++compute_batch) {
		#pragma unroll 1
		for (; fetch_batch < num_batches && fetch_batch < (compute_batch + NUM_STAGE); ++fetch_batch) {
			pipeline.producer_acquire();

			const int l_fetch = fetch_batch * SIZE_UNIT_INT;
			const size_t shared_idx = fetch_batch % NUM_STAGE;
			internal_offset = (l_fetch + SIZE_UNIT_INT) - size_internal;
			block.sync();

			if (internal_offset > 0) { 
				internal_upperbound = internal_offset;
				zero_shared(sm_a + STAGE_OFFSET * shared_idx); // Zero out shared memory if partial tile
				zero_shared(sm_b + STAGE_OFFSET * shared_idx);
				block.sync();
			}

			if ((idx_h3 < rng_h1) && (idx_h1 < rng_h3) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_t2_9<lda, 1, 4 * lda>(sm_a + STAGE_OFFSET * shared_idx, dev_d2_t2_9, 
					blk_idx_h3, 					idx_h1, 
					blk_idx_h1, size_h1, 	idx_h3, 
					blk_idx_p6, size_p6,  
											size_p7, 	threadIdx.x + l_fetch, 
											rng_p6, pipeline);
			}

			if ((idx_h3 < rng_h2) && (idx_h1 < rng_p4) && threadIdx.x < SIZE_UNIT_INT - internal_upperbound) {
				g2s_d2_v2_9<lda, 1, 4 * lda>(sm_b + STAGE_OFFSET * shared_idx, dev_d2_v2_9, 
					blk_idx_p4, 				 	idx_h1, 
					blk_idx_p5, size_p5, 
					blk_idx_h2, size_h2, 	idx_h3, 
											size_p7, 	threadIdx.x + l_fetch, 
											rng_p5, pipeline);
			}
			pipeline.producer_commit();
		}
		pipeline.consumer_wait();
		block.sync();
		const size_t shared_idx = compute_batch % NUM_STAGE;

		#pragma unroll
		for (int ll = 0; ll < 4; ll++) {
			MmaOperandA op_a;
			op_a.template load_plus<lda>(sm_a + STAGE_OFFSET * shared_idx, ll, tile_m, wrm);
			MmaOperandB op_b;
			op_b.template load<lda>(sm_b + STAGE_OFFSET * shared_idx, ll, tile_n, wrm);
			// mma_t(op_c, op_a, op_b);
			mma(op_c, op_a, op_b);
		}
		pipeline.consumer_release();
	}
	block.sync(); 
	
	// 
	//     (p6,h2),     (h1,h3)
	// TB_X(p4,h3), TB_Y(h1,h2), REG_X,Y(p5,p6)
	dev_t3_d = dev_t3_d + base_addr_t3;
	if (idx_p6 < rng_p4 && idx_h2 < rng_h3 && idx_h1 < rng_h1 && idx_h3 < rng_h2) {
		#pragma unroll 4
		for (int idx_reg_y = 0; idx_reg_y < 4; idx_reg_y++) {
			#pragma unroll 4
			for (int idx_reg_x = 0; idx_reg_x < 4; idx_reg_x++) {
				// 
				if (idx_reg_y < rng_p6 && idx_reg_x < rng_p5) { 
          dev_t3_d[idx_reg_y * stride_reg_y + idx_reg_x * stride_reg_x] += op_c.reg[idx_reg_x + idx_reg_y * 4];
				}
			}
		}
	} 
}

void driver_ccsd_t_d2_9(int size_h3, int size_h2, int size_h1, int size_p6, int size_p5, int size_p4, int size_p7, double* host_t3, double* host_t2, double* host_v2) {
	// 
	int numTbs = 	CEIL(size_h3, SIZE_TILE_H3) * CEIL(size_h2, SIZE_TILE_H2) * CEIL(size_h1, SIZE_TILE_H1) * 
								CEIL(size_p6, SIZE_TILE_P6) * CEIL(size_p5, SIZE_TILE_P5) * CEIL(size_p4, SIZE_TILE_P4);
	
	// sd2_9: t3[h3,h2,h1,p6,p5,p4] += t2[p7,p6,h1,h3] * v2[p7,h2,p5,p4]
	double* dev_t3; double* dev_t2; double* dev_v2;

	size_t size_t3 = size_h3 * size_h2 * size_h1 * size_p6 * size_p5 * size_p4;
	size_t size_t2 = size_p7 * size_p6 * size_h1 * size_h3;
	size_t size_v2 = size_p7 * size_h2 * size_p5 * size_p4;
  
  // cudaMalloc()
  // CUCHK(cudaMalloc((void**) &dev_t3, sizeof(double) * size_t3));
  CUCHK(cudaMalloc((void**) &dev_t2, sizeof(double) * size_t2));
  CUCHK(cudaMalloc((void**) &dev_v2, sizeof(double) * size_v2));
	
  // cudaMemcpy()
  // CUCHK(cudaMemcpy(dev_t3, host_t3, sizeof(double) * size_t3, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_t2, host_t2, sizeof(double) * size_t2, cudaMemcpyHostToDevice));
  CUCHK(cudaMemcpy(dev_v2, host_v2, sizeof(double) * size_v2, cudaMemcpyHostToDevice));
  
	// Related to Kernels
  // size_t numOperations = 2 * (size_t)(size_h3) * (size_t)(size_h2) * (size_t)(size_h1) * (size_t)(size_p6) * (size_t)(size_p5) * (size_t)(size_p4) * (size_t)(size_p7);
	
  // printf ("========================================= fusedKernels =============================================\n");
	// printf ("[%s] Grid Size (1D): %6d\n", __func__, numTbs);
	// printf ("[%s] Block Size (2D): %2d, %2d\n", __func__, 16, 16);
  // printf ("[%s] # of Operations: %lu\n", __func__, numOperations);
  // printf ("====================================================================================================\n");
  
	// 
	dim3 gridsize_1(numTbs);
	dim3 blocksize_1(16, 16);

  int stride_output_h3 = 1;
  int stride_output_h2 = stride_output_h3 * size_h3;
  int stride_output_h1 = stride_output_h2 * size_h2;
  int stride_output_p6 = stride_output_h1 * size_h1;
  int stride_output_p5 = stride_output_p6 * size_p6;
  int stride_output_p4 = stride_output_p5 * size_p5;
  int stride_reg_x = stride_output_p5;
  int stride_reg_y = stride_output_p6;
	
	//cudaDeviceSetCacheConfig(cudaFuncCachePreferShared);
	// cudaEvent_t start_kernel;
  // cudaEvent_t stop_kernel;
  // cudaEventCreate(&start_kernel);
  // cudaEventCreate(&stop_kernel);
  // cudaEventRecord(start_kernel);
  dev_t3 = t3_d;

  // 
  int maxbytes = 98304; // 96 KB
  CUCHK(cudaFuncSetAttribute(next_unfused_kernel_d2_9, cudaFuncAttributeMaxDynamicSharedMemorySize, maxbytes));
  next_unfused_kernel_d2_9<<<gridsize_1, blocksize_1, 2 * NUM_STAGE * 8 * STAGE_OFFSET, 0>>>(dev_t3, dev_t2, dev_v2, size_h3, size_h2, size_h1, size_p6, size_p5, size_p4, size_p7, 
		CEIL(size_h3, SIZE_TILE_H3), CEIL(size_h2, SIZE_TILE_H2), CEIL(size_h1, SIZE_TILE_H1), 
		CEIL(size_p6, SIZE_TILE_P6), CEIL(size_p5, SIZE_TILE_P5), CEIL(size_p4, SIZE_TILE_P4), 
		stride_reg_x, stride_reg_y,
    size_p7);
  cudaDeviceSynchronize();
  CUCHK(cudaGetLastError());
  
  // cudaEventRecord(stop_kernel);
  // cudaEventSynchronize(stop_kernel);
  // float kernel_ms = 0;
  // cudaEventElapsedTime(&kernel_ms, start_kernel, stop_kernel);
  // printf ("[%s] kernel: %f (ms)\n", __func__, kernel_ms);

  // Copy the Result from Device to Host
  // CUCHK(cudaMemcpy(host_t3, dev_t3, sizeof(double) * size_t3, cudaMemcpyDeviceToHost));

  // cudaFree()
  // CUCHK(cudaFree(dev_t3)); 
	CUCHK(cudaFree(dev_t2)); 
	CUCHK(cudaFree(dev_v2));
}

#endif // A100 and cuda 11.1 
